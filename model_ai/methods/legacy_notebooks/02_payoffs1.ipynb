{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Payoff Matrices (part 1)\n",
    "\n",
    "> This module contains payoff matrices for different evolutionary games\n",
    ">\n",
    "> Part 1 contains payoff matrices for the following games\n",
    "> - DSAIR\n",
    "> - DSAIR with peer punishment or reward\n",
    "> - DSAIR with voluntary commitments\n",
    "> - DSAIR with collective risk\n",
    ">\n",
    "> Note that all of the payoff matrices here are replications of the models from The Anh et al. 2020, 2021, 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp payoffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ethos/git/gh-pages-example/gh_pages_example/model_utils.py:299: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if (ind not in allowed_inds) and (str(ind) not in allowed_inds):\n",
      "/home/ethos/git/gh-pages-example/gh_pages_example/methods.py:260: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  ergodic = np.array(V.transpose(0, 2, 1)[y], dtype=float)\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "#| export\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import test_eq, test_close\n",
    "import collections\n",
    "import functools\n",
    "from gh_pages_example.utils import *\n",
    "from gh_pages_example.types import *\n",
    "from gh_pages_example.methods import *\n",
    "from gh_pages_example.model_utils import *\n",
    "import itertools\n",
    "import math\n",
    "import typing\n",
    "\n",
    "import fastcore.test\n",
    "import more_itertools\n",
    "import numpy as np\n",
    "import nptyping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True) # don't use scientific notation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DSAIR Model Paramaters\n",
    "\n",
    "| keyword | value type | range | optional | description | \n",
    "|---------|------------|-------|----------|-------------|\n",
    "| b | NDArray | b > 0| | The size of the per round benefit of leading the AI development race|\n",
    "| c | NDArray | c > 0| | The cost of implementing safety recommendations per round|\n",
    "| s | NDArray | s > 1| | The speed advantage from choosing to ignore safety recommendations|\n",
    "| p | NDArray | [0, 1]| | The probability that unsafe firms avoid an AI disaster|\n",
    "| B | NDArray | B >> b| | The size of the prize from winning the AI development race|\n",
    "| W | NDArray | $$[10, 10^6]$$| | The anticipated timeline until the development race has a winner if everyone behaves safely|\n",
    "| pfo | NDArray | [0, 1]|Yes| The probability that firms who ignore safety precautions are found out|\n",
    "| epsilon | NDArray | ϵ > 0|Yes| The cost of setting up a voluntary commitment|\n",
    "| ω | NDArray | [0, 1]|Yes| Noise in arranging an agreement, with some probability they fail to succeed in making an agreement|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/PaoloBova/gh-pages-example/blob/main/gh_pages_example/types.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ModelTypeDSAIR\n",
       "\n",
       ">      ModelTypeDSAIR (b:gh_pages_example.types.Array1D,\n",
       ">                      c:gh_pages_example.types.Array1D,\n",
       ">                      s:gh_pages_example.types.Array1D,\n",
       ">                      p:gh_pages_example.types.Array1D,\n",
       ">                      B:gh_pages_example.types.Array1D,\n",
       ">                      W:gh_pages_example.types.Array1D,\n",
       ">                      pfo:gh_pages_example.types.Array1D=None,\n",
       ">                      α:gh_pages_example.types.Array1D=None,\n",
       ">                      γ:gh_pages_example.types.Array1D=None,\n",
       ">                      epsilon:gh_pages_example.types.Array1D=None,\n",
       ">                      ω:gh_pages_example.types.Array1D=None,\n",
       ">                      collective_risk:gh_pages_example.types.Array1D=None)\n",
       "\n",
       "This is the schema for the inputs to a DSAIR model.\n",
       "\n",
       "Note: This schema is not enforced and is here purely for documentation\n",
       "purposes.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| b | Array1D |  | benefit: The size of the per round benefit of leading the AI development race, b>0 |\n",
       "| c | Array1D |  | cost: The cost of implementing safety recommendations per round, c>0 |\n",
       "| s | Array1D |  | speed: The speed advantage from choosing to ignore safety recommendations, s>1 |\n",
       "| p | Array1D |  | avoid_risk: The probability that unsafe firms avoid an AI disaster, p ∈ [0, 1] |\n",
       "| B | Array1D |  | prize: The size of the prize from winning the AI development race, B>>b |\n",
       "| W | Array1D |  | timeline: The anticipated timeline until the development race has a winner if everyone behaves safely, W ∈ [10, 10**6] |\n",
       "| pfo | Array1D | None | detection risk: The probability that firms who ignore safety precautions are found out, pfo ∈ [0, 1] |\n",
       "| α | Array1D | None | the cost of rewarding/punishing a peer |\n",
       "| γ | Array1D | None | the effect of a reward/punishment on a developer's speed |\n",
       "| epsilon | Array1D | None | commitment_cost: The cost of setting up and maintaining a voluntary commitment, ϵ > 0 |\n",
       "| ω | Array1D | None | noise: Noise in arranging an agreement, with some probability they fail to succeed in making an agreement, ω ∈ [0, 1] |\n",
       "| collective_risk | Array1D | None | The likelihood that a disaster affects all actors |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/PaoloBova/gh-pages-example/blob/main/gh_pages_example/types.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ModelTypeDSAIR\n",
       "\n",
       ">      ModelTypeDSAIR (b:gh_pages_example.types.Array1D,\n",
       ">                      c:gh_pages_example.types.Array1D,\n",
       ">                      s:gh_pages_example.types.Array1D,\n",
       ">                      p:gh_pages_example.types.Array1D,\n",
       ">                      B:gh_pages_example.types.Array1D,\n",
       ">                      W:gh_pages_example.types.Array1D,\n",
       ">                      pfo:gh_pages_example.types.Array1D=None,\n",
       ">                      α:gh_pages_example.types.Array1D=None,\n",
       ">                      γ:gh_pages_example.types.Array1D=None,\n",
       ">                      epsilon:gh_pages_example.types.Array1D=None,\n",
       ">                      ω:gh_pages_example.types.Array1D=None,\n",
       ">                      collective_risk:gh_pages_example.types.Array1D=None)\n",
       "\n",
       "This is the schema for the inputs to a DSAIR model.\n",
       "\n",
       "Note: This schema is not enforced and is here purely for documentation\n",
       "purposes.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| b | Array1D |  | benefit: The size of the per round benefit of leading the AI development race, b>0 |\n",
       "| c | Array1D |  | cost: The cost of implementing safety recommendations per round, c>0 |\n",
       "| s | Array1D |  | speed: The speed advantage from choosing to ignore safety recommendations, s>1 |\n",
       "| p | Array1D |  | avoid_risk: The probability that unsafe firms avoid an AI disaster, p ∈ [0, 1] |\n",
       "| B | Array1D |  | prize: The size of the prize from winning the AI development race, B>>b |\n",
       "| W | Array1D |  | timeline: The anticipated timeline until the development race has a winner if everyone behaves safely, W ∈ [10, 10**6] |\n",
       "| pfo | Array1D | None | detection risk: The probability that firms who ignore safety precautions are found out, pfo ∈ [0, 1] |\n",
       "| α | Array1D | None | the cost of rewarding/punishing a peer |\n",
       "| γ | Array1D | None | the effect of a reward/punishment on a developer's speed |\n",
       "| epsilon | Array1D | None | commitment_cost: The cost of setting up and maintaining a voluntary commitment, ϵ > 0 |\n",
       "| ω | Array1D | None | noise: Noise in arranging an agreement, with some probability they fail to succeed in making an agreement, ω ∈ [0, 1] |\n",
       "| collective_risk | Array1D | None | The likelihood that a disaster affects all actors |"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(ModelTypeDSAIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/PaoloBova/gh-pages-example/blob/main/gh_pages_example/types.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Array1D\n",
       "\n",
       ">      Array1D (ModelVector:NDArray[Shape['N_models'],Any])\n",
       "\n",
       "An alias for a 1D numpy array.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| ModelVector | NDArray | A 1D numpy array suitable for stacks of scalar parameter values |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/PaoloBova/gh-pages-example/blob/main/gh_pages_example/types.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Array1D\n",
       "\n",
       ">      Array1D (ModelVector:NDArray[Shape['N_models'],Any])\n",
       "\n",
       "An alias for a 1D numpy array.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| ModelVector | NDArray | A 1D numpy array suitable for stacks of scalar parameter values |"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Array1D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "valid_dtypes = typing.Union[float, list[float], np.ndarray, dict]\n",
    "def build_DSAIR(b:valid_dtypes=4, # benefit: The size of the per round benefit of leading the AI development race, b>0\n",
    "                c:valid_dtypes=1, # cost: The cost of implementing safety recommendations per round, c>0\n",
    "                s:valid_dtypes={\"start\":1, # speed: The speed advantage from choosing to ignore safety recommendations, s>1\n",
    "                                \"stop\":5.1,\n",
    "                                \"step\":0.1}, \n",
    "                p:valid_dtypes={\"start\":0, # avoid_risk: The probability that unsafe firms avoid an AI disaster, p ∈ [0, 1]\n",
    "                                \"stop\":1.02,\n",
    "                                \"step\":0.02}, \n",
    "                B:valid_dtypes=10**4, # prize: The size of the prize from winning the AI development race, B>>b\n",
    "                W:valid_dtypes=100, # timeline: The anticipated timeline until the development race has a winner if everyone behaves safely, W ∈ [10, 10**6]\n",
    "                pfo:valid_dtypes=0, # detection risk: The probability that firms who ignore safety precautions are found out, pfo ∈ [0, 1]\n",
    "                α:valid_dtypes=0, # the cost of rewarding/punishing a peer\n",
    "                γ:valid_dtypes=0, # the effect of a reward/punishment on a developer's speed\n",
    "                epsilon:valid_dtypes=0, # commitment_cost: The cost of setting up and maintaining a voluntary commitment, ϵ > 0\n",
    "                ω:valid_dtypes=0, # noise: Noise in arranging an agreement, with some probability they fail to succeed in making an agreement, ω ∈ [0, 1]\n",
    "                collective_risk:valid_dtypes=0, # The likelihood that a disaster affects all actors\n",
    "                β:valid_dtypes=0.01, # learning_rate: the rate at which players imitate each other\n",
    "                Z:int=100, # population_size: the number of players in the evolutionary game\n",
    "                strategy_set:list[str]=[\"AS\", \"AU\"], # the set of available strategies\n",
    "                exclude_args:list[str]=['Z', 'strategy_set'], # a list of arguments that should be returned as they are\n",
    "                override:bool=False, # whether to build the grid if it is very large\n",
    "                drop_args:list[str]=['override', 'exclude_args', 'drop_args'], # a list of arguments to drop from the final result\n",
    "               ) -> dict: # A dictionary containing items from `ModelTypeDSAIR` and `ModelTypeEGT`\n",
    "    \"\"\"Initialise baseline DSAIR models for all combinations of the provided\n",
    "    parameter valules. By default, we create models for replicating Figure 1\n",
    "    of Han et al. 2021.\"\"\"\n",
    "    \n",
    "    saved_args = locals()\n",
    "    models = model_builder(saved_args,\n",
    "                           exclude_args=exclude_args,\n",
    "                           override=override,\n",
    "                           drop_args=drop_args)\n",
    "    return models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DSAIR Payoff Matrix (Short Run)\n",
    "\n",
    "| Strategy | Safe | Unsafe |\n",
    "|----------|---|---|\n",
    "| **Safe** | $$\\frac{b}{2} - c$$|  $$\\frac{b}{s+1} - c$$ |\n",
    "| **Unsafe** | $$b \\frac{s}{s+1}$$| $$\\frac{b}{2} $$|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def payoffs_sr(models:dict, # A dictionary containing the items in `ModelTypeDSAIR`\n",
    "              ) -> dict : # The `models` dictionary with added payoff matrix `payoffs_sr`\n",
    "    \"\"\"The short run payoffs for the DSAIR game.\"\"\"\n",
    "    s, b, c = [models[k] for k in ['s', 'b', 'c']]\n",
    "    πAA = -c + b/2\n",
    "    πAB = -c + b/(s+1)\n",
    "    πBA = s*b/(s+1)\n",
    "    πBB = b/2\n",
    "    \n",
    "    # Promote all stacks to 3D arrays\n",
    "    πAA = πAA[:, None, None]\n",
    "    πAB = πAB[:, None, None]\n",
    "    πBA = πBA[:, None, None]\n",
    "    πBB = πBB[:, None, None]\n",
    "    matrix = np.block([[πAA, πAB], \n",
    "                       [πBA, πBB]])\n",
    "    return {**models, 'payoffs_sr':matrix}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/PaoloBova/gh-pages-example/blob/main/gh_pages_example/payoffs.py#L63){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### payoffs_sr\n",
       "\n",
       ">      payoffs_sr (models:dict)\n",
       "\n",
       "The short run payoffs for the DSAIR game.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| models | dict | A dictionary containing the items in `ModelTypeDSAIR` |\n",
       "| **Returns** | **dict** | **The `models` dictionary with added payoff matrix `payoffs_sr`** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/PaoloBova/gh-pages-example/blob/main/gh_pages_example/payoffs.py#L63){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### payoffs_sr\n",
       "\n",
       ">      payoffs_sr (models:dict)\n",
       "\n",
       "The short run payoffs for the DSAIR game.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| models | dict | A dictionary containing the items in `ModelTypeDSAIR` |\n",
       "| **Returns** | **dict** | **The `models` dictionary with added payoff matrix `payoffs_sr`** |"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(payoffs_sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DSAIR Payoff Matrix (Short Run) with probability of being found out\n",
    "\n",
    "| Strategy | Safe | Unsafe |\n",
    "|----------|---|---|\n",
    "| **Safe** | $$\\frac{b}{2} - c$$|  $$(1 - p_{fo}) \\frac{b}{s+1} + p_{fo} b - c$$ |\n",
    "| **Unsafe** | $$ (1 - p_{fo}) b \\frac{s}{s+1}$$| $$(1 - p_{fo}^2) \\frac{b}{2} $$|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def payoffs_sr_pfo_extension(models):\n",
    "    \"\"\"The short run payoffs for the DSAIR game with a chance of unsafe\n",
    "    behaviour being spotted.\"\"\"\n",
    "    s, b, c, pfo = [models[k] for k in ['s', 'b', 'c', 'pfo']]\n",
    "    πAA = -c + b/2\n",
    "    πAB = -c + b/(s+1) * (1 - pfo) + pfo * b\n",
    "    πBA = (1 - pfo) * s * b / (s+1)\n",
    "    πBB = (1 - pfo**2) * b/2\n",
    "    \n",
    "    # Promote all stacks to 3D arrays\n",
    "    πAA = πAA[:, None, None]\n",
    "    πAB = πAB[:, None, None]\n",
    "    πBA = πBA[:, None, None]\n",
    "    πBB = πBB[:, None, None]\n",
    "    matrix = np.block([[πAA, πAB],\n",
    "                       [πBA, πBB]])\n",
    "    return {**models, 'payoffs_sr':matrix}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DSAIR Payoff Matrix (Long Run)\n",
    "\n",
    "Denote $\\pi$ as one of the short run payoff matrices discussed above with rows and columns indexed by letters A, B, ...\n",
    "\n",
    "| Strategy | Always Safe | Always Unsafe |\n",
    "|----------|---|---|\n",
    "| **Always Safe** | $$πAA + \\frac{B}{2W}$$|  $$πAB$$ |\n",
    "| **Always Unsafe** | $$p \\, (s \\frac{B}{W} + πBA)$$| $$p \\, (s \\frac{B}{2W} + πBB)$$|\n",
    "\n",
    "*Note: In a model where we suffer a collective risk of an AI disaster if the winner is unsafe, payoffs for firms who play safe when facing an unsafe firm are also multiplied by $p$.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def payoffs_lr(models:dict, # A dictionary containing the items in `ModelTypeDSAIR`\n",
    "              ) -> dict : # The `models` dictionary with added payoff matrix `payoffs`\n",
    "    \"\"\"The long run average payoffs for the DSAIR game.\"\"\"\n",
    "    # All 1D arrays must be promoted to 3D Arrays for broadcasting\n",
    "    s, p, B, W = [models[k][:, None, None]\n",
    "                  for k in ['s', 'p', 'B', 'W']]\n",
    "    πAA,πAB,πBA,πBB = [models['payoffs_sr'][:, i:i+1, j:j+1]\n",
    "                       for i in range(2) for j in range(2)]    \n",
    "    πAA = πAA + B/(2*W)\n",
    "    πAB = πAB\n",
    "    πBA = p*(s*B/W + πBA)\n",
    "    πBB = p*(s*B/(2*W) + πBB)\n",
    "    payoffs = np.block([[πAA, πAB],\n",
    "                        [πBA, πBB]])\n",
    "    return {**models, 'payoffs': payoffs}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DSAIR Payoff Matrix with punishments (Long Run)\n",
    "\n",
    "Denote $\\pi$ as one of the short run payoff matrices discussed above with rows and columns indexed by letters A, B, ...\n",
    "\n",
    "**Always Safe** and **Always Unsafe** play as they usually do.\n",
    "\n",
    "**Punish Unsafe** always plays Safe. However, they will pay a cost to punish their co-player if the co-player plays Unsafe.\n",
    "\n",
    "\n",
    "| Strategy | Always Safe | Always Unsafe | Punish Unsafe |\n",
    "|----------|---|---|---|\n",
    "| **Always Safe** | $$πAA + \\frac{B}{2W}$$|  $$πAB$$ | $$πAA + \\frac{B}{2W}$$ |\n",
    "| **Always Unsafe** | $$p \\, (s \\frac{B}{W} + πBA)$$| $$p \\, (s \\frac{B}{2W} + πBB)$$| punished_payoff|\n",
    "| **Punish Unsafe** | $$πAA + \\frac{B}{2W}$$| sanctioner_payoff | $$πAA + \\frac{B}{2W}$$ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def punished_and_sanctioned_payoffs(models:dict, # A dictionary containing the items in `ModelTypeDSAIR`\n",
    "                                   ) -> dict : # The `models` dictionary with added payoff matrix `payoffs`:\n",
    "    \"\"\"Compute the payoffs for the punished and sanctioner players in a DSAIR\n",
    "    model with peer punishment.\"\"\"\n",
    "    # All 1D arrays must be promoted to 3D Arrays for broadcasting\n",
    "    s,b,c, p, B, W, pfo = [models[k][:, None, None]\n",
    "                      for k in ['s', 'b', 'c', 'p', 'B', 'W', 'pfo']]\n",
    "    α, γ = [models[k][:, None, None] for k in ['α', 'γ']]\n",
    "    πAA,πAB,πBA,πBB = [models['payoffs_sr'][:, i:i+1, j:j+1]\n",
    "                       for i in range(2) for j in range(2)]\n",
    "    \n",
    "    s_punished = s - γ\n",
    "    s_sanctioner = 1 - α\n",
    "    sum_of_speeds = np.maximum(1e-20, s_punished + s_sanctioner)\n",
    "    punished_wins = (s_punished > 0) & (((W-s)*np.maximum(0, s_sanctioner))\n",
    "                                        <= ((W-1) * s_punished))\n",
    "    punished_draws = (s_punished > 0) & (((W-s) * s_sanctioner)\n",
    "                                         == ((W-1) * s_punished))\n",
    "    sanctioner_wins = (s_sanctioner > 0) & (((W-s) * s_sanctioner)\n",
    "                                            >= ((W-1)*np.maximum(0,s_punished)))\n",
    "    no_winner = (s_punished <= 0) & (s_sanctioner <= 0)\n",
    "\n",
    "    both_speeds_positive = (s_punished > 0) & (s_sanctioner > 0)\n",
    "    only_sanctioner_speed_positive = (s_punished <= 0) & (s_sanctioner > 0)\n",
    "    only_punisher_speed_positive = (s_punished > 0) & (s_sanctioner <= 0)\n",
    "\n",
    "    p_loss = np.where(punished_wins | punished_draws, p, 1)\n",
    "    R = np.where(no_winner,\n",
    "                 1e50,\n",
    "                 1 + np.minimum((W-s)/ np.maximum(s_punished, 1e-10),\n",
    "                                (W-1)/ np.maximum(s_sanctioner, 1e-10)))\n",
    "    B_s = np.where(sanctioner_wins, B, np.where(punished_draws, B/2, 0))\n",
    "    B_p = np.where(punished_wins, B, np.where(punished_draws, B/2, 0))\n",
    "    b_s = np.where(both_speeds_positive,\n",
    "                   (1-pfo) * b * s_sanctioner / sum_of_speeds + pfo * b,\n",
    "                   np.where(only_sanctioner_speed_positive, b, 0))\n",
    "    b_p = np.where(both_speeds_positive,\n",
    "                   (1-pfo) * b * s_punished / sum_of_speeds,\n",
    "                   np.where(only_punisher_speed_positive, (1 - pfo)*b, 0))\n",
    "    sanctioner_payoff = (1 / R) * (πAB + B_s - (b_s - c)) + (b_s - c)\n",
    "    # sanctioner_payoff = (1 / R) * (πAB + B_s + (R-1)*(b_s - c))\n",
    "    punished_payoff = (p_loss / R) * (πBA + B_p - b_p) + p_loss * b_p\n",
    "    # punished_payoff = (p_loss / R) * (πBA + B_p + (R-1)*b_p)\n",
    "    return {**models,\n",
    "            'sanctioner_payoff':sanctioner_payoff,\n",
    "            'punished_payoff':punished_payoff}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, I test that we produce expected results for the punished and sanctioned payoffs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = build_DSAIR(b=4,\n",
    "                     c=1,\n",
    "                     p=0.25,\n",
    "                     s=1.5,\n",
    "                     B=10**4,\n",
    "                     W=10**2,\n",
    "                     pfo=0,\n",
    "                     α=np.array([0]),\n",
    "                     γ=np.array([0]),\n",
    "                     β=0.01,\n",
    "                     Z=100,\n",
    "                     strategy_set=[\"AS\", \"AU\", \"PS\"],\n",
    "                     collective_risk=0)\n",
    "\n",
    "results = thread_macro(models,\n",
    "                       payoffs_sr,\n",
    "                       punished_and_sanctioned_payoffs)\n",
    "\n",
    "expected_result = (1/4 * 3 / 200 * (12/5 + 10**4 + 197/3 * 12/5))\n",
    "test_eq(results['punished_payoff'], expected_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = build_DSAIR(b=4,\n",
    "                     c=1,\n",
    "                     p=0.25,\n",
    "                     s=1.5,\n",
    "                     B=10**4,\n",
    "                     W=10**2,\n",
    "                     pfo=0,\n",
    "                     α= np.arange(0, 3, 0.1),\n",
    "                     γ= np.arange(0, 3, 0.1),\n",
    "                     β=0.01,\n",
    "                     Z=100,\n",
    "                     strategy_set=[\"AS\", \"AU\", \"PS\"],\n",
    "                     collective_risk=0)\n",
    "\n",
    "results = thread_macro(models,\n",
    "                       payoffs_sr,\n",
    "                       punished_and_sanctioned_payoffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expected_fn1(α, γ):\n",
    "    p_punish = np.where((3/2 - γ) * (100 - 1) > (1 - α) * (100 - 3/2),\n",
    "                        1/4,\n",
    "                        1)\n",
    "    origin_speed = np.where((3/2 - γ) * (100 - 1) > (1 - α) * (100 - 3/2),\n",
    "                         3/2, \n",
    "                         1)\n",
    "    win_speed = np.where((3/2 - γ) * (100 - 1) > (1 - α) * (100 - 3/2),\n",
    "                         (3/2 - γ), \n",
    "                         (1 - α))\n",
    "    Bp = np.where((3/2 - γ) * (100 - 1) > (1 - α) * (100 - 3/2),\n",
    "                  10**4,\n",
    "                  np.where((3/2 - γ) * (100 - 1) == (1 - α) * (100 - 3/2),\n",
    "                           10**4 / 2,\n",
    "                           0))\n",
    "    sum_of_speeds = np.maximum(1e-20, (3/2 - γ) + (1 - α))\n",
    "    b_p = np.where((3/2 > γ) & (1 > α),\n",
    "                   4 * (3/2 - γ) / sum_of_speeds,\n",
    "                   np.where((3/2 > γ),\n",
    "                            4,\n",
    "                            0))\n",
    "    R_inv = (np.maximum(0, win_speed) \n",
    "                          / (100 - origin_speed + np.maximum(0, win_speed)))\n",
    "    punished_payoff = (p_punish * R_inv * (12/5 + Bp)\n",
    "                       + p_punish * b_p\n",
    "                       - p_punish * b_p * R_inv\n",
    "                      )\n",
    "    return punished_payoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_close(results['punished_payoff'][:, 0, 0],\n",
    "           expected_fn1(results['α'], results['γ']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expected_fn2(α, γ):\n",
    "    origin_speed = np.where((3/2 - γ) * (100 - 1) > (1 - α) * (100 - 3/2),\n",
    "                         3/2, \n",
    "                         1)\n",
    "    win_speed = np.where((3/2 - γ) * (100 - 1) > (1 - α) * (100 - 3/2),\n",
    "                         (3/2 - γ), \n",
    "                         (1 - α))\n",
    "    Bs = np.where((3/2 - γ) * (100 - 1) < (1 - α) * (100 - 3/2),\n",
    "                  10**4,\n",
    "                  np.where((3/2 - γ) * (100 - 1) == (1 - α) * (100 - 3/2),\n",
    "                           10**4 / 2,\n",
    "                           0))\n",
    "    sum_of_speeds = np.maximum(1e-20, (3/2 - γ) + (1 - α))\n",
    "    b_s = np.where((3/2 > γ) & (1 > α),\n",
    "                   4 * (1 - α) / sum_of_speeds,\n",
    "                   np.where((1 > α),\n",
    "                            4,\n",
    "                            0))\n",
    "    R_inv = (np.maximum(0, win_speed) \n",
    "             / (100 - origin_speed + np.maximum(0, win_speed)))\n",
    "    punished_payoff = (R_inv * (3/5 + Bs)\n",
    "                       + (b_s - 1)\n",
    "                       - (b_s - 1) * R_inv\n",
    "                      )\n",
    "    return punished_payoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_close(results['sanctioner_payoff'][:, 0, 0],\n",
    "           expected_fn2(results['α'], results['γ']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def payoffs_lr_peer_punishment(models:dict, # A dictionary containing the items in `ModelTypeDSAIR`\n",
    "              ) -> dict : # The `models` dictionary with added payoff matrix `payoffs`:\n",
    "    \"\"\"The long run average payoffs for the DSAIR game with peer punishment.\"\"\"\n",
    "    # All 1D arrays must be promoted to 3D Arrays for broadcasting\n",
    "    s,b,c, p, B, W = [models[k][:, None, None]\n",
    "                      for k in ['s', 'b', 'c', 'p', 'B', 'W']]\n",
    "    α, γ = [models[k][:, None, None] for k in ['α', 'γ']]\n",
    "    πAA,πAB,πBA,πBB = [models['payoffs_sr'][:, i:i+1, j:j+1]\n",
    "                       for i in range(2) for j in range(2)]\n",
    "    models = punished_and_sanctioned_payoffs(models)\n",
    "    \n",
    "    ΠAA = πAA + B/(2*W)\n",
    "    ΠAB = πAB\n",
    "    ΠAC = πAA + B/(2*W)\n",
    "    ΠBA = p*(s*B/W + πBA)\n",
    "    ΠBB = p*(s*B/(2*W) + πBB)\n",
    "    ΠBC = models[\"punished_payoff\"]\n",
    "    ΠCA = πAA + B/(2*W)\n",
    "    ΠCB = models[\"sanctioner_payoff\"]\n",
    "    ΠCC = πAA + B/(2*W)\n",
    "    matrix = np.block([[ΠAA, ΠAB, ΠAC], \n",
    "                       [ΠBA, ΠBB, ΠBC],\n",
    "                       [ΠCA, ΠCB, ΠCC],\n",
    "                       ])\n",
    "    return {**models, 'payoffs':matrix}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expressions for the sanctioner and punished payoffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience we denote a number of new variables to simplify the expressions for the sanctioner and punished payoffs.\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{sanctioner payoff} = \\frac{1}{R} (\\pi AB + B_s + (R-1) (b_s - c))\\\\\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{punished payoff} = \\frac{p_{punish}}{R} (πBA + B_p + (R-1) b_p)\\\\\n",
    "\\end{equation}\n",
    "\n",
    "*Note: In a model where we suffer a collective risk of an AI disaster if the winner is unsafe, payoffs for firms who play safe when facing an unsafe firm are also multiplied by $p_{punish}$.*\n",
    "\n",
    "We can read the above payoffs as telling us the average payoffs over the R rounds of the race for each firm, assuming the punishment is levied at the end of the first round and the remaining $R - 1$ rounds are played with the punishment in effect.\n",
    "\n",
    "Note that $s_{\\beta}$ denotes the new speed of the firm who is punished and $s_{\\alpha}$ as the speed of the firm who levies the punishment.\n",
    "\n",
    "Below we denote the four possible outcomes (ignoring disaster) of a race between a sanctioner and a punished firm:\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{punished wins} = (s_{\\beta} > 0) \\, \\& \\, (\\frac{W-s}{s_{\\beta}} <= \\frac{W-1}{s_{\\alpha}})\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{sanctioner wins} = (s_{\\alpha} > 0) \\, \\& \\, (\\frac{W-1}{s_{\\alpha}} <= \\frac{W-s}{s_{\\beta}})\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{draw} = (s_{\\beta} > 0) \\, \\& \\, (\\frac{W-s}{s_{\\beta}} = \\frac{W-1}{s_{\\alpha}})\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{no winner} = (s_{\\beta} <= 0)  \\, \\& \\,  (s_{\\alpha} <= 0)\n",
    "\\end{equation}\n",
    "\n",
    "We can use the above expressions to define the following variables:\n",
    "\n",
    "$p_{punish}$ is the probability of avoiding an AI disaster if a punishment is levied and depends on who wins the race.\n",
    "\n",
    "\\begin{equation}\n",
    "p_{punish} = \\begin{cases} 0 & \\text{sanctioner wins | no winner} \\\\\n",
    "p & otherwise\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "$R$ is the number of rounds that the race lasts for; the race ends when the first firm reaches the finish line.\n",
    "\n",
    "\\begin{equation}\n",
    "R = \\begin{cases} \\infty & \\text{no winner} \\\\\n",
    "\\frac{W - 1}{s_{\\alpha}} & \\text{sanctioner wins} \\\\\n",
    "\\frac{W - s}{s_{\\beta}} & \\text{punished wins | draw} \\\\\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "$B_s$ is the prize that the sanctioner receives at the end of the race.\n",
    "\n",
    "\\begin{equation}\n",
    "B_s = \\begin{cases} B & \\text{sanctioner wins} \\\\\n",
    "\\frac{B}{2} & \\text{draw} \\\\\n",
    "0 & otherwise \\\\\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "$B_p$ is the prize that the punished receives at the end of the race.\n",
    "\n",
    "\\begin{equation}\n",
    "B_p = \\begin{cases} B & \\text{punished wins} \\\\\n",
    "\\frac{B}{2} & \\text{draw} \\\\\n",
    "0 & otherwise \\\\\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "$b_s$ is the benefit the sanctioner receives each round, they only gain a benefit if their speed is positive but gain the whole benefit if they are the only firm with positive speed.\n",
    "\n",
    "\\begin{equation}\n",
    "b_s = \\begin{cases} p_{fo} b + (1-p_{fo}) b \\frac{s_{\\alpha}}{s_{\\alpha} + s_{\\beta}} & s_{\\alpha}, s_{\\beta} > 0\\\\\n",
    "b & s_{\\alpha} > 0 >= s_{\\beta} \\\\\n",
    "0 & s_{\\alpha} <= 0 \\\\\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "$b_p$ is the benefit the punished receives each round, they only gain a benefit if their speed is positive but gain the whole benefit if they are the only firm with positive speed.\n",
    "\n",
    "\\begin{equation}\n",
    "b_p = \\begin{cases} (1-p_{fo}) b \\frac{s_{\\beta}}{s_{\\alpha} + s_{\\beta}} & s_{\\alpha}, s_{\\beta} > 0\\\\\n",
    "b & s_{\\beta} > 0 >= s_{\\alpha} \\\\\n",
    "0 & s_{\\beta} <= 0 \\\\\n",
    "\\end{cases}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DSAIR Payoff Matrix with rewards (Long Run)\n",
    "\n",
    "Denote $\\pi$ as one of the short run payoff matrices discussed above with rows and columns indexed by letters A, B, ...\n",
    "\n",
    "**Always Safe** and **Always Unsafe** play as they usually do.\n",
    "\n",
    "**Reward Safe** always plays Safe. However, they will pay a cost to reward their co-player if the co-player plays Safe.\n",
    "\n",
    "| Strategy | Always Safe | Always Unsafe | Reward Safe |\n",
    "|----------|---|---|---|\n",
    "| **Always Safe** | $$πAA + \\frac{B}{2W}$$|  $$πAB$$ | $$πAA + \\frac{B (1 + s_{\\beta})}{W}$$ |\n",
    "| **Always Unsafe** | $$p \\, (s \\frac{B}{W} + πBA)$$| $$p \\, (s \\frac{B}{2W} + πBB)$$| $$p \\, (s \\frac{B}{W} + πBA)$$|\n",
    "| **Reward Safe** | $$ πAA $$| $$ πAB $$| $$πAA + \\frac{B (1 + s_{\\beta} - s_{\\alpha})}{2W}$$ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def payoffs_lr_peer_reward(models:dict, # A dictionary containing the items in `ModelTypeDSAIR`\n",
    "              ) -> dict : # The `models` dictionary with added payoff matrix `payoffs`:\n",
    "    \"\"\"The long run average payoffs for the DSAIR game with peer punishment.\"\"\"\n",
    "    # All 1D arrays must be promoted to 3D Arrays for broadcasting\n",
    "    s,b,c, p, B, W = [models[k][:, None, None]\n",
    "                      for k in ['s', 'b', 'c', 'p', 'B', 'W']]\n",
    "    α, γ = [models[k][:, None, None] for k in ['α', 'γ']]\n",
    "    πAA,πAB,πBA,πBB = [models['payoffs_sr'][:, i:i+1, j:j+1]\n",
    "                       for i in range(2) for j in range(2)]\n",
    "    \n",
    "    s_rewarded = 1 + γ\n",
    "    s_helper = np.maximum(0, 1 - α)\n",
    "    s_colaborative = np.maximum(0, 1 + γ - α)\n",
    "    ΠAA = πAA + B/(2*W)\n",
    "    ΠAB = πBA\n",
    "    ΠAC = πAA + B * s_rewarded / W\n",
    "    ΠBA = p*(s*B/W + πBA)\n",
    "    ΠBB = p*(s*B/(2*W) + πBB)\n",
    "    ΠBC = p*(s*B/W + πBA)\n",
    "    ΠCA = πAA\n",
    "    ΠCB = πAB\n",
    "    ΠCC = πAA + B * s_colaborative/(2*W)\n",
    "    matrix = np.block([[ΠAA, ΠAB, ΠAC], \n",
    "                       [ΠBA, ΠBB, ΠBC],\n",
    "                       [ΠCA, ΠCB, ΠCC],\n",
    "                       ])\n",
    "    return {**models, 'payoffs':matrix}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DSAIR Payoff Matrix with voluntary commitments (Long Run)\n",
    "\n",
    "Denote $\\pi$ as one of the short run payoff matrices discussed above with rows and columns indexed by letters A, B, ...\n",
    "\n",
    "The strategies below are less obvious than in earlier models. **Always Safe Out** and **Always Unsafe Out** are the same strategies we are used to.\n",
    "\n",
    "**Always Safe In** is willing to form a commitment to play Safe. Otherwise, they will always play Unsafe.\n",
    "\n",
    "**Always Unsafe In** is willing to form a commitment but will violate it by always playing Unsafe. This way, they anticipate that they can encourage other firms to play safe and so pull ahead of them in the race.\n",
    "\n",
    "**Punish Violator** is willing to form a commitment to play Safe. Otherwise, they will always play Unsafe. If the coparty to the commitment violates the commitment by playing Unsafe, then this player pays a cost to levy a punishment on the violator.\n",
    "\n",
    "| Strategy| Always Safe Out | Always Unsafe Out |  Always Safe In | Always Unsafe In  | Punish Violator |\n",
    "|----------|---|---|---|---|---|\n",
    "| **Always Safe Out** | $$πAA + \\frac{B}{2W}$$| $$πAB$$ | $$πAB$$ | $$πAB$$ | $$πAB$$|\n",
    "| **Always Unsafe Out** | $$p \\, (s \\frac{B}{W} + πBA)$$| $$p \\, (s \\frac{B}{2W} + πBB)$$| $$p \\, (s \\frac{B}{2W} + πBB)$$| $$p \\, (s \\frac{B}{2W} + πBB)$$ | $$p \\, (s \\frac{B}{2W} + πBB)$$ |\n",
    "| **Always Safe In** | $$p \\, (s \\frac{B}{W} + πBA)$$|  $$p \\, (s \\frac{B}{2W} + πBB)$$ | $$πAA + \\frac{B}{2W} - \\epsilon$$| $$πAB - \\epsilon$$| $$πAA + \\frac{B}{2W} - \\epsilon$$ |\n",
    "| **Always Unsafe In** | $$p \\, (s \\frac{B}{W} + πBA)$$| $$p \\, (s \\frac{B}{2W} + πBB)$$| $$p \\, (s \\frac{B}{W} + πBA) - \\epsilon$$| $$p \\, (s \\frac{B}{2W} + πBB) - \\epsilon$$ | punished_payoff - ϵ |\n",
    "| **Punish Violator** | $$p \\, (s \\frac{B}{W} + πBA)$$| $$p \\, (s \\frac{B}{2W} + πBB)$$| $$πAA + \\frac{B}{2W} - \\epsilon$$ | sanctioner_payoff - ϵ| $$πAA + \\frac{B}{2W} - \\epsilon$$ |\n",
    "\n",
    "The punished and sanctioner payoffs above are exactly the same as in the model with punishments above, so I do not repeat this here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def payoffs_lr_voluntary(models:dict, # A dictionary containing the items in `ModelTypeDSAIR`\n",
    "              ) -> dict : # The `models` dictionary with added payoff matrix `payoffs`:\n",
    "    \"\"\"The long run average payoffs for the DSAIR game with voluntary\n",
    "    commitments.\"\"\"\n",
    "    # All 1D arrays must be promoted to 3D Arrays for broadcasting\n",
    "    s,b,c, p, B, W = [models[k][:, None, None]\n",
    "                      for k in ['s', 'b', 'c', 'p', 'B', 'W']]\n",
    "    α, γ, ϵ = [models[k][:, None, None] for k in ['α', 'γ', 'epsilon']]\n",
    "    πAA,πAB,πBA,πBB = [models['payoffs_sr'][:, i:i+1, j:j+1]\n",
    "                       for i in range(2) for j in range(2)]\n",
    "    models = punished_and_sanctioned_payoffs(models)\n",
    "    \n",
    "    ΠAA = πAA + B/(2*W)\n",
    "    ΠAB = πAB\n",
    "    ΠAC = πAB\n",
    "    ΠAD = πAB\n",
    "    ΠAE = πAB\n",
    "    ΠBA = p*(s*B/W + πBA)\n",
    "    ΠBB = p*(s*B/(2*W) + πBB)\n",
    "    ΠBC = p*(s*B/(2*W) + πBB)\n",
    "    ΠBD = p*(s*B/(2*W) + πBB)\n",
    "    ΠBE = p*(s*B/(2*W) + πBB)\n",
    "    ΠCA = p*(s*B/W + πBA)\n",
    "    ΠCB = p*(s*B/(2*W) + πBB)\n",
    "    ΠCC = πAA + B/(2*W) - ϵ\n",
    "    ΠCD = πAB - ϵ\n",
    "    ΠCE = πAA + B/(2*W) - ϵ\n",
    "    ΠDA = p*(s*B/W + πBA)\n",
    "    ΠDB = p*(s*B/(2*W) + πBB)\n",
    "    ΠDC = p*(s*B/W + πBA) - ϵ\n",
    "    ΠDD = p*(s*B/(2*W) + πBB) - ϵ\n",
    "    ΠDE = models['punished_payoff'] - ϵ\n",
    "    ΠEA = p*(s*B/W + πBA) - ϵ\n",
    "    ΠEB = p*(s*B/(2*W) + πBB)\n",
    "    ΠEC = πAA + B/(2*W) - ϵ\n",
    "    ΠED = models['sanctioner_payoff'] - ϵ\n",
    "    ΠEE = πAA + B/(2*W) - ϵ\n",
    "    matrix = np.block([[ΠAA, ΠAB, ΠAC, ΠAD, ΠAE], \n",
    "                       [ΠBA, ΠBB, ΠBC, ΠBD, ΠBE],\n",
    "                       [ΠCA, ΠCB, ΠCC, ΠCD, ΠCE],\n",
    "                       [ΠDA, ΠDB, ΠDC, ΠDD, ΠDE],\n",
    "                       [ΠEA, ΠEB, ΠEC, ΠED, ΠEE]\n",
    "                       ])\n",
    "    return {**models, 'payoffs':matrix}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DSAIR Payoff Matrix (Long Run) with collective risk\n",
    "\n",
    "Denote $\\pi$ as one of the short run payoff matrices discussed above with rows and columns indexed by letters A, B, ...\n",
    "\n",
    "| Strategy | Always Safe | Always Unsafe |\n",
    "|----------|---|---|\n",
    "| **Always Safe** | $$πAA + \\frac{B}{2W}$$|  $$p \\, πAB$$ |\n",
    "| **Always Unsafe** | $$p \\, (s \\frac{B}{W} + πBA)$$| $$p^2 \\, (s \\frac{B}{2W} + πBB)$$|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def payoffs_lr_collective(models:dict, # A dictionary containing the items in `ModelTypeDSAIR`\n",
    "              ) -> dict : # The `models` dictionary with added payoff matrix `payoffs`:\n",
    "    \"\"\"Long run average payoffs for the DSAIR model with collective risk.\"\"\"\n",
    "    # All 1D arrays must be promoted to 3D Arrays for broadcasting\n",
    "    s,b,c, p, B, W = [models[k][:, None, None]\n",
    "                      for k in ['s', 'b', 'c', 'p', 'B', 'W']]\n",
    "    risk_shared = models[\"collective_risk\"][:, None, None]\n",
    "    πAA,πAB,πBA,πBB = [models['payoffs_sr'][:, i:i+1, j:j+1]\n",
    "                       for i in range(2) for j in range(2)]\n",
    "    πAA = πAA + B/(2*W)\n",
    "    πAB = πAB * (1 - (1-p)*risk_shared)\n",
    "    πBA = p*(s*B/W + πBA)\n",
    "    πBB = p*(s*B/(2*W) + πBB) * (1 - (1-p)*risk_shared)\n",
    "    matrix = np.block([[πAA, πAB],\n",
    "                       [πBA, πBB]])\n",
    "    return {**models, 'payoffs':matrix}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Payoff Matrices (part 2)\n",
    "\n",
    "> This module contains payoff matrices for different evolutionary games\n",
    ">\n",
    "> Part 2 contains payoff matrices for the following games\n",
    "> - Encanacao et al. 2016\n",
    "> - Vasconcelos et al. 2014\n",
    "> - Stochastic payoffs, a. la. Hilbe et al. 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def payoffs_encanacao_2016(models):\n",
    "    names = ['b_r', 'b_s', 'c_s', 'c_t', 'σ']\n",
    "    b_r, b_s, c_s, c_t, σ = [models[k] for k in names]\n",
    "    payoffs = {}\n",
    "    n_players = 3\n",
    "    n_sectors = 3\n",
    "    n_strategies_per_sector = [2, 2, 2]\n",
    "    n_strategies_total = 6\n",
    "    # All players are from the first sector, playing that sector's first strategy\n",
    "    index_min = \"0-0-0\"\n",
    "    # All players are from the third sector, playing that sector's second strategy\n",
    "    index_max = \"5-5-5\"\n",
    "    # Note: The seperator makes it easy to represent games where n_strategies_total >= 10.\n",
    "\n",
    "    # It is also trivial to define a vector which maps these indexes to strategy profiles\n",
    "    # As sector order is fixed we could neglect to mention suscripts for each sector\n",
    "    strategy_names = [\"D\", \"C\", \"D\", \"C\", \"D\", \"C\"]\n",
    "\n",
    "    zero = np.zeros(b_r.shape[0])\n",
    "    # As in the main text\n",
    "    payoffs[\"C-C-C\"] = {\"P3\": b_r-2*c_s,\n",
    "                        \"P2\": σ+b_s-c_t,\n",
    "                        \"P1\": σ+b_s}\n",
    "    payoffs[\"C-C-D\"] = {\"P3\": -c_s,\n",
    "                        \"P2\": b_s-c_t,\n",
    "                        \"P1\": zero}\n",
    "    payoffs[\"C-D-C\"] = {\"P3\": b_r-c_s,\n",
    "                        \"P2\": zero,\n",
    "                        \"P1\": b_s}\n",
    "    payoffs[\"C-D-D\"] = {\"P3\": zero,\n",
    "                        \"P2\": σ,\n",
    "                        \"P1\": σ}\n",
    "    payoffs[\"D-C-C\"] = {\"P3\": zero,\n",
    "                        \"P2\": σ-c_t,\n",
    "                        \"P1\": σ}\n",
    "    payoffs[\"D-C-D\"] = {\"P3\": zero,\n",
    "                        \"P2\": -c_t,\n",
    "                        \"P1\": zero}\n",
    "    payoffs[\"D-D-C\"] = {\"P3\": zero,\n",
    "                        \"P2\": zero,\n",
    "                        \"P1\": zero}\n",
    "    payoffs[\"D-D-D\"] = {\"P3\": zero,\n",
    "                        \"P2\": σ,\n",
    "                        \"P1\": σ}\n",
    "\n",
    "    # The following indexes capture all strategy profiles where each player is fixed to a unique sector\n",
    "    # (and player order does not matter, so we need only consider one ordering of sectors).\n",
    "    payoffs[\"4-2-0\"] = payoffs[\"D-D-D\"]\n",
    "    payoffs[\"4-2-1\"] = payoffs[\"D-D-C\"]\n",
    "    payoffs[\"4-3-0\"] = payoffs[\"D-C-D\"]\n",
    "    payoffs[\"4-3-1\"] = payoffs[\"D-C-C\"]\n",
    "    payoffs[\"5-2-0\"] = payoffs[\"C-D-D\"]\n",
    "    payoffs[\"5-2-1\"] = payoffs[\"C-D-C\"]\n",
    "    payoffs[\"5-3-0\"] = payoffs[\"C-C-D\"]\n",
    "    payoffs[\"5-3-1\"] = payoffs[\"C-C-C\"]\n",
    "    return {**models, \"payoffs\": payoffs}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vasconselos et al. 2014"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They introduce a model of a Collective Risk Dilemma. It is a variant of the\n",
    "public goods game where players must achieve a target level of contributions\n",
    "to avoid risking a disaster which destroys the group's endowments.\n",
    "\n",
    "We compute payoffs when players contribute $0$ or a fixed $c$ proportion of\n",
    "their endowment as a contribution in\n",
    "a game with up to $n$ participants. To do this, we compute the payoffs as a\n",
    "function of the number of contributors, then use that function for each\n",
    "relevant strategy profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "@multi\n",
    "def build_payoffs(models: dict):\n",
    "    return models.get('payoffs_key')\n",
    "\n",
    "\n",
    "@method(build_payoffs, 'vasconcelos_2014_primitives')\n",
    "def build_payoffs(models: dict):\n",
    "    names = ['payoffs_state', 'c', 'T', 'b_r', 'b_p', 'r']\n",
    "    payoffs_state, c, T, b_r, b_p, r = [models[k] for k in names]\n",
    "    strategy_counts = payoffs_state['strategy_counts']\n",
    "    n_r = strategy_counts[\"2\"]\n",
    "    n_p = strategy_counts[\"4\"]\n",
    "    risk = r * (n_r * c * b_r + n_p * c * b_p < T)\n",
    "    # The payoffs must be computed for each strategy type in the interaction.\n",
    "    # In games where we employ hypergeometric sampling, we usually do not\n",
    "    # care about player order in the interaction. If order did matter, then\n",
    "    # we would represent the payoffs per strategy still but it would capture\n",
    "    # the expected payoffs given how likely a player of that strategy was to\n",
    "    # play in each node of the extensive-form game. Non-players of type 0\n",
    "    # usually do not have payoffs.\n",
    "    payoffs = {\"1\": (1 - risk) * b_r,  # rich_free_rider\n",
    "               \"2\": (1 - risk) * c * b_r,  # rich_contributor\n",
    "               \"3\": (1 - risk) * b_p,  # poor_free_rider\n",
    "               \"4\": (1 - risk) * c * b_p}  # poor_contributor\n",
    "    return {**models, \"payoff_primitives\": payoffs}\n",
    "\n",
    "\n",
    "@method(build_payoffs, 'vasconcelos_2014')\n",
    "def build_payoffs(models: dict):\n",
    "    profiles = create_profiles({'n_players': models.get('n_players', 5),\n",
    "                                'n_strategies': [2, 2]})['profiles']\n",
    "    payoffs = {}\n",
    "    for profile in profiles:\n",
    "        profile_tuple = thread_macro(profile,\n",
    "                                     (str.split, \"-\"),\n",
    "                                     (map, int, \"self\"),\n",
    "                                     list,\n",
    "                                     reversed,\n",
    "                                     list,\n",
    "                                     np.array,\n",
    "                                     )\n",
    "        strategy_counts = {f\"{i}\": np.sum(\n",
    "            profile_tuple == i) for i in range(5)}\n",
    "        payoffs_state = {'strategy_counts': strategy_counts}\n",
    "        primitives = thread_macro(models,\n",
    "                                  (assoc,\n",
    "                                   'payoffs_state', payoffs_state,\n",
    "                                   'payoffs_key', \"vasconcelos_2014_primitives\"),\n",
    "                                  build_payoffs,\n",
    "                                  (get, \"payoff_primitives\"),\n",
    "                                  )\n",
    "        payoffs[profile] = {}\n",
    "        for i, strategy in enumerate(profile_tuple):\n",
    "            if strategy == 0:\n",
    "                continue\n",
    "            elif strategy == 1:\n",
    "                payoffs[profile][f\"P{i+1}\"] = primitives['1']\n",
    "            elif strategy == 2:\n",
    "                payoffs[profile][f\"P{i+1}\"] = primitives['2']\n",
    "            elif strategy == 3:\n",
    "                payoffs[profile][f\"P{i+1}\"] = primitives['3']\n",
    "            elif strategy == 4:\n",
    "                payoffs[profile][f\"P{i+1}\"] = primitives['4']\n",
    "            else:\n",
    "                continue\n",
    "    return {**models, \"payoffs\": payoffs}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are a few simple tests of the payoff primitives for their model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'payoffs_state': {'strategy_counts': {\"2\": 2,\n",
    "                                                \"4\": 4}},\n",
    "          'c': 0.5,\n",
    "          'T': 2,\n",
    "          'b_r': 4,\n",
    "          'b_p': 2,\n",
    "          'r': 0.5,\n",
    "          'payoffs_key': 'vasconcelos_2014_primitives'}\n",
    "models = build_payoffs(models)\n",
    "fastcore.test.test_eq(models['payoff_primitives'],\n",
    "                      {'1': 4,\n",
    "                       '2': 2,\n",
    "                       '3': 2,\n",
    "                       '4': 1})\n",
    "models = {**models,\n",
    "          'payoffs_state': {'strategy_counts': {\"2\": 0,\n",
    "                                                \"4\": 1}}, }\n",
    "models = build_payoffs(models)\n",
    "fastcore.test.test_eq(models['payoff_primitives'],\n",
    "                      {'1': 2,\n",
    "                       '2': 1,\n",
    "                       '3': 1,\n",
    "                       '4': 0.5})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We quickly check that we can generate payoffs for each of the 4**5 possible\n",
    "interactions in their model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'c': 0.5,\n",
    "          'T': 2,\n",
    "          'b_r': 4,\n",
    "          'b_p': 2,\n",
    "          'r': 0.5,\n",
    "          'payoffs_key': 'vasconcelos_2014'}\n",
    "models = build_payoffs(models)\n",
    "fastcore.test.test_eq(len(models['payoffs']), 4**5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we are unwilling to use the 5**5 possible strategy profiles for computing\n",
    "the transition matrices for the evolutionary system, we can always restrict\n",
    "our attention to the payoffs given the number of contributors from each sector.\n",
    "We often use hypergeometric sampling anyways when computing the success of\n",
    "each strategy in the evolutionary system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Payoff Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "@method(build_payoffs, 'payoff_function_wrapper')\n",
    "def build_payoffs(models: dict):\n",
    "    profiles = create_profiles(models)['profiles']\n",
    "    profile_payoffs_key = models['profile_payoffs_key']\n",
    "    payoffs_state = models.get(\"payoffs_state\", {})\n",
    "    payoffs = {}\n",
    "    for profile in profiles:\n",
    "        profile_tuple = string_to_tuple(profile)\n",
    "        strategy_counts = dict(zip(*np.unique(profile_tuple,\n",
    "                                              return_counts=True)))\n",
    "        payoffs_state = {**payoffs_state,\n",
    "                         'strategy_counts': strategy_counts}\n",
    "        profile_models = {**models,\n",
    "                          \"strategy_profile\": profile,\n",
    "                          \"payoffs_state\": payoffs_state,\n",
    "                          \"payoffs_key\": profile_payoffs_key}\n",
    "        profile_payoffs = thread_macro(profile_models,\n",
    "                                       build_payoffs,\n",
    "                                       (get, \"profile_payoffs\"),\n",
    "                                       )\n",
    "        payoffs[profile] = {}\n",
    "        for i, strategy in enumerate(profile_tuple):\n",
    "            if strategy == 0:\n",
    "                # A strategy of 0 is reserved for missing players, missing\n",
    "                # players do not have payoffs.\n",
    "                continue\n",
    "            elif str(strategy) in profile_payoffs.keys():\n",
    "                payoffs[profile][f\"P{i+1}\"] = profile_payoffs[f\"{strategy}\"]\n",
    "            else:\n",
    "                continue\n",
    "    return {**models, \"payoffs\": payoffs}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Payoffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic payoffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute the payoffs of stochastic games with state-action transition\n",
    "matrix, $M$, and state-action utilities, $u$, and discount factor, $\\delta$,\n",
    "as follows:\n",
    "\n",
    "$v = (1 - \\delta) v^0 (I - \\delta M)^{-1}$ \\\n",
    "$payoffs = v \\cdot u$\n",
    "\n",
    "When $\\delta \\rightarrow 1$, we instead compute $v$ as the eigenvector of $M$\n",
    "with associated eigenvalue $1$.\n",
    "\n",
    "$M$ is the product of a transition matrix and a matrix containing the\n",
    "probabilities with which each action profile occurs (i.e. a matrix of player\n",
    "(mixed) strategies). $M$ has size $2mk + 1$, where $m$ is the number of states\n",
    "and $k$ is the number of strategies available to each player."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first need to define our flow payoffs, that is, at each state-action\n",
    "combination, what are the payoffs to each type of player."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "@method(build_payoffs, \"flow_payoffs_wrapper\")\n",
    "def build_payoffs(models):\n",
    "    \"Build the flow payoffs for each state-action in a stochastic game.\"\n",
    "    state_actions = models['state_actions']\n",
    "    payoffs_state = models.get('payoffs_state', {})\n",
    "    flow_payoffs = collections.defaultdict()\n",
    "    for state_action in state_actions:\n",
    "        state, action_profile = str.split(state_action, \":\")\n",
    "        action_tuple = string_to_tuple(action_profile)\n",
    "        action_counts = dict(zip(*np.unique(action_tuple,\n",
    "                                            return_counts=True)))\n",
    "        payoffs_state = {**payoffs_state,\n",
    "                         'strategy_counts': action_counts,\n",
    "                         'state': state}\n",
    "        payoffs_flow_key = models['payoffs_flow_key']\n",
    "        profile_models = {**models,\n",
    "                          \"payoffs_state\": payoffs_state,\n",
    "                          \"payoffs_key\": payoffs_flow_key}\n",
    "        flow_payoffs[state_action] = thread_macro(profile_models,\n",
    "                                                  build_payoffs,\n",
    "                                                  (get, \"flow_payoffs\"),\n",
    "                                                  )\n",
    "    return {**models, \"flow_payoffs\": flow_payoffs}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "\n",
    "Specify Q as a map of state-action keys to probabilities for each next state \\\n",
    "Specify P as a map of state-action keys to probabilities for each next action that each player could take.\n",
    "\n",
    "There can be memory issues with storing so many state_actions:\n",
    "- Total number of possible state_actions is equal to (n_states * n_choices^n_players)^2\n",
    "- If game is anonymous (so order does not matter), this reduces to (n_states * ncr(n_choices + n_players -1, n_choices-1))^2\n",
    "\n",
    "The second approach is much much smaller if n_choices is a lot larger than n_players. Unfortunately, we\n",
    "still need to add up the likelihood of each possible action profile, so computation may still \n",
    "be incredibly slow, even if the result still fits in memory.\n",
    "\n",
    "If we ever find ourselves needing to look at many players when trying to\n",
    "compute the transition probabilities for a stochastic game, use a monte carlo\n",
    "simulation instead to learn the transition probabilities and payoffs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "@multi\n",
    "def compute_transition(models):\n",
    "    \"Compute the transition likelihood for the given transition.\"\n",
    "    return models.get('compute_transition_key')\n",
    "\n",
    "@method(compute_transition, 'anonymous_actions')\n",
    "def compute_transition(models):\n",
    "    \"\"\"Compute transition likelihood when we are only passed anonymous action\n",
    "    profiles (i.e. order does not matter).\"\"\"\n",
    "    P, Q = [models[k] for k in ['P', 'Q']]\n",
    "    transition_start, transition_end = [models[k] for k in ['transition_start',\n",
    "                                                            'transition_end']]\n",
    "    next_state, action_profile = transition_end.split(\":\")\n",
    "    action_tuple = string_to_tuple(action_profile)\n",
    "    action_count = dict(zip(*np.unique(action_tuple, return_counts=True)))\n",
    "    profiles = create_profiles({**models,\n",
    "                                \"profiles_rule\": \"from_strategy_count\",\n",
    "                                \"strategy_count\": action_count})['profiles']\n",
    "    profile_tuples = map(string_to_tuple, profiles)\n",
    "    p = [np.prod([P[f\"P{player + 1}\"][transition_start].get(f\"A{action}\", 0)\n",
    "                  for player, action in enumerate(profile_tuple)])\n",
    "         for profile_tuple in profile_tuples]\n",
    "    return np.sum(p) * Q[transition_start][next_state]\n",
    "\n",
    "\n",
    "@method(compute_transition)\n",
    "def compute_transition(models):\n",
    "    \"Compute transition likelihood given the states and action profiles.\"\n",
    "    P, Q = [models[k] for k in ['P', 'Q']]\n",
    "    transition_start, transition_end = [models[k] for k in ['transition_start',\n",
    "                                                            'transition_end']]\n",
    "    next_state, action_profile = transition_end.split(\":\")\n",
    "    action_tuple = string_to_tuple(action_profile)\n",
    "    p = np.prod([P[f\"P{player + 1}\"][transition_start].get(f\"A{action}\", 0)\n",
    "                 for player, action in enumerate(action_tuple)])\n",
    "    return p * Q[transition_start][next_state]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "@method(build_payoffs, \"stochastic-no-discounting\")\n",
    "def build_payoffs(models: dict):\n",
    "    \"\"\"Compute the payoffs for a stochastic game with the given flow_payoffs,\n",
    "    state_transitions, strategies, and strategy_profile, when there is no\n",
    "    discounting.\"\"\"\n",
    "    u = models['flow_payoffs']\n",
    "    Q = models['state_transitions']\n",
    "    strategy_profile = models['strategy_profile'].split(\"-\")[::-1]\n",
    "    strategies = models['strategies']\n",
    "    P = {f\"P{player + 1}\": strategies[strategy_key]\n",
    "         for player, strategy_key in enumerate(strategy_profile)}\n",
    "    state_actions = list(Q.keys())\n",
    "    M = np.zeros((len(state_actions), len(state_actions)))\n",
    "    for row, transition_start in enumerate(state_actions):\n",
    "        for col, transition_end in enumerate(state_actions):\n",
    "            transition_data = {**models,\n",
    "                               \"P\": P,\n",
    "                               \"Q\": Q,\n",
    "                               \"transition_start\": transition_start,\n",
    "                               \"transition_end\": transition_end}\n",
    "            M[row, col] = compute_transition(transition_data)\n",
    "    v = thread_macro({**models, \"transition_matrix\": np.array([M])},\n",
    "                     find_ergodic_distribution,\n",
    "                     (get, \"ergodic\"))[0]\n",
    "    u = np.array([[u[s][f\"{i+1}\"] for i in range(len(u[s]))]\n",
    "                  for s in state_actions])\n",
    "    for _ in range(v.ndim, u.ndim):\n",
    "        v = v[:, None]\n",
    "    payoffs = np.sum(v * u, axis=0)\n",
    "    profile_payoffs = {f\"{i+1}\": pi for i, pi in enumerate(payoffs)}\n",
    "    return {**models, \"profile_payoffs\": profile_payoffs}\n",
    "\n",
    "\n",
    "@method(build_payoffs, \"stochastic-with-discounting\")\n",
    "def build_payoffs(models: dict):\n",
    "    \"\"\"Compute the payoffs for a stochastic game with the given flow_payoffs,\n",
    "    state_transitions, strategies, and strategy_profile.\"\"\"\n",
    "    u = models['flow_payoffs']\n",
    "    Q = models['state_transitions']\n",
    "    d = models['discount_rate']\n",
    "    v0 = models['initial_state_action_distribution']\n",
    "    strategy_profile = models['strategy_profile'].split(\"-\")[::-1]\n",
    "    strategies = models['strategies']\n",
    "    P = {f\"P{player + 1}\": strategies[strategy_key]\n",
    "         for player, strategy_key in enumerate(strategy_profile)}\n",
    "    state_actions = list(Q.keys())\n",
    "    M = np.zeros((len(state_actions), len(state_actions)))\n",
    "    for row, transition_start in enumerate(state_actions):\n",
    "        for col, transition_end in enumerate(state_actions):\n",
    "            transition_data = {**models,\n",
    "                               \"P\": P,\n",
    "                               \"Q\": Q,\n",
    "                               \"transition_start\": transition_start,\n",
    "                               \"transition_end\": transition_end}\n",
    "            M[row, col] = compute_transition(transition_data)\n",
    "    v = (1 - d) * v0 * np.linalg.inv(np.eye(M.shape) - d * M)\n",
    "    u = np.array([[u[s][f\"{i+1}\"] for i in range(len(u[s]))]\n",
    "                  for s in state_actions])\n",
    "    for _ in range(v.ndim, u.ndim):\n",
    "        v = v[:, None]\n",
    "    payoffs = np.sum(v * u, axis=0)\n",
    "    profile_payoffs = {f\"{i+1}\": pi for i, pi in enumerate(payoffs)}\n",
    "    return {**models, \"profile_payoffs\": profile_payoffs}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tests for \"flow_payoffs_wrapper\" method of `build_payoffs`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of flow payoffs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "@method(build_payoffs, 'vasconcelos_2014_flow')\n",
    "def build_payoffs(models: dict):\n",
    "    names = ['payoffs_state', 'c', 'T', 'b_r', 'b_p', 'r', 'g']\n",
    "    payoffs_state, c, T, b_r, b_p, r, g = [models[k] for k in names]\n",
    "    strategy_counts = payoffs_state['strategy_counts']\n",
    "    state = payoffs_state['state']\n",
    "    reward_bonus = g if state=='1' else 1\n",
    "    n_r = strategy_counts.get(\"2\", 0)\n",
    "    n_p = strategy_counts.get(\"4\", 0)\n",
    "    risk = r * (n_r * c * b_r + n_p * c * b_p < T)\n",
    "    payoffs = {\"1\": (1 - risk) * b_r * reward_bonus,  # rich_free_rider\n",
    "               \"2\": (1 - risk) * c * b_r * reward_bonus,  # rich_contributor\n",
    "               \"3\": (1 - risk) * b_p * reward_bonus,  # poor_free_rider\n",
    "               \"4\": (1 - risk) * c * b_p * reward_bonus}  # poor_contributor\n",
    "    return {**models, \"flow_payoffs\": payoffs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\"allowed_sectors\": {\"P1\": [\"S1\", \"S2\"],\n",
    "                              \"P2\": [\"S1\", \"S2\"]},\n",
    "          \"sector_strategies\": {\"S1\": [1, 2],\n",
    "                                \"S2\": [3, 4]},\n",
    "          \"profiles_rule\": \"allowed_sectors\",}\n",
    "action_profiles = create_profiles(models)[\"profiles\"]\n",
    "n_states = 2\n",
    "state_actions = []\n",
    "for profile in action_profiles:\n",
    "    for state in range(n_states):\n",
    "        state_actions.append(f\"{state}:{profile}\")\n",
    "\n",
    "models = {\"payoffs_flow_key\": \"vasconcelos_2014_flow\",\n",
    "          \"payoffs_key\": \"flow_payoffs_wrapper\",\n",
    "          \"state_actions\": state_actions,\n",
    "          'c': 0.5,\n",
    "          'T': 2,\n",
    "          'b_r': 4,\n",
    "          'b_p': 2,\n",
    "          'r': 0.8,\n",
    "          'g': 2,\n",
    "          }\n",
    "flow_payoffs = build_payoffs(models)['flow_payoffs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None,\n",
       "            {'0:1-1': {'1': 0.7999999999999998,\n",
       "              '2': 0.3999999999999999,\n",
       "              '3': 0.3999999999999999,\n",
       "              '4': 0.19999999999999996},\n",
       "             '1:1-1': {'1': 1.5999999999999996,\n",
       "              '2': 0.7999999999999998,\n",
       "              '3': 0.7999999999999998,\n",
       "              '4': 0.3999999999999999},\n",
       "             '0:1-2': {'1': 0.7999999999999998,\n",
       "              '2': 0.3999999999999999,\n",
       "              '3': 0.3999999999999999,\n",
       "              '4': 0.19999999999999996},\n",
       "             '1:1-2': {'1': 1.5999999999999996,\n",
       "              '2': 0.7999999999999998,\n",
       "              '3': 0.7999999999999998,\n",
       "              '4': 0.3999999999999999},\n",
       "             '0:1-3': {'1': 0.7999999999999998,\n",
       "              '2': 0.3999999999999999,\n",
       "              '3': 0.3999999999999999,\n",
       "              '4': 0.19999999999999996},\n",
       "             '1:1-3': {'1': 1.5999999999999996,\n",
       "              '2': 0.7999999999999998,\n",
       "              '3': 0.7999999999999998,\n",
       "              '4': 0.3999999999999999},\n",
       "             '0:1-4': {'1': 0.7999999999999998,\n",
       "              '2': 0.3999999999999999,\n",
       "              '3': 0.3999999999999999,\n",
       "              '4': 0.19999999999999996},\n",
       "             '1:1-4': {'1': 1.5999999999999996,\n",
       "              '2': 0.7999999999999998,\n",
       "              '3': 0.7999999999999998,\n",
       "              '4': 0.3999999999999999},\n",
       "             '0:2-1': {'1': 0.7999999999999998,\n",
       "              '2': 0.3999999999999999,\n",
       "              '3': 0.3999999999999999,\n",
       "              '4': 0.19999999999999996},\n",
       "             '1:2-1': {'1': 1.5999999999999996,\n",
       "              '2': 0.7999999999999998,\n",
       "              '3': 0.7999999999999998,\n",
       "              '4': 0.3999999999999999},\n",
       "             '0:2-2': {'1': 0.7999999999999998,\n",
       "              '2': 0.3999999999999999,\n",
       "              '3': 0.3999999999999999,\n",
       "              '4': 0.19999999999999996},\n",
       "             '1:2-2': {'1': 1.5999999999999996,\n",
       "              '2': 0.7999999999999998,\n",
       "              '3': 0.7999999999999998,\n",
       "              '4': 0.3999999999999999},\n",
       "             '0:2-3': {'1': 0.7999999999999998,\n",
       "              '2': 0.3999999999999999,\n",
       "              '3': 0.3999999999999999,\n",
       "              '4': 0.19999999999999996},\n",
       "             '1:2-3': {'1': 1.5999999999999996,\n",
       "              '2': 0.7999999999999998,\n",
       "              '3': 0.7999999999999998,\n",
       "              '4': 0.3999999999999999},\n",
       "             '0:2-4': {'1': 0.7999999999999998,\n",
       "              '2': 0.3999999999999999,\n",
       "              '3': 0.3999999999999999,\n",
       "              '4': 0.19999999999999996},\n",
       "             '1:2-4': {'1': 1.5999999999999996,\n",
       "              '2': 0.7999999999999998,\n",
       "              '3': 0.7999999999999998,\n",
       "              '4': 0.3999999999999999},\n",
       "             '0:3-1': {'1': 0.7999999999999998,\n",
       "              '2': 0.3999999999999999,\n",
       "              '3': 0.3999999999999999,\n",
       "              '4': 0.19999999999999996},\n",
       "             '1:3-1': {'1': 1.5999999999999996,\n",
       "              '2': 0.7999999999999998,\n",
       "              '3': 0.7999999999999998,\n",
       "              '4': 0.3999999999999999},\n",
       "             '0:3-2': {'1': 0.7999999999999998,\n",
       "              '2': 0.3999999999999999,\n",
       "              '3': 0.3999999999999999,\n",
       "              '4': 0.19999999999999996},\n",
       "             '1:3-2': {'1': 1.5999999999999996,\n",
       "              '2': 0.7999999999999998,\n",
       "              '3': 0.7999999999999998,\n",
       "              '4': 0.3999999999999999},\n",
       "             '0:3-3': {'1': 0.7999999999999998,\n",
       "              '2': 0.3999999999999999,\n",
       "              '3': 0.3999999999999999,\n",
       "              '4': 0.19999999999999996},\n",
       "             '1:3-3': {'1': 1.5999999999999996,\n",
       "              '2': 0.7999999999999998,\n",
       "              '3': 0.7999999999999998,\n",
       "              '4': 0.3999999999999999},\n",
       "             '0:3-4': {'1': 0.7999999999999998,\n",
       "              '2': 0.3999999999999999,\n",
       "              '3': 0.3999999999999999,\n",
       "              '4': 0.19999999999999996},\n",
       "             '1:3-4': {'1': 1.5999999999999996,\n",
       "              '2': 0.7999999999999998,\n",
       "              '3': 0.7999999999999998,\n",
       "              '4': 0.3999999999999999},\n",
       "             '0:4-1': {'1': 0.7999999999999998,\n",
       "              '2': 0.3999999999999999,\n",
       "              '3': 0.3999999999999999,\n",
       "              '4': 0.19999999999999996},\n",
       "             '1:4-1': {'1': 1.5999999999999996,\n",
       "              '2': 0.7999999999999998,\n",
       "              '3': 0.7999999999999998,\n",
       "              '4': 0.3999999999999999},\n",
       "             '0:4-2': {'1': 0.7999999999999998,\n",
       "              '2': 0.3999999999999999,\n",
       "              '3': 0.3999999999999999,\n",
       "              '4': 0.19999999999999996},\n",
       "             '1:4-2': {'1': 1.5999999999999996,\n",
       "              '2': 0.7999999999999998,\n",
       "              '3': 0.7999999999999998,\n",
       "              '4': 0.3999999999999999},\n",
       "             '0:4-3': {'1': 0.7999999999999998,\n",
       "              '2': 0.3999999999999999,\n",
       "              '3': 0.3999999999999999,\n",
       "              '4': 0.19999999999999996},\n",
       "             '1:4-3': {'1': 1.5999999999999996,\n",
       "              '2': 0.7999999999999998,\n",
       "              '3': 0.7999999999999998,\n",
       "              '4': 0.3999999999999999},\n",
       "             '0:4-4': {'1': 0.7999999999999998,\n",
       "              '2': 0.3999999999999999,\n",
       "              '3': 0.3999999999999999,\n",
       "              '4': 0.19999999999999996},\n",
       "             '1:4-4': {'1': 1.5999999999999996,\n",
       "              '2': 0.7999999999999998,\n",
       "              '3': 0.7999999999999998,\n",
       "              '4': 0.3999999999999999}})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flow_payoffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### State transition functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "@multi\n",
    "def state_transition(models):\n",
    "    \"Compute the likelihood of the given state_transition.\"\n",
    "    return models.get('state_transition_key')\n",
    "\n",
    "@method(state_transition, 'ex1')\n",
    "def state_transition(models):\n",
    "    \"\"\"Compute transition likelihood for a model with 2 states and an arbitrary\n",
    "    number of players. To stay in the good state, 0, all players need to choose\n",
    "    to cooperate, i.e. action 1.\"\"\"\n",
    "    state_action, next_state = [models[k] for k in ['state_action',\n",
    "                                                    'next_state']]\n",
    "    current_state, action_profile = state_action.split(\":\")\n",
    "    action_tuple = string_to_tuple(action_profile)\n",
    "    action_count = dict(zip(*np.unique(action_tuple, return_counts=True)))\n",
    "    n_players = len(action_tuple)\n",
    "    n_cooperators = action_count.get(1, 0) + action_count.get(3, 0)\n",
    "    if (current_state == '0'\n",
    "        and next_state == '1'\n",
    "        and n_cooperators != n_players):\n",
    "        transition_likelihood = 1\n",
    "    elif (current_state == '1'\n",
    "          and next_state == '0'\n",
    "          and n_cooperators == n_players):\n",
    "        transition_likelihood = 1\n",
    "    elif (current_state == '0'\n",
    "          and next_state == '0'\n",
    "          and n_cooperators == n_players):\n",
    "        transition_likelihood = 1\n",
    "    elif (current_state == '1'\n",
    "          and next_state == '1'\n",
    "          and n_cooperators != n_players):\n",
    "        transition_likelihood = 1\n",
    "    else:\n",
    "        transition_likelihood = 0\n",
    "    return transition_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def build_state_transitions(models):\n",
    "    state_actions = models['state_actions']\n",
    "    n_states = models['n_states']\n",
    "    state_transitions = {}\n",
    "    for state_action in state_actions:\n",
    "        state_transitions[state_action] = {}\n",
    "        for next_state in [f\"{i}\" for i in range(n_states)]:\n",
    "            likelihood = state_transition({**models,\n",
    "                                           \"state_action\": state_action,\n",
    "                                           \"next_state\": next_state})\n",
    "            state_transitions[state_action][next_state] = likelihood\n",
    "    return {**models, \"state_transitions\": state_transitions}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tests for `build_state_transitions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\"allowed_sectors\": {\"P1\": [\"S1\", \"S2\"],\n",
    "                              \"P2\": [\"S1\", \"S2\"]},\n",
    "          \"sector_strategies\": {\"S1\": [1, 2],\n",
    "                                \"S2\": [3, 4]},\n",
    "          \"profiles_rule\": \"allowed_sectors\", }\n",
    "action_profiles = create_profiles(models)[\"profiles\"]\n",
    "n_states = 2\n",
    "state_actions = [f\"{state}:{a}\"\n",
    "                 for a in action_profiles\n",
    "                 for state in range(n_states)]\n",
    "models = {'n_states':n_states,\n",
    "          'state_actions': state_actions,\n",
    "          'state_transition_key': 'ex1'}\n",
    "result = build_state_transitions(models)['state_transitions']\n",
    "expected = {'0:1-1': {'0': 1, '1': 0},\n",
    " '1:1-1': {'0': 1, '1': 0},\n",
    " '0:1-2': {'0': 0, '1': 1},\n",
    " '1:1-2': {'0': 0, '1': 1},\n",
    " '0:1-3': {'0': 1, '1': 0},\n",
    " '1:1-3': {'0': 1, '1': 0},\n",
    " '0:1-4': {'0': 0, '1': 1},\n",
    " '1:1-4': {'0': 0, '1': 1},\n",
    " '0:2-1': {'0': 0, '1': 1},\n",
    " '1:2-1': {'0': 0, '1': 1},\n",
    " '0:2-2': {'0': 0, '1': 1},\n",
    " '1:2-2': {'0': 0, '1': 1},\n",
    " '0:2-3': {'0': 0, '1': 1},\n",
    " '1:2-3': {'0': 0, '1': 1},\n",
    " '0:2-4': {'0': 0, '1': 1},\n",
    " '1:2-4': {'0': 0, '1': 1},\n",
    " '0:3-1': {'0': 1, '1': 0},\n",
    " '1:3-1': {'0': 1, '1': 0},\n",
    " '0:3-2': {'0': 0, '1': 1},\n",
    " '1:3-2': {'0': 0, '1': 1},\n",
    " '0:3-3': {'0': 1, '1': 0},\n",
    " '1:3-3': {'0': 1, '1': 0},\n",
    " '0:3-4': {'0': 0, '1': 1},\n",
    " '1:3-4': {'0': 0, '1': 1},\n",
    " '0:4-1': {'0': 0, '1': 1},\n",
    " '1:4-1': {'0': 0, '1': 1},\n",
    " '0:4-2': {'0': 0, '1': 1},\n",
    " '1:4-2': {'0': 0, '1': 1},\n",
    " '0:4-3': {'0': 0, '1': 1},\n",
    " '1:4-3': {'0': 0, '1': 1},\n",
    " '0:4-4': {'0': 0, '1': 1},\n",
    " '1:4-4': {'0': 0, '1': 1}}\n",
    "fastcore.test.test_eq(result, expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\"allowed_sectors\": {\"P1\": [\"S1\", \"S2\"],\n",
    "                              \"P2\": [\"S1\", \"S2\"]},\n",
    "          \"sector_strategies\": {\"S1\": [\"1\", \"2\"],\n",
    "                                \"S2\": [\"3\", \"4\"]},\n",
    "          \"profiles_rule\": \"anonymous\", }\n",
    "action_profiles = create_profiles(models)[\"profiles\"]\n",
    "n_states = 2\n",
    "state_actions = [f\"{state}:{a}\"\n",
    "                 for a in action_profiles\n",
    "                 for state in range(n_states)]\n",
    "models = {'n_states':n_states,\n",
    "          'state_actions': state_actions,\n",
    "          'state_transition_key': 'ex1'}\n",
    "result = build_state_transitions(models)['state_transitions']\n",
    "expected = {'0:4-4': {'0': 0, '1': 1},\n",
    " '1:4-4': {'0': 0, '1': 1},\n",
    " '0:4-3': {'0': 0, '1': 1},\n",
    " '1:4-3': {'0': 0, '1': 1},\n",
    " '0:3-3': {'0': 1, '1': 0},\n",
    " '1:3-3': {'0': 1, '1': 0},\n",
    " '0:4-2': {'0': 0, '1': 1},\n",
    " '1:4-2': {'0': 0, '1': 1},\n",
    " '0:3-2': {'0': 0, '1': 1},\n",
    " '1:3-2': {'0': 0, '1': 1},\n",
    " '0:2-2': {'0': 0, '1': 1},\n",
    " '1:2-2': {'0': 0, '1': 1},\n",
    " '0:4-1': {'0': 0, '1': 1},\n",
    " '1:4-1': {'0': 0, '1': 1},\n",
    " '0:3-1': {'0': 1, '1': 0},\n",
    " '1:3-1': {'0': 1, '1': 0},\n",
    " '0:2-1': {'0': 0, '1': 1},\n",
    " '1:2-1': {'0': 0, '1': 1},\n",
    " '0:1-1': {'0': 1, '1': 0},\n",
    " '1:1-1': {'0': 1, '1': 0}}\n",
    "fastcore.test.test_eq(result, expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Strategy construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "@multi\n",
    "def build_strategy(models):\n",
    "    \"Build the desired strategy\"\n",
    "    return models.get('strategy_key')\n",
    "\n",
    "@method(build_strategy, 'ex1_rich_cooperator')\n",
    "def build_strategy(models):\n",
    "    \"\"\"A rich player who cooperates with 95% probability if everyone currently\n",
    "    cooperates, otherwise defects with 95% probability.\"\"\"\n",
    "    state_action = models['state_action']\n",
    "    current_state, action_profile = state_action.split(\":\")\n",
    "    action_tuple = string_to_tuple(action_profile)\n",
    "    action_count = dict(zip(*np.unique(action_tuple, return_counts=True)))\n",
    "    n_players = len(action_tuple)\n",
    "    n_cooperators = action_count.get(1, 0) + action_count.get(3, 0)\n",
    "    if (current_state == '0'\n",
    "        and n_cooperators == n_players):\n",
    "        strategy = {\"A1\": 0.95, \"A2\": 0.05}\n",
    "    elif (current_state == '0'\n",
    "          and n_cooperators != n_players):\n",
    "        strategy = {\"A1\": 0.05, \"A2\": 0.95}\n",
    "    elif (current_state == '1'\n",
    "          and n_cooperators == n_players):\n",
    "        strategy = {\"A1\": 0.95, \"A2\": 0.05}\n",
    "    elif (current_state == '1'\n",
    "          and n_cooperators != n_players):\n",
    "        strategy = {\"A1\": 0.05, \"A2\": 0.95}\n",
    "    return strategy\n",
    "\n",
    "@method(build_strategy, 'ex1_rich_defector')\n",
    "def build_strategy(models):\n",
    "    \"\"\"A rich player who defects with 95% probability no matter what others\n",
    "    do, nor what state they are in.\"\"\"\n",
    "    state_action = models['state_action']\n",
    "    current_state, action_profile = state_action.split(\":\")\n",
    "    action_tuple = string_to_tuple(action_profile)\n",
    "    action_count = dict(zip(*np.unique(action_tuple, return_counts=True)))\n",
    "    n_players = len(action_tuple)\n",
    "    n_cooperators = action_count.get(1, 0) + action_count.get(3, 0)\n",
    "    if (current_state == '0'\n",
    "        and n_cooperators == n_players):\n",
    "        strategy = {\"A1\": 0.05, \"A2\": 0.95}\n",
    "    elif (current_state == '0'\n",
    "          and n_cooperators != n_players):\n",
    "        strategy = {\"A1\": 0.05, \"A2\": 0.95}\n",
    "    elif (current_state == '1'\n",
    "          and n_cooperators == n_players):\n",
    "        strategy = {\"A1\": 0.05, \"A2\": 0.95}\n",
    "    elif (current_state == '1'\n",
    "          and n_cooperators != n_players):\n",
    "        strategy = {\"A1\": 0.05, \"A2\": 0.95}\n",
    "    return strategy\n",
    "\n",
    "@method(build_strategy, 'ex1_poor_cooperator')\n",
    "def build_strategy(models):\n",
    "    \"\"\"A poor player who cooperates with 95% probability if everyone currently\n",
    "    cooperates, otherwise defects with 95% probability.\"\"\"\n",
    "    state_action = models['state_action']\n",
    "    current_state, action_profile = state_action.split(\":\")\n",
    "    action_tuple = string_to_tuple(action_profile)\n",
    "    action_count = dict(zip(*np.unique(action_tuple, return_counts=True)))\n",
    "    n_players = len(action_tuple)\n",
    "    n_cooperators = action_count.get(1, 0) + action_count.get(3, 0)\n",
    "    if (current_state == '0'\n",
    "        and n_cooperators == n_players):\n",
    "        strategy = {\"A3\": 0.95, \"A4\": 0.05}\n",
    "    elif (current_state == '0'\n",
    "          and n_cooperators != n_players):\n",
    "        strategy = {\"A3\": 0.05, \"A4\": 0.95}\n",
    "    elif (current_state == '1'\n",
    "          and n_cooperators == n_players):\n",
    "        strategy = {\"A3\": 0.95, \"A4\": 0.05}\n",
    "    elif (current_state == '1'\n",
    "          and n_cooperators != n_players):\n",
    "        strategy = {\"A3\": 0.05, \"A4\": 0.95}\n",
    "    return strategy\n",
    "\n",
    "@method(build_strategy, 'ex1_poor_defector')\n",
    "def build_strategy(models):\n",
    "    \"\"\"A poor player who defects with 95% probability no matter what others\n",
    "    do, nor what state they are in.\"\"\"\n",
    "    state_action = models['state_action']\n",
    "    current_state, action_profile = state_action.split(\":\")\n",
    "    action_tuple = string_to_tuple(action_profile)\n",
    "    action_count = dict(zip(*np.unique(action_tuple, return_counts=True)))\n",
    "    n_players = len(action_tuple)\n",
    "    n_cooperators = action_count.get(1, 0) + action_count.get(3, 0)\n",
    "    if (current_state == '0'\n",
    "        and n_cooperators == n_players):\n",
    "        strategy = {\"A3\": 0.05, \"A4\": 0.95}\n",
    "    elif (current_state == '0'\n",
    "          and n_cooperators != n_players):\n",
    "        strategy = {\"A3\": 0.05, \"A4\": 0.95}\n",
    "    elif (current_state == '1'\n",
    "          and n_cooperators == n_players):\n",
    "        strategy = {\"A3\": 0.05, \"A4\": 0.95}\n",
    "    elif (current_state == '1'\n",
    "          and n_cooperators != n_players):\n",
    "        strategy = {\"A3\": 0.05, \"A4\": 0.95}\n",
    "    return strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def build_strategies(models):\n",
    "    \"Build a dictionary containing the specified strategies in `models`\"\n",
    "    state_actions, strategy_keys = [models[k] for k in [\"state_actions\",\n",
    "                                                        \"strategy_keys\"]]\n",
    "    strategies = {f\"{i+1}\": {s: build_strategy({\"strategy_key\": strategy_key,\n",
    "                                            \"state_action\": s})\n",
    "                         for s in state_actions}\n",
    "              for i, strategy_key in enumerate(strategy_keys)}\n",
    "    return {**models, \"strategies\": strategies}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tests for `build_strategy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\"allowed_sectors\": {\"P1\": [\"S1\", \"S2\"],\n",
    "                              \"P2\": [\"S1\", \"S2\"]},\n",
    "          \"sector_strategies\": {\"S1\": [\"1\", \"2\"],\n",
    "                                \"S2\": [\"3\", \"4\"]},\n",
    "          \"profiles_rule\": \"anonymous\", }\n",
    "action_profiles = create_profiles(models)[\"profiles\"]\n",
    "n_states = 2\n",
    "state_actions = [f\"{state}:{a}\"\n",
    "                 for a in action_profiles\n",
    "                 for state in range(n_states)]\n",
    "strategy_keys = [\"ex1_rich_cooperator\",\n",
    "                 \"ex1_rich_defector\",\n",
    "                 \"ex1_poor_cooperator\",\n",
    "                 \"ex1_poor_defector\",]\n",
    "strategies = {f\"{i+1}\": {s: build_strategy({\"strategy_key\": strategy_key,\n",
    "                                            \"state_action\": s})\n",
    "                         for s in state_actions}\n",
    "              for i, strategy_key in enumerate(strategy_keys)}\n",
    "expected = {'1': {'0:4-4': {'A1': 0.05, 'A2': 0.95},\n",
    "  '1:4-4': {'A1': 0.05, 'A2': 0.95},\n",
    "  '0:4-3': {'A1': 0.05, 'A2': 0.95},\n",
    "  '1:4-3': {'A1': 0.05, 'A2': 0.95},\n",
    "  '0:3-3': {'A1': 0.95, 'A2': 0.05},\n",
    "  '1:3-3': {'A1': 0.95, 'A2': 0.05},\n",
    "  '0:4-2': {'A1': 0.05, 'A2': 0.95},\n",
    "  '1:4-2': {'A1': 0.05, 'A2': 0.95},\n",
    "  '0:3-2': {'A1': 0.05, 'A2': 0.95},\n",
    "  '1:3-2': {'A1': 0.05, 'A2': 0.95},\n",
    "  '0:2-2': {'A1': 0.05, 'A2': 0.95},\n",
    "  '1:2-2': {'A1': 0.05, 'A2': 0.95},\n",
    "  '0:4-1': {'A1': 0.05, 'A2': 0.95},\n",
    "  '1:4-1': {'A1': 0.05, 'A2': 0.95},\n",
    "  '0:3-1': {'A1': 0.95, 'A2': 0.05},\n",
    "  '1:3-1': {'A1': 0.95, 'A2': 0.05},\n",
    "  '0:2-1': {'A1': 0.05, 'A2': 0.95},\n",
    "  '1:2-1': {'A1': 0.05, 'A2': 0.95},\n",
    "  '0:1-1': {'A1': 0.95, 'A2': 0.05},\n",
    "  '1:1-1': {'A1': 0.95, 'A2': 0.05}},\n",
    " '2': {'0:4-4': {'A1': 0.05, 'A2': 0.95},\n",
    "  '1:4-4': {'A1': 0.05, 'A2': 0.95},\n",
    "  '0:4-3': {'A1': 0.05, 'A2': 0.95},\n",
    "  '1:4-3': {'A1': 0.05, 'A2': 0.95},\n",
    "  '0:3-3': {'A1': 0.05, 'A2': 0.95},\n",
    "  '1:3-3': {'A1': 0.05, 'A2': 0.95},\n",
    "  '0:4-2': {'A1': 0.05, 'A2': 0.95},\n",
    "  '1:4-2': {'A1': 0.05, 'A2': 0.95},\n",
    "  '0:3-2': {'A1': 0.05, 'A2': 0.95},\n",
    "  '1:3-2': {'A1': 0.05, 'A2': 0.95},\n",
    "  '0:2-2': {'A1': 0.05, 'A2': 0.95},\n",
    "  '1:2-2': {'A1': 0.05, 'A2': 0.95},\n",
    "  '0:4-1': {'A1': 0.05, 'A2': 0.95},\n",
    "  '1:4-1': {'A1': 0.05, 'A2': 0.95},\n",
    "  '0:3-1': {'A1': 0.05, 'A2': 0.95},\n",
    "  '1:3-1': {'A1': 0.05, 'A2': 0.95},\n",
    "  '0:2-1': {'A1': 0.05, 'A2': 0.95},\n",
    "  '1:2-1': {'A1': 0.05, 'A2': 0.95},\n",
    "  '0:1-1': {'A1': 0.05, 'A2': 0.95},\n",
    "  '1:1-1': {'A1': 0.05, 'A2': 0.95}},\n",
    " '3': {'0:4-4': {'A3': 0.05, 'A4': 0.95},\n",
    "  '1:4-4': {'A3': 0.05, 'A4': 0.95},\n",
    "  '0:4-3': {'A3': 0.05, 'A4': 0.95},\n",
    "  '1:4-3': {'A3': 0.05, 'A4': 0.95},\n",
    "  '0:3-3': {'A3': 0.95, 'A4': 0.05},\n",
    "  '1:3-3': {'A3': 0.95, 'A4': 0.05},\n",
    "  '0:4-2': {'A3': 0.05, 'A4': 0.95},\n",
    "  '1:4-2': {'A3': 0.05, 'A4': 0.95},\n",
    "  '0:3-2': {'A3': 0.05, 'A4': 0.95},\n",
    "  '1:3-2': {'A3': 0.05, 'A4': 0.95},\n",
    "  '0:2-2': {'A3': 0.05, 'A4': 0.95},\n",
    "  '1:2-2': {'A3': 0.05, 'A4': 0.95},\n",
    "  '0:4-1': {'A3': 0.05, 'A4': 0.95},\n",
    "  '1:4-1': {'A3': 0.05, 'A4': 0.95},\n",
    "  '0:3-1': {'A3': 0.95, 'A4': 0.05},\n",
    "  '1:3-1': {'A3': 0.95, 'A4': 0.05},\n",
    "  '0:2-1': {'A3': 0.05, 'A4': 0.95},\n",
    "  '1:2-1': {'A3': 0.05, 'A4': 0.95},\n",
    "  '0:1-1': {'A3': 0.95, 'A4': 0.05},\n",
    "  '1:1-1': {'A3': 0.95, 'A4': 0.05}},\n",
    " '4': {'0:4-4': {'A3': 0.05, 'A4': 0.95},\n",
    "  '1:4-4': {'A3': 0.05, 'A4': 0.95},\n",
    "  '0:4-3': {'A3': 0.05, 'A4': 0.95},\n",
    "  '1:4-3': {'A3': 0.05, 'A4': 0.95},\n",
    "  '0:3-3': {'A3': 0.05, 'A4': 0.95},\n",
    "  '1:3-3': {'A3': 0.05, 'A4': 0.95},\n",
    "  '0:4-2': {'A3': 0.05, 'A4': 0.95},\n",
    "  '1:4-2': {'A3': 0.05, 'A4': 0.95},\n",
    "  '0:3-2': {'A3': 0.05, 'A4': 0.95},\n",
    "  '1:3-2': {'A3': 0.05, 'A4': 0.95},\n",
    "  '0:2-2': {'A3': 0.05, 'A4': 0.95},\n",
    "  '1:2-2': {'A3': 0.05, 'A4': 0.95},\n",
    "  '0:4-1': {'A3': 0.05, 'A4': 0.95},\n",
    "  '1:4-1': {'A3': 0.05, 'A4': 0.95},\n",
    "  '0:3-1': {'A3': 0.05, 'A4': 0.95},\n",
    "  '1:3-1': {'A3': 0.05, 'A4': 0.95},\n",
    "  '0:2-1': {'A3': 0.05, 'A4': 0.95},\n",
    "  '1:2-1': {'A3': 0.05, 'A4': 0.95},\n",
    "  '0:1-1': {'A3': 0.05, 'A4': 0.95},\n",
    "  '1:1-1': {'A3': 0.05, 'A4': 0.95}}}\n",
    "fastcore.test.test_eq(strategies, expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\"allowed_sectors\": {\"P1\": [\"S1\", \"S2\"],\n",
    "                              \"P2\": [\"S1\", \"S2\"]},\n",
    "          \"sector_strategies\": {\"S1\": [\"1\", \"2\"],\n",
    "                                \"S2\": [\"3\", \"4\"]},\n",
    "          \"profiles_rule\": \"anonymous\", }\n",
    "action_profiles = create_profiles(models)[\"profiles\"]\n",
    "n_states = 2\n",
    "state_actions = [f\"{state}:{a}\"\n",
    "                 for a in action_profiles\n",
    "                 for state in range(n_states)]\n",
    "strategy_keys = [\"ex1_rich_cooperator\",\n",
    "                 \"ex1_rich_defector\",\n",
    "                 \"ex1_poor_cooperator\",\n",
    "                 \"ex1_poor_defector\",]\n",
    "models = {**models,\n",
    "          \"strategy_keys\": strategy_keys,\n",
    "          \"state_actions\": state_actions}\n",
    "strategies = build_strategies(models)['strategies']\n",
    "expected = {'1': {'0:4-4': {'A1': 0.05, 'A2': 0.95},\n",
    "  '1:4-4': {'A1': 0.05, 'A2': 0.95},\n",
    "  '0:4-3': {'A1': 0.05, 'A2': 0.95},\n",
    "  '1:4-3': {'A1': 0.05, 'A2': 0.95},\n",
    "  '0:3-3': {'A1': 0.95, 'A2': 0.05},\n",
    "  '1:3-3': {'A1': 0.95, 'A2': 0.05},\n",
    "  '0:4-2': {'A1': 0.05, 'A2': 0.95},\n",
    "  '1:4-2': {'A1': 0.05, 'A2': 0.95},\n",
    "  '0:3-2': {'A1': 0.05, 'A2': 0.95},\n",
    "  '1:3-2': {'A1': 0.05, 'A2': 0.95},\n",
    "  '0:2-2': {'A1': 0.05, 'A2': 0.95},\n",
    "  '1:2-2': {'A1': 0.05, 'A2': 0.95},\n",
    "  '0:4-1': {'A1': 0.05, 'A2': 0.95},\n",
    "  '1:4-1': {'A1': 0.05, 'A2': 0.95},\n",
    "  '0:3-1': {'A1': 0.95, 'A2': 0.05},\n",
    "  '1:3-1': {'A1': 0.95, 'A2': 0.05},\n",
    "  '0:2-1': {'A1': 0.05, 'A2': 0.95},\n",
    "  '1:2-1': {'A1': 0.05, 'A2': 0.95},\n",
    "  '0:1-1': {'A1': 0.95, 'A2': 0.05},\n",
    "  '1:1-1': {'A1': 0.95, 'A2': 0.05}},\n",
    " '2': {'0:4-4': {'A1': 0.05, 'A2': 0.95},\n",
    "  '1:4-4': {'A1': 0.05, 'A2': 0.95},\n",
    "  '0:4-3': {'A1': 0.05, 'A2': 0.95},\n",
    "  '1:4-3': {'A1': 0.05, 'A2': 0.95},\n",
    "  '0:3-3': {'A1': 0.05, 'A2': 0.95},\n",
    "  '1:3-3': {'A1': 0.05, 'A2': 0.95},\n",
    "  '0:4-2': {'A1': 0.05, 'A2': 0.95},\n",
    "  '1:4-2': {'A1': 0.05, 'A2': 0.95},\n",
    "  '0:3-2': {'A1': 0.05, 'A2': 0.95},\n",
    "  '1:3-2': {'A1': 0.05, 'A2': 0.95},\n",
    "  '0:2-2': {'A1': 0.05, 'A2': 0.95},\n",
    "  '1:2-2': {'A1': 0.05, 'A2': 0.95},\n",
    "  '0:4-1': {'A1': 0.05, 'A2': 0.95},\n",
    "  '1:4-1': {'A1': 0.05, 'A2': 0.95},\n",
    "  '0:3-1': {'A1': 0.05, 'A2': 0.95},\n",
    "  '1:3-1': {'A1': 0.05, 'A2': 0.95},\n",
    "  '0:2-1': {'A1': 0.05, 'A2': 0.95},\n",
    "  '1:2-1': {'A1': 0.05, 'A2': 0.95},\n",
    "  '0:1-1': {'A1': 0.05, 'A2': 0.95},\n",
    "  '1:1-1': {'A1': 0.05, 'A2': 0.95}},\n",
    " '3': {'0:4-4': {'A3': 0.05, 'A4': 0.95},\n",
    "  '1:4-4': {'A3': 0.05, 'A4': 0.95},\n",
    "  '0:4-3': {'A3': 0.05, 'A4': 0.95},\n",
    "  '1:4-3': {'A3': 0.05, 'A4': 0.95},\n",
    "  '0:3-3': {'A3': 0.95, 'A4': 0.05},\n",
    "  '1:3-3': {'A3': 0.95, 'A4': 0.05},\n",
    "  '0:4-2': {'A3': 0.05, 'A4': 0.95},\n",
    "  '1:4-2': {'A3': 0.05, 'A4': 0.95},\n",
    "  '0:3-2': {'A3': 0.05, 'A4': 0.95},\n",
    "  '1:3-2': {'A3': 0.05, 'A4': 0.95},\n",
    "  '0:2-2': {'A3': 0.05, 'A4': 0.95},\n",
    "  '1:2-2': {'A3': 0.05, 'A4': 0.95},\n",
    "  '0:4-1': {'A3': 0.05, 'A4': 0.95},\n",
    "  '1:4-1': {'A3': 0.05, 'A4': 0.95},\n",
    "  '0:3-1': {'A3': 0.95, 'A4': 0.05},\n",
    "  '1:3-1': {'A3': 0.95, 'A4': 0.05},\n",
    "  '0:2-1': {'A3': 0.05, 'A4': 0.95},\n",
    "  '1:2-1': {'A3': 0.05, 'A4': 0.95},\n",
    "  '0:1-1': {'A3': 0.95, 'A4': 0.05},\n",
    "  '1:1-1': {'A3': 0.95, 'A4': 0.05}},\n",
    " '4': {'0:4-4': {'A3': 0.05, 'A4': 0.95},\n",
    "  '1:4-4': {'A3': 0.05, 'A4': 0.95},\n",
    "  '0:4-3': {'A3': 0.05, 'A4': 0.95},\n",
    "  '1:4-3': {'A3': 0.05, 'A4': 0.95},\n",
    "  '0:3-3': {'A3': 0.05, 'A4': 0.95},\n",
    "  '1:3-3': {'A3': 0.05, 'A4': 0.95},\n",
    "  '0:4-2': {'A3': 0.05, 'A4': 0.95},\n",
    "  '1:4-2': {'A3': 0.05, 'A4': 0.95},\n",
    "  '0:3-2': {'A3': 0.05, 'A4': 0.95},\n",
    "  '1:3-2': {'A3': 0.05, 'A4': 0.95},\n",
    "  '0:2-2': {'A3': 0.05, 'A4': 0.95},\n",
    "  '1:2-2': {'A3': 0.05, 'A4': 0.95},\n",
    "  '0:4-1': {'A3': 0.05, 'A4': 0.95},\n",
    "  '1:4-1': {'A3': 0.05, 'A4': 0.95},\n",
    "  '0:3-1': {'A3': 0.05, 'A4': 0.95},\n",
    "  '1:3-1': {'A3': 0.05, 'A4': 0.95},\n",
    "  '0:2-1': {'A3': 0.05, 'A4': 0.95},\n",
    "  '1:2-1': {'A3': 0.05, 'A4': 0.95},\n",
    "  '0:1-1': {'A3': 0.05, 'A4': 0.95},\n",
    "  '1:1-1': {'A3': 0.05, 'A4': 0.95}}}\n",
    "fastcore.test.test_eq(strategies, expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stochastic payoffs test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\"allowed_sectors\": {\"P1\": [\"S1\", \"S2\"],\n",
    "                              \"P2\": [\"S1\", \"S2\"]},\n",
    "          \"sector_strategies\": {\"S1\": [\"1\", \"2\"],\n",
    "                                \"S2\": [\"3\", \"4\"]},\n",
    "          \"profiles_rule\": \"anonymous\", }\n",
    "action_profiles = create_profiles(models)[\"profiles\"]\n",
    "n_states = 2\n",
    "state_actions = [f\"{state}:{a}\"\n",
    "                 for a in action_profiles\n",
    "                 for state in range(n_states)]\n",
    "\n",
    "strategy_keys = [\"ex1_rich_cooperator\",\n",
    "                 \"ex1_rich_defector\",\n",
    "                 \"ex1_poor_cooperator\",\n",
    "                 \"ex1_poor_defector\",]\n",
    "models = {**models,\n",
    "          \"strategy_keys\": strategy_keys,\n",
    "          \"state_actions\": state_actions}\n",
    "strategies = build_strategies(models)['strategies']\n",
    "strategy_profile = \"1-2-3\"\n",
    "models = {\"payoffs_flow_key\": \"vasconcelos_2014_flow\",\n",
    "          \"payoffs_key\": \"flow_payoffs_wrapper\",\n",
    "          \"state_actions\": state_actions,\n",
    "          \"strategies\": strategies,\n",
    "          \"strategy_profile\": strategy_profile,\n",
    "          'n_states':n_states,\n",
    "          'state_transition_key': 'ex1',\n",
    "          'compute_transition_key': \"anonymous_actions\",\n",
    "          'c': 0.5,\n",
    "          'T': 2,\n",
    "          'b_r': 4,\n",
    "          'b_p': 2,\n",
    "          'r': 0.8,\n",
    "          'g': 2,\n",
    "          }\n",
    "\n",
    "models = build_state_transitions(models)\n",
    "models = build_payoffs(models)\n",
    "models = {**models,\n",
    "          \"payoffs_key\": \"stochastic-no-discounting\"}\n",
    "results = build_payoffs(models)\n",
    "expected = {'1': 1.5979057591623032,\n",
    " '2': 0.7989528795811516,\n",
    " '3': 0.7989528795811516,\n",
    " '4': 0.3994764397905758}\n",
    "for k, v in results['profile_payoffs'].items():\n",
    "    fastcore.test.test_close(v, expected[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'4-4': {'P1': 0.39949999999999986, 'P2': 0.39949999999999986},\n",
       " '4-3': {'P1': 0.7989528795811517, 'P2': 0.39947643979057584},\n",
       " '3-3': {'P1': 0.7899999999999998, 'P2': 0.7899999999999998},\n",
       " '4-2': {'P1': 0.7989999999999997, 'P2': 0.39949999999999986},\n",
       " '3-2': {'P1': 0.7989528795811518, 'P2': 0.7989528795811518},\n",
       " '2-2': {'P1': 0.7989999999999997, 'P2': 0.7989999999999997},\n",
       " '4-1': {'P1': 1.5979057591623036, 'P2': 0.3994764397905759},\n",
       " '3-1': {'P1': 1.5799999999999994, 'P2': 0.7899999999999997},\n",
       " '2-1': {'P1': 1.5979057591623034, 'P2': 0.7989528795811517},\n",
       " '1-1': {'P1': 1.5799999999999994, 'P2': 1.5799999999999994}}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = {\"allowed_sectors\": {\"P1\": [\"S1\", \"S2\"],\n",
    "                              \"P2\": [\"S1\", \"S2\"]},\n",
    "          \"sector_strategies\": {\"S1\": [\"1\", \"2\"],\n",
    "                                \"S2\": [\"3\", \"4\"]},\n",
    "          \"profiles_rule\": \"anonymous\", }\n",
    "action_profiles = create_profiles(models)[\"profiles\"]\n",
    "n_states = 2\n",
    "state_actions = [f\"{state}:{a}\"\n",
    "                 for a in action_profiles\n",
    "                 for state in range(n_states)]\n",
    "\n",
    "strategy_keys = [\"ex1_rich_cooperator\",\n",
    "                 \"ex1_rich_defector\",\n",
    "                 \"ex1_poor_cooperator\",\n",
    "                 \"ex1_poor_defector\",]\n",
    "models = {**models,\n",
    "          \"strategy_keys\": strategy_keys,\n",
    "          \"state_actions\": state_actions}\n",
    "strategies = build_strategies(models)['strategies']\n",
    "strategy_profile = \"1-2-3\"\n",
    "models = {**models,\n",
    "          \"payoffs_flow_key\": \"vasconcelos_2014_flow\",\n",
    "          \"payoffs_key\": \"flow_payoffs_wrapper\",\n",
    "          \"state_actions\": state_actions,\n",
    "          \"strategies\": strategies,\n",
    "          \"strategy_profile\": strategy_profile,\n",
    "          'n_states':n_states,\n",
    "          'state_transition_key': 'ex1',\n",
    "          'compute_transition_key': \"anonymous_actions\",\n",
    "          'c': 0.5,\n",
    "          'T': 2,\n",
    "          'b_r': 4,\n",
    "          'b_p': 2,\n",
    "          'r': 0.8,\n",
    "          'g': 2,\n",
    "          }\n",
    "models = build_state_transitions(models)\n",
    "models = build_payoffs(models)\n",
    "models = {**models,\n",
    "          \"payoffs_key\": \"payoff_function_wrapper\",\n",
    "          \"profile_payoffs_key\": \"stochastic-no-discounting\"}\n",
    "results = build_payoffs(models)\n",
    "results['payoffs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Payoff Matrices (part 3)\n",
    "\n",
    "> This module contains payoff matrices for different evolutionary games\n",
    ">\n",
    "> Part 3 contains payoff matrices for the following games\n",
    "> - Regulatory Markets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "@method(build_payoffs, \"regulatory_markets_v1_reward_before\")\n",
    "def build_payoffs(models):\n",
    "    \"\"\"Regulatory market payoffs when incentives are given in advance and only\n",
    "    taken away if firms act unsafely.\"\"\"\n",
    "    names1 = ['b', 'c', 's', 'p', 'B', 'W']\n",
    "    names2 = ['pfo_l', 'pfo_h', 'λ', 'r_l', 'r_h', 'g']\n",
    "    b, c, s, p, B, W = [models[k] for k in names1]\n",
    "    pfo_l, pfo_h, λ, r_l, r_h, g = [models[k] for k in names2]\n",
    "    collective_risk = models.get('collective_risk', 0)\n",
    "    risk_shared = (1 - (1-p)*collective_risk)\n",
    "    \n",
    "    Π_h11 = B / (2*W) + b/2 - c\n",
    "    Π_h12 = b / (s+1) * (1 - pfo_h) * risk_shared + (b + B / W) * pfo_h - c\n",
    "    Π_h21 = p * ( 1 - pfo_h) * (s*b / (s + 1) + s * B / W)\n",
    "    Π_h22 = p * ( 1 - pfo_h**2) * (b/2 + s*B/(2*W)) * risk_shared\n",
    "    \n",
    "    Π_l11 = B / (2*W) + b/2 - c\n",
    "    Π_l12 = b / (s+1) * (1 - pfo_l) * risk_shared + (b + B / W) * pfo_l - c\n",
    "    Π_l21 = p * ( 1 - pfo_l) * (s*b / (s + 1) + s * B / W)\n",
    "    Π_l22 = p * ( 1 - pfo_l**2) * (b/2 + s*B/(2*W)) * risk_shared\n",
    "    \n",
    "    λ_h = λ * (1 - p) * (1 - pfo_h)\n",
    "    λ_l = λ * (1 - p) * (1 - pfo_l)\n",
    "    \n",
    "    Ω_11 = r_h + g\n",
    "    Ω_12 = r_l + g\n",
    "    Ω_21 = r_h + g * pfo_h**2 - λ_h\n",
    "    Ω_22 = r_l + g * pfo_l**2 - λ_l\n",
    "    Ω_31 = r_h + g\n",
    "    Ω_32 = r_l + g * pfo_l**2 - λ_l\n",
    "    \n",
    "    payoffs = {}\n",
    "    payoffs[\"4-1-1\"] = {\"P3\": Ω_11,\n",
    "                        \"P2\": Π_h11,\n",
    "                        \"P1\": Π_h11}\n",
    "    payoffs[\"4-1-2\"] = {\"P3\": (Ω_11 + Ω_21) / 2,\n",
    "                        \"P2\": Π_h12,\n",
    "                        \"P1\": Π_h21}\n",
    "    payoffs[\"4-1-3\"] = {\"P3\": Ω_11,\n",
    "                        \"P2\": Π_h11,\n",
    "                        \"P1\": Π_h11}\n",
    "    payoffs[\"4-2-1\"] = {\"P3\": (Ω_11 + Ω_21) / 2,\n",
    "                        \"P2\": Π_h21,\n",
    "                        \"P1\": Π_h12}\n",
    "    payoffs[\"4-2-2\"] = {\"P3\": Ω_21,\n",
    "                        \"P2\": Π_h22,\n",
    "                        \"P1\": Π_h22}\n",
    "    payoffs[\"4-2-3\"] = {\"P3\": (Ω_11 + Ω_21) / 2,\n",
    "                        \"P2\": Π_h21,\n",
    "                        \"P1\": Π_h12}\n",
    "    payoffs[\"4-3-1\"] = {\"P3\": Ω_11,\n",
    "                        \"P2\": Π_h11,\n",
    "                        \"P1\": Π_h11}\n",
    "    payoffs[\"4-3-2\"] = {\"P3\": (Ω_11 + Ω_21) / 2,\n",
    "                        \"P2\": Π_h12,\n",
    "                        \"P1\": Π_h21}\n",
    "    payoffs[\"4-3-3\"] = {\"P3\": Ω_31,\n",
    "                        \"P2\": Π_h11,\n",
    "                        \"P1\": Π_h11}\n",
    "    \n",
    "    payoffs[\"5-1-1\"] = {\"P3\": Ω_12,\n",
    "                        \"P2\": Π_l11,\n",
    "                        \"P1\": Π_l11}\n",
    "    payoffs[\"5-1-2\"] = {\"P3\": (Ω_12 + Ω_22) / 2,\n",
    "                        \"P2\": Π_l12,\n",
    "                        \"P1\": Π_l21}\n",
    "    payoffs[\"5-1-3\"] = {\"P3\": (Ω_12 + Ω_22) / 2,\n",
    "                        \"P2\": Π_l12,\n",
    "                        \"P1\": Π_l21}\n",
    "    payoffs[\"5-2-1\"] = {\"P3\": (Ω_12 + Ω_22) / 2,\n",
    "                        \"P2\": Π_l21,\n",
    "                        \"P1\": Π_l12}\n",
    "    payoffs[\"5-2-2\"] = {\"P3\": Ω_22,\n",
    "                        \"P2\": Π_l22,\n",
    "                        \"P1\": Π_l22}\n",
    "    payoffs[\"5-2-3\"] = {\"P3\": Ω_22,\n",
    "                        \"P2\": Π_l22,\n",
    "                        \"P1\": Π_l22}\n",
    "    payoffs[\"5-3-1\"] = {\"P3\": (Ω_12 + Ω_22) / 2,\n",
    "                        \"P2\": Π_l21,\n",
    "                        \"P1\": Π_l12}\n",
    "    payoffs[\"5-3-2\"] = {\"P3\": Ω_22,\n",
    "                        \"P2\": Π_l22,\n",
    "                        \"P1\": Π_l22}\n",
    "    payoffs[\"5-3-3\"] = {\"P3\": Ω_32,\n",
    "                        \"P2\": Π_l22,\n",
    "                        \"P1\": Π_l22}\n",
    "\n",
    "    return {**models, \"payoffs\": payoffs}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "@method(build_payoffs, \"regulatory_markets_v1_reward_after\")\n",
    "def build_payoffs(models):\n",
    "    \"\"\"Regulatory market payoffs when there is only a reward after catching\n",
    "    unsafe firms.\"\"\"\n",
    "    names1 = ['b', 'c', 's', 'p', 'B', 'W']\n",
    "    names2 = ['pfo_l', 'pfo_h', 'λ', 'r_l', 'r_h', 'g']\n",
    "    b, c, s, p, B, W = [models[k] for k in names1]\n",
    "    pfo_l, pfo_h, λ, r_l, r_h, g = [models[k] for k in names2]\n",
    "    collective_risk = models.get('collective_risk', 0)\n",
    "    risk_shared = (1 - (1-p)*collective_risk)\n",
    "    \n",
    "    Π_h11 = B / (2*W) + b/2 - c\n",
    "    Π_h12 = b / (s+1) * (1 - pfo_h) * risk_shared + (b + B / W) * pfo_h - c\n",
    "    Π_h21 = p * ( 1 - pfo_h) * (s*b / (s + 1) + s * B / W)\n",
    "    Π_h22 = p * ( 1 - pfo_h**2) * (b/2 + s*B/(2*W)) * risk_shared\n",
    "    \n",
    "    Π_l11 = B / (2*W) + b/2 - c\n",
    "    Π_l12 = b / (s+1) * (1 - pfo_l) * risk_shared + (b + B / W) * pfo_l - c\n",
    "    Π_l21 = p * ( 1 - pfo_l) * (s*b / (s + 1) + s * B / W)\n",
    "    Π_l22 = p * ( 1 - pfo_l**2) * (b/2 + s*B/(2*W)) * risk_shared\n",
    "    \n",
    "    λ_h = λ * (1 - p) * (1 - pfo_h)\n",
    "    λ_l = λ * (1 - p) * (1 - pfo_l)\n",
    "    \n",
    "    # No ex-ante reward for regulators\n",
    "    Ω_11 = r_h\n",
    "    Ω_12 = r_l\n",
    "    # Expect to catch n*p unsafe firms, where n=2 and p=pfo_h\n",
    "    # They may expect to be penalised if a disaster occurs under their watch\n",
    "    # but by default the penalty λ may be 0.\n",
    "    Ω_21 = r_h + g * 2 * pfo_h - λ_h\n",
    "    Ω_22 = r_l + g * 2 * pfo_l - λ_l\n",
    "    Ω_31 = r_h\n",
    "    Ω_32 = r_l + g * 2 * pfo_l - λ_l\n",
    "    \n",
    "    payoffs = {}\n",
    "    payoffs[\"4-1-1\"] = {\"P3\": Ω_11,\n",
    "                        \"P2\": Π_h11,\n",
    "                        \"P1\": Π_h11}\n",
    "    payoffs[\"4-1-2\"] = {\"P3\": (Ω_11 + Ω_21) / 2,\n",
    "                        \"P2\": Π_h12,\n",
    "                        \"P1\": Π_h21}\n",
    "    payoffs[\"4-1-3\"] = {\"P3\": Ω_11,\n",
    "                        \"P2\": Π_h11,\n",
    "                        \"P1\": Π_h11}\n",
    "    payoffs[\"4-2-1\"] = {\"P3\": (Ω_11 + Ω_21) / 2,\n",
    "                        \"P2\": Π_h21,\n",
    "                        \"P1\": Π_h12}\n",
    "    payoffs[\"4-2-2\"] = {\"P3\": Ω_21,\n",
    "                        \"P2\": Π_h22,\n",
    "                        \"P1\": Π_h22}\n",
    "    payoffs[\"4-2-3\"] = {\"P3\": (Ω_11 + Ω_21) / 2,\n",
    "                        \"P2\": Π_h21,\n",
    "                        \"P1\": Π_h12}\n",
    "    payoffs[\"4-3-1\"] = {\"P3\": Ω_11,\n",
    "                        \"P2\": Π_h11,\n",
    "                        \"P1\": Π_h11}\n",
    "    payoffs[\"4-3-2\"] = {\"P3\": (Ω_11 + Ω_21) / 2,\n",
    "                        \"P2\": Π_h12,\n",
    "                        \"P1\": Π_h21}\n",
    "    payoffs[\"4-3-3\"] = {\"P3\": Ω_31,\n",
    "                        \"P2\": Π_h11,\n",
    "                        \"P1\": Π_h11}\n",
    "    \n",
    "    payoffs[\"5-1-1\"] = {\"P3\": Ω_12,\n",
    "                        \"P2\": Π_l11,\n",
    "                        \"P1\": Π_l11}\n",
    "    payoffs[\"5-1-2\"] = {\"P3\": (Ω_12 + Ω_22) / 2,\n",
    "                        \"P2\": Π_l12,\n",
    "                        \"P1\": Π_l21}\n",
    "    payoffs[\"5-1-3\"] = {\"P3\": (Ω_12 + Ω_22) / 2,\n",
    "                        \"P2\": Π_l12,\n",
    "                        \"P1\": Π_l21}\n",
    "    payoffs[\"5-2-1\"] = {\"P3\": (Ω_12 + Ω_22) / 2,\n",
    "                        \"P2\": Π_l21,\n",
    "                        \"P1\": Π_l12}\n",
    "    payoffs[\"5-2-2\"] = {\"P3\": Ω_22,\n",
    "                        \"P2\": Π_l22,\n",
    "                        \"P1\": Π_l22}\n",
    "    payoffs[\"5-2-3\"] = {\"P3\": Ω_22,\n",
    "                        \"P2\": Π_l22,\n",
    "                        \"P1\": Π_l22}\n",
    "    payoffs[\"5-3-1\"] = {\"P3\": (Ω_12 + Ω_22) / 2,\n",
    "                        \"P2\": Π_l21,\n",
    "                        \"P1\": Π_l12}\n",
    "    payoffs[\"5-3-2\"] = {\"P3\": Ω_22,\n",
    "                        \"P2\": Π_l22,\n",
    "                        \"P1\": Π_l22}\n",
    "    payoffs[\"5-3-3\"] = {\"P3\": Ω_32,\n",
    "                        \"P2\": Π_l22,\n",
    "                        \"P1\": Π_l22}\n",
    "\n",
    "    return {**models, \"payoffs\": payoffs}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "@method(build_payoffs, \"regulatory_markets_v1a_reward_after\")\n",
    "def build_payoffs(models):\n",
    "    \"\"\"An alternative payoff scheme for regulatory markets which more closely\n",
    "    matches the DSAIR model\"\"\"\n",
    "    names1 = ['b', 'c', 's', 'p', 'B', 'W']\n",
    "    names2 = ['pfo_l', 'pfo_h', 'λ', 'r_l', 'r_h', 'g']\n",
    "    b, c, s, p, B, W = [models[k] for k in names1]\n",
    "    pfo_l, pfo_h, λ, r_l, r_h, g = [models[k] for k in names2]\n",
    "    collective_risk = models.get('collective_risk', 0)\n",
    "    risk_shared = (1 - (1-p)*collective_risk)\n",
    "    \n",
    "    Π_h11 = B / (2*W) + b/2 - c\n",
    "    Π_h12 = b / (s+1) * (1 - pfo_h) * risk_shared + (b) * pfo_h - c\n",
    "    Π_h21 = p * (s*b / (s + 1)  * ( 1 - pfo_h) + s * B / W)\n",
    "    Π_h22 = p * (b/2 * ( 1 - pfo_h**2) + s*B/(2*W)) * risk_shared\n",
    "    \n",
    "    Π_l11 = B / (2*W) + b/2 - c\n",
    "    Π_l12 = b / (s+1) * (1 - pfo_l) * risk_shared + (b) * pfo_l - c\n",
    "    Π_l21 = p * (s*b / (s + 1) * ( 1 - pfo_l) + s * B / W)\n",
    "    Π_l22 = p * (b/2 * ( 1 - pfo_l**2) + s*B/(2*W)) * risk_shared\n",
    "    \n",
    "    λ_h = λ * (1 - p) * (1 - pfo_h)\n",
    "    λ_l = λ * (1 - p) * (1 - pfo_l)\n",
    "    \n",
    "    # No ex-ante reward for regulators\n",
    "    Ω_11 = r_h\n",
    "    Ω_12 = r_l\n",
    "    # Expect to catch n*p unsafe firms, where n=2 and p=pfo_h\n",
    "    # They may expect to be penalised if a disaster occurs under their watch\n",
    "    # but by default the penalty λ may be 0.\n",
    "    Ω_21 = r_h + g * 2 * pfo_h - λ_h\n",
    "    Ω_22 = r_l + g * 2 * pfo_l - λ_l\n",
    "    Ω_31 = r_h\n",
    "    Ω_32 = r_l + g * 2 * pfo_l - λ_l\n",
    "    \n",
    "    payoffs = {}\n",
    "    payoffs[\"4-1-1\"] = {\"P3\": Ω_11,\n",
    "                        \"P2\": Π_h11,\n",
    "                        \"P1\": Π_h11}\n",
    "    payoffs[\"4-1-2\"] = {\"P3\": (Ω_11 + Ω_21) / 2,\n",
    "                        \"P2\": Π_h12,\n",
    "                        \"P1\": Π_h21}\n",
    "    payoffs[\"4-1-3\"] = {\"P3\": Ω_11,\n",
    "                        \"P2\": Π_h11,\n",
    "                        \"P1\": Π_h11}\n",
    "    payoffs[\"4-2-1\"] = {\"P3\": (Ω_11 + Ω_21) / 2,\n",
    "                        \"P2\": Π_h21,\n",
    "                        \"P1\": Π_h12}\n",
    "    payoffs[\"4-2-2\"] = {\"P3\": Ω_21,\n",
    "                        \"P2\": Π_h22,\n",
    "                        \"P1\": Π_h22}\n",
    "    payoffs[\"4-2-3\"] = {\"P3\": (Ω_11 + Ω_21) / 2,\n",
    "                        \"P2\": Π_h21,\n",
    "                        \"P1\": Π_h12}\n",
    "    payoffs[\"4-3-1\"] = {\"P3\": Ω_11,\n",
    "                        \"P2\": Π_h11,\n",
    "                        \"P1\": Π_h11}\n",
    "    payoffs[\"4-3-2\"] = {\"P3\": (Ω_11 + Ω_21) / 2,\n",
    "                        \"P2\": Π_h12,\n",
    "                        \"P1\": Π_h21}\n",
    "    payoffs[\"4-3-3\"] = {\"P3\": Ω_31,\n",
    "                        \"P2\": Π_h11,\n",
    "                        \"P1\": Π_h11}\n",
    "    \n",
    "    payoffs[\"5-1-1\"] = {\"P3\": Ω_12,\n",
    "                        \"P2\": Π_l11,\n",
    "                        \"P1\": Π_l11}\n",
    "    payoffs[\"5-1-2\"] = {\"P3\": (Ω_12 + Ω_22) / 2,\n",
    "                        \"P2\": Π_l12,\n",
    "                        \"P1\": Π_l21}\n",
    "    payoffs[\"5-1-3\"] = {\"P3\": (Ω_12 + Ω_22) / 2,\n",
    "                        \"P2\": Π_l12,\n",
    "                        \"P1\": Π_l21}\n",
    "    payoffs[\"5-2-1\"] = {\"P3\": (Ω_12 + Ω_22) / 2,\n",
    "                        \"P2\": Π_l21,\n",
    "                        \"P1\": Π_l12}\n",
    "    payoffs[\"5-2-2\"] = {\"P3\": Ω_22,\n",
    "                        \"P2\": Π_l22,\n",
    "                        \"P1\": Π_l22}\n",
    "    payoffs[\"5-2-3\"] = {\"P3\": Ω_22,\n",
    "                        \"P2\": Π_l22,\n",
    "                        \"P1\": Π_l22}\n",
    "    payoffs[\"5-3-1\"] = {\"P3\": (Ω_12 + Ω_22) / 2,\n",
    "                        \"P2\": Π_l21,\n",
    "                        \"P1\": Π_l12}\n",
    "    payoffs[\"5-3-2\"] = {\"P3\": Ω_22,\n",
    "                        \"P2\": Π_l22,\n",
    "                        \"P1\": Π_l22}\n",
    "    payoffs[\"5-3-3\"] = {\"P3\": Ω_32,\n",
    "                        \"P2\": Π_l22,\n",
    "                        \"P1\": Π_l22}\n",
    "\n",
    "    return {**models, \"payoffs\": payoffs}\n",
    "\n",
    "\n",
    "# | export\n",
    "@method(build_payoffs, \"regulatory_markets_v1a_reward_before\")\n",
    "def build_payoffs(models):\n",
    "    \"\"\"Regulatory market payoffs when incentives are given in advance and only\n",
    "    taken away if firms act unsafely.\"\"\"\n",
    "    names1 = ['b', 'c', 's', 'p', 'B', 'W']\n",
    "    names2 = ['pfo_l', 'pfo_h', 'λ', 'r_l', 'r_h', 'g']\n",
    "    b, c, s, p, B, W = [models[k] for k in names1]\n",
    "    pfo_l, pfo_h, λ, r_l, r_h, g = [models[k] for k in names2]\n",
    "    collective_risk = models.get('collective_risk', 0)\n",
    "    risk_shared = (1 - (1-p)*collective_risk)\n",
    "    \n",
    "    Π_h11 = B / (2*W) + b/2 - c\n",
    "    Π_h12 = b / (s+1) * (1 - pfo_h) * risk_shared + (b) * pfo_h - c\n",
    "    Π_h21 = p * (s*b / (s + 1)  * ( 1 - pfo_h) + s * B / W)\n",
    "    Π_h22 = p * (b/2 * ( 1 - pfo_h**2) + s*B/(2*W)) * risk_shared\n",
    "    \n",
    "    Π_l11 = B / (2*W) + b/2 - c\n",
    "    Π_l12 = b / (s+1) * (1 - pfo_l) * risk_shared + (b) * pfo_l - c\n",
    "    Π_l21 = p * (s*b / (s + 1) * ( 1 - pfo_l) + s * B / W)\n",
    "    Π_l22 = p * (b/2 * ( 1 - pfo_l**2) + s*B/(2*W)) * risk_shared\n",
    "    \n",
    "    λ_h = λ * (1 - p) * (1 - pfo_h)\n",
    "    λ_l = λ * (1 - p) * (1 - pfo_l)\n",
    "    \n",
    "    Ω_11 = r_h + g\n",
    "    Ω_12 = r_l + g\n",
    "    Ω_21 = r_h + g * pfo_h**2 - λ_h\n",
    "    Ω_22 = r_l + g * pfo_l**2 - λ_l\n",
    "    Ω_31 = r_h + g\n",
    "    Ω_32 = r_l + g * pfo_l**2 - λ_l\n",
    "    \n",
    "    payoffs = {}\n",
    "    payoffs[\"4-1-1\"] = {\"P3\": Ω_11,\n",
    "                        \"P2\": Π_h11,\n",
    "                        \"P1\": Π_h11}\n",
    "    payoffs[\"4-1-2\"] = {\"P3\": (Ω_11 + Ω_21) / 2,\n",
    "                        \"P2\": Π_h12,\n",
    "                        \"P1\": Π_h21}\n",
    "    payoffs[\"4-1-3\"] = {\"P3\": Ω_11,\n",
    "                        \"P2\": Π_h11,\n",
    "                        \"P1\": Π_h11}\n",
    "    payoffs[\"4-2-1\"] = {\"P3\": (Ω_11 + Ω_21) / 2,\n",
    "                        \"P2\": Π_h21,\n",
    "                        \"P1\": Π_h12}\n",
    "    payoffs[\"4-2-2\"] = {\"P3\": Ω_21,\n",
    "                        \"P2\": Π_h22,\n",
    "                        \"P1\": Π_h22}\n",
    "    payoffs[\"4-2-3\"] = {\"P3\": (Ω_11 + Ω_21) / 2,\n",
    "                        \"P2\": Π_h21,\n",
    "                        \"P1\": Π_h12}\n",
    "    payoffs[\"4-3-1\"] = {\"P3\": Ω_11,\n",
    "                        \"P2\": Π_h11,\n",
    "                        \"P1\": Π_h11}\n",
    "    payoffs[\"4-3-2\"] = {\"P3\": (Ω_11 + Ω_21) / 2,\n",
    "                        \"P2\": Π_h12,\n",
    "                        \"P1\": Π_h21}\n",
    "    payoffs[\"4-3-3\"] = {\"P3\": Ω_31,\n",
    "                        \"P2\": Π_h11,\n",
    "                        \"P1\": Π_h11}\n",
    "    \n",
    "    payoffs[\"5-1-1\"] = {\"P3\": Ω_12,\n",
    "                        \"P2\": Π_l11,\n",
    "                        \"P1\": Π_l11}\n",
    "    payoffs[\"5-1-2\"] = {\"P3\": (Ω_12 + Ω_22) / 2,\n",
    "                        \"P2\": Π_l12,\n",
    "                        \"P1\": Π_l21}\n",
    "    payoffs[\"5-1-3\"] = {\"P3\": (Ω_12 + Ω_22) / 2,\n",
    "                        \"P2\": Π_l12,\n",
    "                        \"P1\": Π_l21}\n",
    "    payoffs[\"5-2-1\"] = {\"P3\": (Ω_12 + Ω_22) / 2,\n",
    "                        \"P2\": Π_l21,\n",
    "                        \"P1\": Π_l12}\n",
    "    payoffs[\"5-2-2\"] = {\"P3\": Ω_22,\n",
    "                        \"P2\": Π_l22,\n",
    "                        \"P1\": Π_l22}\n",
    "    payoffs[\"5-2-3\"] = {\"P3\": Ω_22,\n",
    "                        \"P2\": Π_l22,\n",
    "                        \"P1\": Π_l22}\n",
    "    payoffs[\"5-3-1\"] = {\"P3\": (Ω_12 + Ω_22) / 2,\n",
    "                        \"P2\": Π_l21,\n",
    "                        \"P1\": Π_l12}\n",
    "    payoffs[\"5-3-2\"] = {\"P3\": Ω_22,\n",
    "                        \"P2\": Π_l22,\n",
    "                        \"P1\": Π_l22}\n",
    "    payoffs[\"5-3-3\"] = {\"P3\": Ω_32,\n",
    "                        \"P2\": Π_l22,\n",
    "                        \"P1\": Π_l22}\n",
    "\n",
    "    return {**models, \"payoffs\": payoffs}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "@method(build_payoffs, \"regulatory_markets_v1_reward_mixed\")\n",
    "def build_payoffs(models):\n",
    "    \"\"\"Regulatory market payoffs when there is only a reward after catching\n",
    "    unsafe firms.\"\"\"\n",
    "    names1 = ['b', 'c', 's', 'p', 'B', 'W']\n",
    "    names2 = ['pfo_l', 'pfo_h', 'λ', 'r_l', 'r_h', 'g']\n",
    "    b, c, s, p, B, W = [models[k] for k in names1]\n",
    "    pfo_l, pfo_h, λ, r_l, r_h, g = [models[k] for k in names2]\n",
    "    collective_risk = models.get('collective_risk', 0)\n",
    "    risk_shared = (1 - (1-p)*collective_risk)\n",
    "    mix = models.get('incentive_mix', 0)\n",
    "    \n",
    "    Π_h11 = B / (2*W) + b/2 - c\n",
    "    Π_h12 = b / (s+1) * (1 - pfo_h) * risk_shared + (b + B / W) * pfo_h - c\n",
    "    Π_h21 = p * ( 1 - pfo_h) * (s*b / (s + 1) + s * B / W)\n",
    "    Π_h22 = p * ( 1 - pfo_h**2) * (b/2 + s*B/(2*W)) * risk_shared\n",
    "    \n",
    "    Π_l11 = B / (2*W) + b/2 - c\n",
    "    Π_l12 = b / (s+1) * (1 - pfo_l) * risk_shared + (b + B / W) * pfo_l - c\n",
    "    Π_l21 = p * ( 1 - pfo_l) * (s*b / (s + 1) + s * B / W)\n",
    "    Π_l22 = p * ( 1 - pfo_l**2) * (b/2 + s*B/(2*W)) * risk_shared\n",
    "    \n",
    "    λ_h = λ * (1 - p) * (1 - pfo_h)\n",
    "    λ_l = λ * (1 - p) * (1 - pfo_l)\n",
    "    \n",
    "    Ω_11 = r_h + g * mix\n",
    "    Ω_12 = r_l + g * mix\n",
    "    Ω_21 = r_h + g * (pfo_h**2 * mix + pfo_h * (1 - mix)) - λ_h\n",
    "    Ω_22 = r_l + g * (pfo_l**2 * mix + pfo_l * (1 - mix)) - λ_l\n",
    "    Ω_31 = r_h + g * mix\n",
    "    Ω_32 = r_l + g * (pfo_l**2 * mix + pfo_l * (1 - mix)) - λ_l\n",
    "    \n",
    "    payoffs = {}\n",
    "    payoffs[\"4-1-1\"] = {\"P3\": Ω_11,\n",
    "                        \"P2\": Π_h11,\n",
    "                        \"P1\": Π_h11}\n",
    "    payoffs[\"4-1-2\"] = {\"P3\": (Ω_11 + Ω_21) / 2,\n",
    "                        \"P2\": Π_h12,\n",
    "                        \"P1\": Π_h21}\n",
    "    payoffs[\"4-1-3\"] = {\"P3\": Ω_11,\n",
    "                        \"P2\": Π_h11,\n",
    "                        \"P1\": Π_h11}\n",
    "    payoffs[\"4-2-1\"] = {\"P3\": (Ω_11 + Ω_21) / 2,\n",
    "                        \"P2\": Π_h21,\n",
    "                        \"P1\": Π_h12}\n",
    "    payoffs[\"4-2-2\"] = {\"P3\": Ω_21,\n",
    "                        \"P2\": Π_h22,\n",
    "                        \"P1\": Π_h22}\n",
    "    payoffs[\"4-2-3\"] = {\"P3\": (Ω_11 + Ω_21) / 2,\n",
    "                        \"P2\": Π_h21,\n",
    "                        \"P1\": Π_h12}\n",
    "    payoffs[\"4-3-1\"] = {\"P3\": Ω_11,\n",
    "                        \"P2\": Π_h11,\n",
    "                        \"P1\": Π_h11}\n",
    "    payoffs[\"4-3-2\"] = {\"P3\": (Ω_11 + Ω_21) / 2,\n",
    "                        \"P2\": Π_h12,\n",
    "                        \"P1\": Π_h21}\n",
    "    payoffs[\"4-3-3\"] = {\"P3\": Ω_31,\n",
    "                        \"P2\": Π_h11,\n",
    "                        \"P1\": Π_h11}\n",
    "    \n",
    "    payoffs[\"5-1-1\"] = {\"P3\": Ω_12,\n",
    "                        \"P2\": Π_l11,\n",
    "                        \"P1\": Π_l11}\n",
    "    payoffs[\"5-1-2\"] = {\"P3\": (Ω_12 + Ω_22) / 2,\n",
    "                        \"P2\": Π_l12,\n",
    "                        \"P1\": Π_l21}\n",
    "    payoffs[\"5-1-3\"] = {\"P3\": (Ω_12 + Ω_22) / 2,\n",
    "                        \"P2\": Π_l12,\n",
    "                        \"P1\": Π_l21}\n",
    "    payoffs[\"5-2-1\"] = {\"P3\": (Ω_12 + Ω_22) / 2,\n",
    "                        \"P2\": Π_l21,\n",
    "                        \"P1\": Π_l12}\n",
    "    payoffs[\"5-2-2\"] = {\"P3\": Ω_22,\n",
    "                        \"P2\": Π_l22,\n",
    "                        \"P1\": Π_l22}\n",
    "    payoffs[\"5-2-3\"] = {\"P3\": Ω_22,\n",
    "                        \"P2\": Π_l22,\n",
    "                        \"P1\": Π_l22}\n",
    "    payoffs[\"5-3-1\"] = {\"P3\": (Ω_12 + Ω_22) / 2,\n",
    "                        \"P2\": Π_l21,\n",
    "                        \"P1\": Π_l12}\n",
    "    payoffs[\"5-3-2\"] = {\"P3\": Ω_22,\n",
    "                        \"P2\": Π_l22,\n",
    "                        \"P1\": Π_l22}\n",
    "    payoffs[\"5-3-3\"] = {\"P3\": Ω_32,\n",
    "                        \"P2\": Π_l22,\n",
    "                        \"P1\": Π_l22}\n",
    "\n",
    "    return {**models, \"payoffs\": payoffs}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "@multi\n",
    "def compute_game_welfare(models):\n",
    "    \"Compute the welfare generated by the game in each state.\"\n",
    "    return models.get('game_welfare_rule')\n",
    "\n",
    "@method(compute_game_welfare, \"regulatory_markets_v1_reward_before\")\n",
    "def compute_game_welfare(models):\n",
    "    \"Compute the welfare generated by the game in each state.\"\n",
    "    names = ['payoffs', 'ergodic']\n",
    "    payoffs, ergodic = [models[k] for k in names]\n",
    "    p, g, pfo_h, pfo_l = [models[k] for k in ['p', 'g', 'pfo_h', 'pfo_l']]\n",
    "    consumer_surplus = models.get('consumer_surplus', 0)\n",
    "    externality = models.get('externality', 0)\n",
    "\n",
    "    company_payoffs_safe_hq = payoffs['4-1-1'][\"P1\"] + payoffs['4-1-1'][\"P2\"]\n",
    "    company_payoffs_safe_lq = payoffs['5-1-1'][\"P1\"] + payoffs['5-1-1'][\"P2\"]\n",
    "    company_payoffs_unsafe_hq = payoffs['4-2-2'][\"P1\"] + payoffs['4-2-2'][\"P2\"]\n",
    "    company_payoffs_unsafe_lq = payoffs['5-2-2'][\"P1\"] + payoffs['5-2-2'][\"P2\"]\n",
    "    company_payoffs_vetted_hq = payoffs['4-3-3'][\"P1\"] + payoffs['4-3-3'][\"P2\"]\n",
    "    company_payoffs_vetted_lq = payoffs['5-3-3'][\"P1\"] + payoffs['5-3-3'][\"P2\"]\n",
    "\n",
    "    welfare_safe_hq = (company_payoffs_safe_hq * (1 + consumer_surplus)\n",
    "                       - g)\n",
    "    welfare_unsafe_hq = (company_payoffs_unsafe_hq * (1 + consumer_surplus)\n",
    "                         - (1-p)*externality\n",
    "                         - g * pfo_h**2)\n",
    "    welfare_vetted_hq = (company_payoffs_vetted_hq * (1 + consumer_surplus)\n",
    "                         - g)\n",
    "    welfare_safe_lq = (company_payoffs_safe_lq * (1 + consumer_surplus)\n",
    "                       - g)\n",
    "    welfare_unsafe_lq = (company_payoffs_unsafe_lq * (1 + consumer_surplus)\n",
    "                       - (1-p)*externality\n",
    "                       - g * pfo_l**2)\n",
    "    welfare_vetted_lq = (company_payoffs_vetted_lq * (1 + consumer_surplus)\n",
    "                       - (1-p)*externality\n",
    "                       - g * pfo_l**2)\n",
    "    welfares = [welfare_safe_hq,\n",
    "                welfare_unsafe_hq,\n",
    "                welfare_vetted_hq,\n",
    "                welfare_safe_lq,\n",
    "                welfare_unsafe_lq,\n",
    "                welfare_vetted_lq]\n",
    "    game_welfare = np.sum([welfare * state_frequency\n",
    "                           for welfare, state_frequency in zip(welfares,\n",
    "                                                               ergodic.T)],\n",
    "                          axis=0)\n",
    "    return {**models, \"game_welfare\": game_welfare}\n",
    "\n",
    "@method(compute_game_welfare, \"regulatory_markets_v1_reward_after\")\n",
    "def compute_game_welfare(models):\n",
    "    \"Compute the welfare generated by the game in each state.\"\n",
    "    names = ['payoffs', 'ergodic']\n",
    "    payoffs, ergodic = [models[k] for k in names]\n",
    "    p, g, pfo_h, pfo_l = [models[k] for k in ['p', 'g', 'pfo_h', 'pfo_l']]\n",
    "    consumer_surplus = models.get('consumer_surplus', 0)\n",
    "    externality = models.get('externality', 0)\n",
    "\n",
    "    company_payoffs_safe_hq = payoffs['4-1-1'][\"P1\"] + payoffs['4-1-1'][\"P2\"]\n",
    "    company_payoffs_safe_lq = payoffs['5-1-1'][\"P1\"] + payoffs['5-1-1'][\"P2\"]\n",
    "    company_payoffs_unsafe_hq = payoffs['4-2-2'][\"P1\"] + payoffs['4-2-2'][\"P2\"]\n",
    "    company_payoffs_unsafe_lq = payoffs['5-2-2'][\"P1\"] + payoffs['5-2-2'][\"P2\"]\n",
    "    company_payoffs_vetted_hq = payoffs['4-3-3'][\"P1\"] + payoffs['4-3-3'][\"P2\"]\n",
    "    company_payoffs_vetted_lq = payoffs['5-3-3'][\"P1\"] + payoffs['5-3-3'][\"P2\"]\n",
    "\n",
    "    welfare_safe_hq = (company_payoffs_safe_hq * (1 + consumer_surplus))\n",
    "    welfare_unsafe_hq = (company_payoffs_unsafe_hq * (1 + consumer_surplus)\n",
    "                         - (1-p)*externality\n",
    "                         - g * pfo_h)\n",
    "    welfare_vetted_hq = (company_payoffs_vetted_hq * (1 + consumer_surplus))\n",
    "    welfare_safe_lq = (company_payoffs_safe_lq * (1 + consumer_surplus))\n",
    "    welfare_unsafe_lq = (company_payoffs_unsafe_lq * (1 + consumer_surplus)\n",
    "                         - (1-p)*externality\n",
    "                         - g * pfo_l)\n",
    "    welfare_vetted_lq = (company_payoffs_vetted_lq * (1 + consumer_surplus)\n",
    "                         - (1-p)*externality\n",
    "                         - g * pfo_l)\n",
    "    welfares = [welfare_safe_hq,\n",
    "                welfare_unsafe_hq,\n",
    "                welfare_vetted_hq,\n",
    "                welfare_safe_lq,\n",
    "                welfare_unsafe_lq,\n",
    "                welfare_vetted_lq]\n",
    "    game_welfare = np.sum([welfare * state_frequency\n",
    "                           for welfare, state_frequency in zip(welfares,\n",
    "                                                               ergodic.T)],\n",
    "                          axis=0)\n",
    "    return {**models, \"game_welfare\": game_welfare}\n",
    "\n",
    "@method(compute_game_welfare, \"regulatory_markets_v1_reward_mixed\")\n",
    "def compute_game_welfare(models):\n",
    "    \"Compute the welfare generated by the game in each state.\"\n",
    "    names = ['payoffs', 'ergodic']\n",
    "    payoffs, ergodic = [models[k] for k in names]\n",
    "    p, g, pfo_h, pfo_l = [models[k] for k in ['p', 'g', 'pfo_h', 'pfo_l']]\n",
    "    consumer_surplus = models.get('consumer_surplus', 0)\n",
    "    externality = models.get('externality', 0)\n",
    "    mix = models['incentive_mix']\n",
    "\n",
    "    company_payoffs_safe_hq = payoffs['4-1-1'][\"P1\"] + payoffs['4-1-1'][\"P2\"]\n",
    "    company_payoffs_safe_lq = payoffs['5-1-1'][\"P1\"] + payoffs['5-1-1'][\"P2\"]\n",
    "    company_payoffs_unsafe_hq = payoffs['4-2-2'][\"P1\"] + payoffs['4-2-2'][\"P2\"]\n",
    "    company_payoffs_unsafe_lq = payoffs['5-2-2'][\"P1\"] + payoffs['5-2-2'][\"P2\"]\n",
    "    company_payoffs_vetted_hq = payoffs['4-3-3'][\"P1\"] + payoffs['4-3-3'][\"P2\"]\n",
    "    company_payoffs_vetted_lq = payoffs['5-3-3'][\"P1\"] + payoffs['5-3-3'][\"P2\"]\n",
    "\n",
    "    welfare_safe_hq = (company_payoffs_safe_hq * (1 + consumer_surplus)\n",
    "                       - g * mix)\n",
    "    welfare_unsafe_hq = (company_payoffs_unsafe_hq * (1 + consumer_surplus)\n",
    "                         - (1-p) * (1 - pfo_h**2) * externality\n",
    "                         - g * (mix * pfo_h**2 * + (1 - mix) * pfo_h))\n",
    "    welfare_vetted_hq = (company_payoffs_vetted_hq * (1 + consumer_surplus)\n",
    "                         - g * mix)\n",
    "    welfare_unsafe_lq = (company_payoffs_unsafe_lq * (1 + consumer_surplus)\n",
    "                         - (1-p) * (1 - pfo_l**2) * externality\n",
    "                         - g * (mix * pfo_l**2 * + (1 - mix) * pfo_l))\n",
    "    welfare_safe_lq = (company_payoffs_safe_lq * (1 + consumer_surplus)\n",
    "                       - g * mix)\n",
    "    welfare_vetted_lq = (company_payoffs_vetted_lq * (1 + consumer_surplus)\n",
    "                         - (1-p) * (1 - pfo_l**2) * externality\n",
    "                         - g * (mix * pfo_l**2 * + (1 - mix) * pfo_l))\n",
    "    welfares = [welfare_safe_hq,\n",
    "                welfare_unsafe_hq,\n",
    "                welfare_vetted_hq,\n",
    "                welfare_safe_lq,\n",
    "                welfare_unsafe_lq,\n",
    "                welfare_vetted_lq]\n",
    "    game_welfare = np.sum([welfare * state_frequency\n",
    "                           for welfare, state_frequency in zip(welfares,\n",
    "                                                               ergodic.T)],\n",
    "                          axis=0)\n",
    "    return {**models, \"game_welfare\": game_welfare}\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "@method(build_payoffs, \"regulatory_markets_v2_reward_mixed\")\n",
    "def build_payoffs(models):\n",
    "    \"\"\"Regulatory market payoffs when there is only a reward after catching\n",
    "    unsafe firms.\"\"\"\n",
    "    names1 = ['b', 'c', 's', 'p', 'B', 'W']\n",
    "    names2 = ['pfo_l', 'pfo_h', 'λ', 'r_l', 'r_h', 'g']\n",
    "    b, c, s, p, B, W = [models[k] for k in names1]\n",
    "    pfo_l, pfo_h, λ, r_l, r_h, g = [models[k] for k in names2]\n",
    "    collective_risk = models.get('collective_risk', 0)\n",
    "    risk_shared = (1 - (1-p)*collective_risk)\n",
    "    mix = models.get('incentive_mix', 0)\n",
    "    \n",
    "    k = models.get('decisiveness', 100)\n",
    "    phi_h = models.get('phi_h', (1 - pfo_h))\n",
    "    phi_l = models.get('phi_l', (1 - pfo_l))\n",
    "    caught_loses_h = ((s * phi_h)**k + 1)**(-1)\n",
    "    caught_loses_l = ((s * phi_l)**k + 1)**(-1)\n",
    "    \n",
    "    Π_h11 = B / (2*W) + b/2 - c\n",
    "    Π_h12 = ((1 - pfo_h) * b / (s+1) * risk_shared\n",
    "             + pfo_h * caught_loses_h * (b + B / W)\n",
    "             - c)\n",
    "    Π_h21 = (p * (1 - pfo_h) * (s*b / (s + 1) + s * B / W)\n",
    "             + pfo_h * (1 - caught_loses_h) * B / W)\n",
    "    Π_h22 = p * ( 1 - pfo_h**2) * (b/2 + s*B/(2*W)) * risk_shared\n",
    "    Π_h22 = (p * (1 - pfo_h**2) * (b/2 + s*B/(2*W)) * risk_shared\n",
    "             + pfo_h**2 * B/(2*W))\n",
    "    \n",
    "    Π_l11 = B / (2*W) + b/2 - c\n",
    "    Π_l12 = ((1 - pfo_l) * b / (s+1) * risk_shared\n",
    "             + pfo_l * caught_loses_l * (b + B / W)\n",
    "             - c)\n",
    "    Π_l21 = (p * (1 - pfo_l) * (s*b / (s + 1)  + s * B / W)\n",
    "                 + pfo_l * (1 - caught_loses_l) * B / W)\n",
    "    Π_l22 = p * ( 1 - pfo_l**2) * (b/2 + s*B/(2*W)) * risk_shared\n",
    "    Π_l22 = (p * ( 1 - pfo_l**2) * (b/2 + s*B/(2*W)) * risk_shared\n",
    "             + pfo_l**2 * B/(2*W))\n",
    "    \n",
    "    λ_h = λ * (1 - p) * (1 - pfo_h)\n",
    "    λ_l = λ * (1 - p) * (1 - pfo_l)\n",
    "    \n",
    "    Ω_11 = r_h + g * mix\n",
    "    Ω_12 = r_l + g * mix\n",
    "    Ω_21 = r_h + g * (pfo_h**2 * mix + pfo_h * (1 - mix)) - λ_h\n",
    "    Ω_22 = r_l + g * (pfo_l**2 * mix + pfo_l * (1 - mix)) - λ_l\n",
    "    Ω_31 = r_h + g * mix\n",
    "    Ω_32 = r_l + g * (pfo_l**2 * mix + pfo_l * (1 - mix)) - λ_l\n",
    "    \n",
    "    payoffs = {}\n",
    "    payoffs[\"4-1-1\"] = {\"P3\": Ω_11,\n",
    "                        \"P2\": Π_h11,\n",
    "                        \"P1\": Π_h11}\n",
    "    payoffs[\"4-1-2\"] = {\"P3\": (Ω_11 + Ω_21) / 2,\n",
    "                        \"P2\": Π_h12,\n",
    "                        \"P1\": Π_h21}\n",
    "    payoffs[\"4-1-3\"] = {\"P3\": Ω_11,\n",
    "                        \"P2\": Π_h11,\n",
    "                        \"P1\": Π_h11}\n",
    "    payoffs[\"4-2-1\"] = {\"P3\": (Ω_11 + Ω_21) / 2,\n",
    "                        \"P2\": Π_h21,\n",
    "                        \"P1\": Π_h12}\n",
    "    payoffs[\"4-2-2\"] = {\"P3\": Ω_21,\n",
    "                        \"P2\": Π_h22,\n",
    "                        \"P1\": Π_h22}\n",
    "    payoffs[\"4-2-3\"] = {\"P3\": (Ω_11 + Ω_21) / 2,\n",
    "                        \"P2\": Π_h21,\n",
    "                        \"P1\": Π_h12}\n",
    "    payoffs[\"4-3-1\"] = {\"P3\": Ω_11,\n",
    "                        \"P2\": Π_h11,\n",
    "                        \"P1\": Π_h11}\n",
    "    payoffs[\"4-3-2\"] = {\"P3\": (Ω_11 + Ω_21) / 2,\n",
    "                        \"P2\": Π_h12,\n",
    "                        \"P1\": Π_h21}\n",
    "    payoffs[\"4-3-3\"] = {\"P3\": Ω_31,\n",
    "                        \"P2\": Π_h11,\n",
    "                        \"P1\": Π_h11}\n",
    "    \n",
    "    payoffs[\"5-1-1\"] = {\"P3\": Ω_12,\n",
    "                        \"P2\": Π_l11,\n",
    "                        \"P1\": Π_l11}\n",
    "    payoffs[\"5-1-2\"] = {\"P3\": (Ω_12 + Ω_22) / 2,\n",
    "                        \"P2\": Π_l12,\n",
    "                        \"P1\": Π_l21}\n",
    "    payoffs[\"5-1-3\"] = {\"P3\": (Ω_12 + Ω_22) / 2,\n",
    "                        \"P2\": Π_l12,\n",
    "                        \"P1\": Π_l21}\n",
    "    payoffs[\"5-2-1\"] = {\"P3\": (Ω_12 + Ω_22) / 2,\n",
    "                        \"P2\": Π_l21,\n",
    "                        \"P1\": Π_l12}\n",
    "    payoffs[\"5-2-2\"] = {\"P3\": Ω_22,\n",
    "                        \"P2\": Π_l22,\n",
    "                        \"P1\": Π_l22}\n",
    "    payoffs[\"5-2-3\"] = {\"P3\": Ω_22,\n",
    "                        \"P2\": Π_l22,\n",
    "                        \"P1\": Π_l22}\n",
    "    payoffs[\"5-3-1\"] = {\"P3\": (Ω_12 + Ω_22) / 2,\n",
    "                        \"P2\": Π_l21,\n",
    "                        \"P1\": Π_l12}\n",
    "    payoffs[\"5-3-2\"] = {\"P3\": Ω_22,\n",
    "                        \"P2\": Π_l22,\n",
    "                        \"P1\": Π_l22}\n",
    "    payoffs[\"5-3-3\"] = {\"P3\": Ω_32,\n",
    "                        \"P2\": Π_l22,\n",
    "                        \"P1\": Π_l22}\n",
    "\n",
    "    return {**models, \"payoffs\": payoffs}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "@method(build_payoffs, \"regulatory_markets_v3_reward_mixed\")\n",
    "def build_payoffs(models):\n",
    "    \"\"\"Regulatory market payoffs when there is only a reward after catching\n",
    "    unsafe firms.\"\"\"\n",
    "    names1 = ['b', 'c', 's', 'p', 'B', 'W']\n",
    "    names2 = ['pfo_l', 'pfo_h', 'λ', 'r_l', 'r_h', 'g']\n",
    "    b, c, s, p, B, W = [models[k] for k in names1]\n",
    "    pfo_l, pfo_h, λ, r_l, r_h, g = [models[k] for k in names2]\n",
    "    collective_risk = models.get('collective_risk', 0)\n",
    "    risk_shared = (1 - (1-p)*collective_risk)\n",
    "    mix = models.get('incentive_mix', 0)\n",
    "    \n",
    "    k = models.get('decisiveness', 100)\n",
    "    phi_h = models.get('phi_h', 1/s)\n",
    "    phi_l = models.get('phi_l', 1/s)\n",
    "    caught_loses_h = ((s * phi_h)**k + 1)**(-1)\n",
    "    caught_loses_l = ((s * phi_l)**k + 1)**(-1)\n",
    "    \n",
    "    Π_h11 = B / (2*W) + b/2 - c\n",
    "    Π_h12 = ((1 - pfo_h) * b / (s+1) * risk_shared\n",
    "             + pfo_h * caught_loses_h * (b + B / W)\n",
    "             - c)\n",
    "    Π_h21 = (p * (1 - pfo_h) * (s*b / (s + 1) + s * B / W)\n",
    "                 + pfo_h * (1 - caught_loses_h) * B / W)\n",
    "    Π_h22 = p * ( 1 - pfo_h**2) * (b/2 + s*B/(2*W)) * risk_shared\n",
    "    \n",
    "    Π_l11 = B / (2*W) + b/2 - c\n",
    "    Π_l12 = ((1 - pfo_l) * b / (s+1) * risk_shared\n",
    "             + pfo_l * caught_loses_l * (b + B / W)\n",
    "             - c)\n",
    "    Π_l21 = (p * (1 - pfo_l) * (s*b / (s + 1)  + s * B / W)\n",
    "                 + pfo_l * (1 - caught_loses_l) * B / W)\n",
    "    Π_l22 = p * ( 1 - pfo_l**2) * (b/2 + s*B/(2*W)) * risk_shared\n",
    "    \n",
    "    λ_h = λ * (1 - p) * (1 - pfo_h)\n",
    "    λ_l = λ * (1 - p) * (1 - pfo_l)\n",
    "    \n",
    "    Ω_11 = r_h + g * mix\n",
    "    Ω_12 = r_l + g * mix\n",
    "    Ω_21 = r_h + g * (pfo_h**2 * mix + pfo_h * (1 - mix)) - λ_h\n",
    "    Ω_22 = r_l + g * (pfo_l**2 * mix + pfo_l * (1 - mix)) - λ_l\n",
    "    Ω_31 = r_h + g * mix\n",
    "    Ω_32 = r_l + g * (pfo_l**2 * mix + pfo_l * (1 - mix)) - λ_l\n",
    "    \n",
    "    payoffs = {}\n",
    "    payoffs[\"4-1-1\"] = {\"P3\": Ω_11,\n",
    "                        \"P2\": Π_h11,\n",
    "                        \"P1\": Π_h11}\n",
    "    payoffs[\"4-1-2\"] = {\"P3\": (Ω_11 + Ω_21) / 2,\n",
    "                        \"P2\": Π_h12,\n",
    "                        \"P1\": Π_h21}\n",
    "    payoffs[\"4-1-3\"] = {\"P3\": Ω_11,\n",
    "                        \"P2\": Π_h11,\n",
    "                        \"P1\": Π_h11}\n",
    "    payoffs[\"4-2-1\"] = {\"P3\": (Ω_11 + Ω_21) / 2,\n",
    "                        \"P2\": Π_h21,\n",
    "                        \"P1\": Π_h12}\n",
    "    payoffs[\"4-2-2\"] = {\"P3\": Ω_21,\n",
    "                        \"P2\": Π_h22,\n",
    "                        \"P1\": Π_h22}\n",
    "    payoffs[\"4-2-3\"] = {\"P3\": (Ω_11 + Ω_21) / 2,\n",
    "                        \"P2\": Π_h21,\n",
    "                        \"P1\": Π_h12}\n",
    "    payoffs[\"4-3-1\"] = {\"P3\": Ω_11,\n",
    "                        \"P2\": Π_h11,\n",
    "                        \"P1\": Π_h11}\n",
    "    payoffs[\"4-3-2\"] = {\"P3\": (Ω_11 + Ω_21) / 2,\n",
    "                        \"P2\": Π_h12,\n",
    "                        \"P1\": Π_h21}\n",
    "    payoffs[\"4-3-3\"] = {\"P3\": Ω_31,\n",
    "                        \"P2\": Π_h11,\n",
    "                        \"P1\": Π_h11}\n",
    "    \n",
    "    payoffs[\"5-1-1\"] = {\"P3\": Ω_12,\n",
    "                        \"P2\": Π_l11,\n",
    "                        \"P1\": Π_l11}\n",
    "    payoffs[\"5-1-2\"] = {\"P3\": (Ω_12 + Ω_22) / 2,\n",
    "                        \"P2\": Π_l12,\n",
    "                        \"P1\": Π_l21}\n",
    "    payoffs[\"5-1-3\"] = {\"P3\": (Ω_12 + Ω_22) / 2,\n",
    "                        \"P2\": Π_l12,\n",
    "                        \"P1\": Π_l21}\n",
    "    payoffs[\"5-2-1\"] = {\"P3\": (Ω_12 + Ω_22) / 2,\n",
    "                        \"P2\": Π_l21,\n",
    "                        \"P1\": Π_l12}\n",
    "    payoffs[\"5-2-2\"] = {\"P3\": Ω_22,\n",
    "                        \"P2\": Π_l22,\n",
    "                        \"P1\": Π_l22}\n",
    "    payoffs[\"5-2-3\"] = {\"P3\": Ω_22,\n",
    "                        \"P2\": Π_l22,\n",
    "                        \"P1\": Π_l22}\n",
    "    payoffs[\"5-3-1\"] = {\"P3\": (Ω_12 + Ω_22) / 2,\n",
    "                        \"P2\": Π_l21,\n",
    "                        \"P1\": Π_l12}\n",
    "    payoffs[\"5-3-2\"] = {\"P3\": Ω_22,\n",
    "                        \"P2\": Π_l22,\n",
    "                        \"P1\": Π_l22}\n",
    "    payoffs[\"5-3-3\"] = {\"P3\": Ω_32,\n",
    "                        \"P2\": Π_l22,\n",
    "                        \"P1\": Π_l22}\n",
    "\n",
    "    return {**models, \"payoffs\": payoffs}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "@method(build_payoffs, \"regulatory_markets_v4_reward_mixed\")\n",
    "def build_payoffs(models):\n",
    "    \"\"\"Regulatory market payoffs for a mix of incentives and allows a\n",
    "    schedule of measures to apply to firms detected as unsafe.\"\"\"\n",
    "    names1 = ['b', 'c', 's', 'p', 'B', 'W']\n",
    "    names2 = ['pfo_l', 'pfo_h', 'λ', 'r_l', 'r_h', 'g']\n",
    "    b, c, s, p, B, W = [models[k] for k in names1]\n",
    "    pfo_l, pfo_h, λ, r_l, r_h, g = [models[k] for k in names2]\n",
    "    collective_risk = models.get('collective_risk', 0)\n",
    "    risk_shared = (1 - (1-p)*collective_risk)\n",
    "    mix = models.get('incentive_mix', 0)\n",
    "    \n",
    "    k = models.get('decisiveness', 100)\n",
    "    phi_h = models.get('phi_h', 1/s)\n",
    "    phi2_h = models.get('phi2_h,', 1/s)\n",
    "    phi_l = models.get('phi_l', 1/s)\n",
    "    phi2_l = models.get('phi2_l', 1/s)\n",
    "    caught_loses_h = ((s * phi_h)**k + 1)**(-1)\n",
    "    caught_loses_l = ((s * phi_l)**k + 1)**(-1)\n",
    "    both_caught_lose_h = ((s * phi2_h)**k + 1)**(-1)\n",
    "    both_caught_lose_l = ((s * phi2_l)**k + 1)**(-1)\n",
    "    \n",
    "    Π_h11 = B / (2*W) + b/2 - c\n",
    "    Π_h12 = ((1 - pfo_h) * b / (s+1) * risk_shared\n",
    "             + pfo_h * caught_loses_h * (b + B / W)\n",
    "             - c)\n",
    "    Π_h21 = (p * (1 - pfo_h) * (s*b / (s + 1) + s * B / W)\n",
    "             + pfo_h * (1 - caught_loses_h) * B / W)\n",
    "    Π_h22 = p * ( 1 - pfo_h**2) * (b/2 + s*B/(2*W)) * risk_shared\n",
    "    Π_h22 = (p * (1 - pfo_h**2) * (b/2 + s*B/(2*W)) * risk_shared\n",
    "             + pfo_h**2 * both_caught_lose_h * B/(2*W))\n",
    "    \n",
    "    Π_l11 = B / (2*W) + b/2 - c\n",
    "    Π_l12 = ((1 - pfo_l) * b / (s+1) * risk_shared\n",
    "             + pfo_l * caught_loses_l * (b + B / W)\n",
    "             - c)\n",
    "    Π_l21 = (p * (1 - pfo_l) * (s*b / (s + 1)  + s * B / W)\n",
    "                 + pfo_l * (1 - caught_loses_l) * B / W)\n",
    "    Π_l22 = p * ( 1 - pfo_l**2) * (b/2 + s*B/(2*W)) * risk_shared\n",
    "    Π_l22 = (p * ( 1 - pfo_l**2) * (b/2 + s*B/(2*W)) * risk_shared\n",
    "             + pfo_l**2  * both_caught_lose_l * B/(2*W))\n",
    "    \n",
    "    λ_h = λ * (1 - p) * (1 - pfo_h)\n",
    "    λ_l = λ * (1 - p) * (1 - pfo_l)\n",
    "    \n",
    "    Ω_11 = r_h + g * mix\n",
    "    Ω_12 = r_l + g * mix\n",
    "    Ω_21 = r_h + g * (pfo_h**2 * mix + pfo_h * (1 - mix)) - λ_h\n",
    "    Ω_22 = r_l + g * (pfo_l**2 * mix + pfo_l * (1 - mix)) - λ_l\n",
    "    Ω_31 = r_h + g * mix\n",
    "    Ω_32 = r_l + g * (pfo_l**2 * mix + pfo_l * (1 - mix)) - λ_l\n",
    "    \n",
    "    payoffs = {}\n",
    "    payoffs[\"4-1-1\"] = {\"P3\": Ω_11,\n",
    "                        \"P2\": Π_h11,\n",
    "                        \"P1\": Π_h11}\n",
    "    payoffs[\"4-1-2\"] = {\"P3\": (Ω_11 + Ω_21) / 2,\n",
    "                        \"P2\": Π_h12,\n",
    "                        \"P1\": Π_h21}\n",
    "    payoffs[\"4-1-3\"] = {\"P3\": Ω_11,\n",
    "                        \"P2\": Π_h11,\n",
    "                        \"P1\": Π_h11}\n",
    "    payoffs[\"4-2-1\"] = {\"P3\": (Ω_11 + Ω_21) / 2,\n",
    "                        \"P2\": Π_h21,\n",
    "                        \"P1\": Π_h12}\n",
    "    payoffs[\"4-2-2\"] = {\"P3\": Ω_21,\n",
    "                        \"P2\": Π_h22,\n",
    "                        \"P1\": Π_h22}\n",
    "    payoffs[\"4-2-3\"] = {\"P3\": (Ω_11 + Ω_21) / 2,\n",
    "                        \"P2\": Π_h21,\n",
    "                        \"P1\": Π_h12}\n",
    "    payoffs[\"4-3-1\"] = {\"P3\": Ω_11,\n",
    "                        \"P2\": Π_h11,\n",
    "                        \"P1\": Π_h11}\n",
    "    payoffs[\"4-3-2\"] = {\"P3\": (Ω_11 + Ω_21) / 2,\n",
    "                        \"P2\": Π_h12,\n",
    "                        \"P1\": Π_h21}\n",
    "    payoffs[\"4-3-3\"] = {\"P3\": Ω_31,\n",
    "                        \"P2\": Π_h11,\n",
    "                        \"P1\": Π_h11}\n",
    "    \n",
    "    payoffs[\"5-1-1\"] = {\"P3\": Ω_12,\n",
    "                        \"P2\": Π_l11,\n",
    "                        \"P1\": Π_l11}\n",
    "    payoffs[\"5-1-2\"] = {\"P3\": (Ω_12 + Ω_22) / 2,\n",
    "                        \"P2\": Π_l12,\n",
    "                        \"P1\": Π_l21}\n",
    "    payoffs[\"5-1-3\"] = {\"P3\": (Ω_12 + Ω_22) / 2,\n",
    "                        \"P2\": Π_l12,\n",
    "                        \"P1\": Π_l21}\n",
    "    payoffs[\"5-2-1\"] = {\"P3\": (Ω_12 + Ω_22) / 2,\n",
    "                        \"P2\": Π_l21,\n",
    "                        \"P1\": Π_l12}\n",
    "    payoffs[\"5-2-2\"] = {\"P3\": Ω_22,\n",
    "                        \"P2\": Π_l22,\n",
    "                        \"P1\": Π_l22}\n",
    "    payoffs[\"5-2-3\"] = {\"P3\": Ω_22,\n",
    "                        \"P2\": Π_l22,\n",
    "                        \"P1\": Π_l22}\n",
    "    payoffs[\"5-3-1\"] = {\"P3\": (Ω_12 + Ω_22) / 2,\n",
    "                        \"P2\": Π_l21,\n",
    "                        \"P1\": Π_l12}\n",
    "    payoffs[\"5-3-2\"] = {\"P3\": Ω_22,\n",
    "                        \"P2\": Π_l22,\n",
    "                        \"P1\": Π_l22}\n",
    "    payoffs[\"5-3-3\"] = {\"P3\": Ω_32,\n",
    "                        \"P2\": Π_l22,\n",
    "                        \"P1\": Π_l22}\n",
    "\n",
    "    return {**models, \"payoffs\": payoffs}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "@method(build_payoffs, \"regulatory_markets_v5_reward_mixed\")\n",
    "def build_payoffs(models):\n",
    "    \"\"\"Regulatory market payoffs for a mix of incentives and allows a\n",
    "    schedule of measures to apply to firms detected as unsafe. Investigating\n",
    "    a potential correction to the probability of a firm winning.\"\"\"\n",
    "    names1 = ['b', 'c', 's', 'p', 'B', 'W']\n",
    "    names2 = ['pfo_l', 'pfo_h', 'λ', 'r_l', 'r_h', 'g']\n",
    "    b, c, s, p, B, W = [models[k] for k in names1]\n",
    "    pfo_l, pfo_h, λ, r_l, r_h, g = [models[k] for k in names2]\n",
    "    collective_risk = models.get('collective_risk', 0)\n",
    "    risk_shared = (1 - (1-p)*collective_risk)\n",
    "    mix = models.get('incentive_mix', 0)\n",
    "    \n",
    "    k = models.get('decisiveness', 100)\n",
    "    # Speed impact of regulators when they catch 1 or 2 safety violators\n",
    "    phi_h = models.get('phi_h', 1/s)\n",
    "    phi2_h = models.get('phi2_h,', 1/s)\n",
    "    phi_l = models.get('phi_l', 1/s)\n",
    "    phi2_l = models.get('phi2_l', 1/s)\n",
    "    # Tullock contest to determine which firm wins after\n",
    "    # one safety violator is caught\n",
    "    caught_loses_h = ((s * phi_h)**k + 1)**(-1)\n",
    "    caught_loses_l = ((s * phi_l)**k + 1)**(-1)\n",
    "    # Tullock contest to determine whether any firm wins if they are both\n",
    "    # safety violators who were caught by the regulator\n",
    "    both_caught_fail_h = ((s * phi2_h)**k + 1)**(-1)\n",
    "    both_caught_fail_l = ((s * phi2_l)**k + 1)**(-1)\n",
    "    \n",
    "    Π_h11 = B / (2*W) + b/2 - c\n",
    "    Π_h12 = ((1 - pfo_h) * b / (s+1) * risk_shared\n",
    "             + pfo_h * caught_loses_h * (b + B / W)\n",
    "             - c)\n",
    "    Π_h21 = (p * (1 - pfo_h) * (s*b / (s + 1) + s * B / W)\n",
    "             + (pfo_h * (1 - caught_loses_h)\n",
    "                * B / W))\n",
    "    Π_h22 = (p * (1 - pfo_h**2) * (b/2 + s*B/(2*W)) * risk_shared\n",
    "             + (pfo_h**2 * (1 - both_caught_fail_h)\n",
    "                * B/(2*W)))\n",
    "    \n",
    "    Π_l11 = B / (2*W) + b/2 - c\n",
    "    Π_l12 = ((1 - pfo_l) * b / (s+1) * risk_shared\n",
    "             + pfo_l * caught_loses_l * (b + B / W)\n",
    "             - c)\n",
    "    Π_l21 = (p * (1 - pfo_l) * (s*b / (s + 1)  + s * B / W)\n",
    "             + (pfo_l * (1 - caught_loses_l)\n",
    "                * B / W))\n",
    "    Π_l22 = (p * ( 1 - pfo_l**2) * (b/2 + s*B/(2*W)) * risk_shared\n",
    "             + (pfo_l**2  * (1 - both_caught_fail_l)\n",
    "                * B/(2*W)))\n",
    "    \n",
    "    λ_h = λ * (1 - p) * (1 - pfo_h)\n",
    "    λ_l = λ * (1 - p) * (1 - pfo_l)\n",
    "    \n",
    "    Ω_11 = r_h + g * mix\n",
    "    Ω_12 = r_l + g * mix\n",
    "    Ω_21 = r_h + g * (pfo_h**2 * mix + pfo_h * (1 - mix)) - λ_h\n",
    "    Ω_22 = r_l + g * (pfo_l**2 * mix + pfo_l * (1 - mix)) - λ_l\n",
    "    Ω_31 = r_h + g * mix\n",
    "    Ω_32 = r_l + g * (pfo_l**2 * mix + pfo_l * (1 - mix)) - λ_l\n",
    "    \n",
    "    payoffs = {}\n",
    "    payoffs[\"4-1-1\"] = {\"P3\": Ω_11,\n",
    "                        \"P2\": Π_h11,\n",
    "                        \"P1\": Π_h11}\n",
    "    payoffs[\"4-1-2\"] = {\"P3\": (Ω_11 + Ω_21) / 2,\n",
    "                        \"P2\": Π_h12,\n",
    "                        \"P1\": Π_h21}\n",
    "    payoffs[\"4-1-3\"] = {\"P3\": Ω_11,\n",
    "                        \"P2\": Π_h11,\n",
    "                        \"P1\": Π_h11}\n",
    "    payoffs[\"4-2-1\"] = {\"P3\": (Ω_11 + Ω_21) / 2,\n",
    "                        \"P2\": Π_h21,\n",
    "                        \"P1\": Π_h12}\n",
    "    payoffs[\"4-2-2\"] = {\"P3\": Ω_21,\n",
    "                        \"P2\": Π_h22,\n",
    "                        \"P1\": Π_h22}\n",
    "    payoffs[\"4-2-3\"] = {\"P3\": (Ω_11 + Ω_21) / 2,\n",
    "                        \"P2\": Π_h21,\n",
    "                        \"P1\": Π_h12}\n",
    "    payoffs[\"4-3-1\"] = {\"P3\": Ω_11,\n",
    "                        \"P2\": Π_h11,\n",
    "                        \"P1\": Π_h11}\n",
    "    payoffs[\"4-3-2\"] = {\"P3\": (Ω_11 + Ω_21) / 2,\n",
    "                        \"P2\": Π_h12,\n",
    "                        \"P1\": Π_h21}\n",
    "    payoffs[\"4-3-3\"] = {\"P3\": Ω_31,\n",
    "                        \"P2\": Π_h11,\n",
    "                        \"P1\": Π_h11}\n",
    "    \n",
    "    payoffs[\"5-1-1\"] = {\"P3\": Ω_12,\n",
    "                        \"P2\": Π_l11,\n",
    "                        \"P1\": Π_l11}\n",
    "    payoffs[\"5-1-2\"] = {\"P3\": (Ω_12 + Ω_22) / 2,\n",
    "                        \"P2\": Π_l12,\n",
    "                        \"P1\": Π_l21}\n",
    "    payoffs[\"5-1-3\"] = {\"P3\": (Ω_12 + Ω_22) / 2,\n",
    "                        \"P2\": Π_l12,\n",
    "                        \"P1\": Π_l21}\n",
    "    payoffs[\"5-2-1\"] = {\"P3\": (Ω_12 + Ω_22) / 2,\n",
    "                        \"P2\": Π_l21,\n",
    "                        \"P1\": Π_l12}\n",
    "    payoffs[\"5-2-2\"] = {\"P3\": Ω_22,\n",
    "                        \"P2\": Π_l22,\n",
    "                        \"P1\": Π_l22}\n",
    "    payoffs[\"5-2-3\"] = {\"P3\": Ω_22,\n",
    "                        \"P2\": Π_l22,\n",
    "                        \"P1\": Π_l22}\n",
    "    payoffs[\"5-3-1\"] = {\"P3\": (Ω_12 + Ω_22) / 2,\n",
    "                        \"P2\": Π_l21,\n",
    "                        \"P1\": Π_l12}\n",
    "    payoffs[\"5-3-2\"] = {\"P3\": Ω_22,\n",
    "                        \"P2\": Π_l22,\n",
    "                        \"P1\": Π_l22}\n",
    "    payoffs[\"5-3-3\"] = {\"P3\": Ω_32,\n",
    "                        \"P2\": Π_l22,\n",
    "                        \"P1\": Π_l22}\n",
    "\n",
    "    return {**models, \"payoffs\": payoffs}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "@method(build_payoffs, \"regulatory_markets_v6_reward_mixed\")\n",
    "def build_payoffs(models):\n",
    "    \"\"\"Regulatory market payoffs for a mix of incentives and allows a\n",
    "    schedule of measures to apply to firms detected as unsafe. The speed of\n",
    "    caught safety violators is not necessarily 1 and the risk is not\n",
    "    necessarily 0.\"\"\"\n",
    "    names1 = ['b', 'c', 's', 'p', 'B', 'W']\n",
    "    names2 = ['pfo_l', 'pfo_h', 'λ', 'r_l', 'r_h', 'g']\n",
    "    b, c, s, p, B, W = [models[k] for k in names1]\n",
    "    pfo_l, pfo_h, λ, r_l, r_h, g = [models[k] for k in names2]\n",
    "    collective_risk = models.get('collective_risk', 0)\n",
    "    risk_shared = (1 - (1-p)*collective_risk)\n",
    "    mix = models.get('incentive_mix', 0)\n",
    "    \n",
    "    k = models.get('decisiveness', 100)\n",
    "    # Win impact of regulators when they catch 1 or 2 safety violators\n",
    "    phi_h = models.get('phi_h', 1/s)\n",
    "    phi2_h = models.get('phi2_h,', 1/s)\n",
    "    phi_l = models.get('phi_l', 1/s)\n",
    "    phi2_l = models.get('phi2_l', 1/s)\n",
    "    # Speed impact of regulators when they catch 1 or 2 safety violators\n",
    "    theta_h = models.get('theta_h', 1/s)\n",
    "    theta2_h = models.get('theta2_h,', 1/s)\n",
    "    theta_l = models.get('theta_l', 1/s)\n",
    "    theta2_l = models.get('theta2_l,', 1/s)\n",
    "    # Risk impact of regulators when they catch 1 or 2 safety violators\n",
    "    gamma_h = models.get('gamma_h', phi_h)\n",
    "    gamma2_h = models.get('gamma2_h', phi2_h)\n",
    "    gamma_l = models.get('gamma_l', phi_l)\n",
    "    gamma2_l = models.get('gamma2_l', phi2_l)\n",
    "    # Tullock contest to determine which firm wins after\n",
    "    # one safety violator is caught\n",
    "    caught_loses_h = ((s * phi_h)**k + 1)**(-1)\n",
    "    caught_loses_l = ((s * phi_l)**k + 1)**(-1)\n",
    "    # Tullock contest to determine whether any firm wins if they are both\n",
    "    # safety violators who were caught by the regulator\n",
    "    both_caught_fail_h = ((s * phi2_h)**k + 1)**(-1)\n",
    "    both_caught_fail_l = ((s * phi2_l)**k + 1)**(-1)\n",
    "    risk_shared_reg2_h = (1 - (1-p)*collective_risk * gamma2_h)\n",
    "    risk_shared_reg2_l = (1 - (1-p)*collective_risk * gamma2_l)\n",
    "    \n",
    "    Π_h11 = B / (2*W) + b/2 - c\n",
    "    Π_h12 = ((1 - pfo_h) * b / (s+1) * risk_shared\n",
    "             + pfo_h * caught_loses_h * (b + B / W)\n",
    "             - c)\n",
    "    Π_h21 = (p * (1 - pfo_h) * (s*b / (s + 1) + s * B / W)\n",
    "             + ((1 - (1 - p) * gamma_h)\n",
    "                * pfo_h * (1 - caught_loses_h)\n",
    "                * theta_h * s\n",
    "                * B / W))\n",
    "    Π_h22 = (p * (1 - pfo_h**2) * (b/2 + s*B/(2*W)) * risk_shared\n",
    "             + ((1 - (1 - p) * gamma2_h) * risk_shared_reg2_h\n",
    "                * pfo_h**2 * (1 - both_caught_fail_h)\n",
    "                * theta2_h * s\n",
    "                * B/(2*W)))\n",
    "    \n",
    "    Π_l11 = B / (2*W) + b/2 - c\n",
    "    Π_l12 = ((1 - pfo_l) * b / (s+1) * risk_shared\n",
    "             + pfo_l * caught_loses_l * (b + B / W)\n",
    "             - c)\n",
    "    Π_l21 = (p * (1 - pfo_l) * (s*b / (s + 1)  + s * B / W)\n",
    "             + ((1 - (1 - p) * gamma_l)\n",
    "                * pfo_l * (1 - caught_loses_l)\n",
    "                * theta_l* s\n",
    "                * B / W))\n",
    "    Π_l22 = (p * ( 1 - pfo_l**2) * (b/2 + s*B/(2*W)) * risk_shared\n",
    "             + ((1 - (1 - p) * gamma2_l) * risk_shared_reg2_l\n",
    "                * pfo_l**2  * (1 - both_caught_fail_l)\n",
    "                * theta2_l * s\n",
    "                * B/(2*W)))\n",
    "    \n",
    "    λ_h = λ * (1 - p) * (1 - pfo_h)\n",
    "    λ_l = λ * (1 - p) * (1 - pfo_l)\n",
    "    \n",
    "    Ω_11 = r_h + g * mix\n",
    "    Ω_12 = r_l + g * mix\n",
    "    Ω_21 = r_h + g * (pfo_h**2 * mix + pfo_h * (1 - mix)) - λ_h\n",
    "    Ω_22 = r_l + g * (pfo_l**2 * mix + pfo_l * (1 - mix)) - λ_l\n",
    "    Ω_31 = r_h + g * mix\n",
    "    Ω_32 = r_l + g * (pfo_l**2 * mix + pfo_l * (1 - mix)) - λ_l\n",
    "    \n",
    "    payoffs = {}\n",
    "    payoffs[\"4-1-1\"] = {\"P3\": Ω_11,\n",
    "                        \"P2\": Π_h11,\n",
    "                        \"P1\": Π_h11}\n",
    "    payoffs[\"4-1-2\"] = {\"P3\": (Ω_11 + Ω_21) / 2,\n",
    "                        \"P2\": Π_h12,\n",
    "                        \"P1\": Π_h21}\n",
    "    payoffs[\"4-1-3\"] = {\"P3\": Ω_11,\n",
    "                        \"P2\": Π_h11,\n",
    "                        \"P1\": Π_h11}\n",
    "    payoffs[\"4-2-1\"] = {\"P3\": (Ω_11 + Ω_21) / 2,\n",
    "                        \"P2\": Π_h21,\n",
    "                        \"P1\": Π_h12}\n",
    "    payoffs[\"4-2-2\"] = {\"P3\": Ω_21,\n",
    "                        \"P2\": Π_h22,\n",
    "                        \"P1\": Π_h22}\n",
    "    payoffs[\"4-2-3\"] = {\"P3\": (Ω_11 + Ω_21) / 2,\n",
    "                        \"P2\": Π_h21,\n",
    "                        \"P1\": Π_h12}\n",
    "    payoffs[\"4-3-1\"] = {\"P3\": Ω_11,\n",
    "                        \"P2\": Π_h11,\n",
    "                        \"P1\": Π_h11}\n",
    "    payoffs[\"4-3-2\"] = {\"P3\": (Ω_11 + Ω_21) / 2,\n",
    "                        \"P2\": Π_h12,\n",
    "                        \"P1\": Π_h21}\n",
    "    payoffs[\"4-3-3\"] = {\"P3\": Ω_31,\n",
    "                        \"P2\": Π_h11,\n",
    "                        \"P1\": Π_h11}\n",
    "    \n",
    "    payoffs[\"5-1-1\"] = {\"P3\": Ω_12,\n",
    "                        \"P2\": Π_l11,\n",
    "                        \"P1\": Π_l11}\n",
    "    payoffs[\"5-1-2\"] = {\"P3\": (Ω_12 + Ω_22) / 2,\n",
    "                        \"P2\": Π_l12,\n",
    "                        \"P1\": Π_l21}\n",
    "    payoffs[\"5-1-3\"] = {\"P3\": (Ω_12 + Ω_22) / 2,\n",
    "                        \"P2\": Π_l12,\n",
    "                        \"P1\": Π_l21}\n",
    "    payoffs[\"5-2-1\"] = {\"P3\": (Ω_12 + Ω_22) / 2,\n",
    "                        \"P2\": Π_l21,\n",
    "                        \"P1\": Π_l12}\n",
    "    payoffs[\"5-2-2\"] = {\"P3\": Ω_22,\n",
    "                        \"P2\": Π_l22,\n",
    "                        \"P1\": Π_l22}\n",
    "    payoffs[\"5-2-3\"] = {\"P3\": Ω_22,\n",
    "                        \"P2\": Π_l22,\n",
    "                        \"P1\": Π_l22}\n",
    "    payoffs[\"5-3-1\"] = {\"P3\": (Ω_12 + Ω_22) / 2,\n",
    "                        \"P2\": Π_l21,\n",
    "                        \"P1\": Π_l12}\n",
    "    payoffs[\"5-3-2\"] = {\"P3\": Ω_22,\n",
    "                        \"P2\": Π_l22,\n",
    "                        \"P1\": Π_l22}\n",
    "    payoffs[\"5-3-3\"] = {\"P3\": Ω_32,\n",
    "                        \"P2\": Π_l22,\n",
    "                        \"P1\": Π_l22}\n",
    "\n",
    "    return {**models, \"payoffs\": payoffs}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "@method(build_payoffs, \"group_competition_v1\")\n",
    "def build_payoffs(models):\n",
    "    \"\"\"A group competition model of blocs competiting over AI when using\n",
    "    a regulatory market policy.\"\"\"\n",
    "    \n",
    "    # Payoffs for an economic bloc are the sum of expected EGT payoffs for all\n",
    "    # AI labs in their economy given the bloc's choice of g, phi (and λ).\n",
    "    # Blocs engage in pairwise interactions with other blocs where they lose\n",
    "    # if they have the lower payoff. For simplicity, we capture this using\n",
    "    # social learning only. Bloc payoffs are independent.\n",
    "    \n",
    "    # We first need to define the model of interactions between AI labs and\n",
    "    # auditors in each bloc.\n",
    "    models_inner = models[\"models_inner\"]\n",
    "\n",
    "    # The user should define a list of policy_bundles to evaluate the bloc\n",
    "    # payoffs for.\n",
    "    policy_bundles = models['policy_bundles']\n",
    "    bloc_payoffs = []\n",
    "    for policy in policy_bundles:\n",
    "         results = thread_macro({**models_inner,\n",
    "                                 **policy,\n",
    "                                    },\n",
    "                                    payoffs_sr_pfo_extension,\n",
    "                                    create_profiles,\n",
    "                                    apply_profile_filters,\n",
    "                                    build_payoffs,\n",
    "                                    build_transition_matrix,\n",
    "                                    find_ergodic_distribution,\n",
    "                                    calculate_sd_helper,\n",
    "                                    compute_game_welfare,\n",
    "                                    )\n",
    "         bloc_payoffs.append(results['game_welfare'])\n",
    "    \n",
    "    # The bloc interaction is a 2 player game where players choose among 4\n",
    "    # strategies.\n",
    "    \n",
    "     \n",
    "    payoffs = {}\n",
    "    for i, in range(len(bloc_payoffs)):\n",
    "        for j in range(len(bloc_payoffs)):\n",
    "                payoffs[f\"{j+1}-{i+1}\"] = {\"P2\": bloc_payoffs[j],\n",
    "                                           \"P1\": bloc_payoffs[i]}\n",
    "\n",
    "    return {**models, \"payoffs\": payoffs}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Payoff Matrices (part 4)\n",
    "\n",
    "> This module contains payoff matrices for different evolutionary games\n",
    ">\n",
    "> Part 4 contains payoff matrices for the following games\n",
    "> - Game 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Payoffs Part 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "5844494aa8caf4c1a0a05d85746d5381f91a25fadc32ae63a73a248c881db361"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
