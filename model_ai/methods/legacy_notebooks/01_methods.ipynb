{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3275141f-78f8-43c7-8a4f-7517dee6f284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88b6efd0-6adb-4de2-8383-2bdc5af68496",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/Paolo-Work/git/gh-pages-example/gh_pages_example/model_utils.py:299: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if (ind not in allowed_inds) and (str(ind) not in allowed_inds):\n"
     ]
    }
   ],
   "source": [
    "# | hide\n",
    "# | export\n",
    "from gh_pages_example.utils import *\n",
    "from gh_pages_example.model_utils import *\n",
    "from gh_pages_example.types import *\n",
    "\n",
    "import collections\n",
    "import functools\n",
    "import math\n",
    "import typing\n",
    "from typing import Optional, List, Generator, Union, Callable\n",
    "from warnings import warn\n",
    "\n",
    "import fastcore.test\n",
    "from nbdev.showdoc import *\n",
    "import numpy as np\n",
    "import nptyping\n",
    "from scipy.linalg import schur, eigvals\n",
    "from scipy.sparse import csr_matrix, csc_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c675457e-78d3-4dcc-8b4d-9dc966a3ec97",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c06847-fe93-4fc5-9b91-30f92cc69f3c",
   "metadata": {},
   "source": [
    "# Methods in Evolutionary Game Theory\n",
    "\n",
    "> A set of methods for solving Evolutionary Games (see Nowak 2006 and the references section)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66e4126-c29d-41e8-bce9-54dcabbc63ba",
   "metadata": {},
   "source": [
    "## Evolutionary Dynamics in Finite Populations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8f91a3-f1d3-4ad5-a574-3ab583f1edf5",
   "metadata": {},
   "source": [
    "We examine a finite population of players using different strategies who engage in social learning.\n",
    "\n",
    "In the limit of small mutations, most of the time everyone plays the same strategy. States in which everyone plays the same strategy are known as **monomorphic states**. Occassionally, mutant strategies can fixate in the population, resulting in everyone adopting the same new strategy. We can use Markov Chains to analyse the relative frequencies with which each strategy is played by the population.\n",
    "\n",
    "The steps for computing the ergodic (i.e. long-run, stationary) strategy distribution is as follows:\n",
    "\n",
    "1. Build a transition matrix between all monomorphic states\n",
    "2. Find the ergodic distribution for the markov chain defined using this transition matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb44b7a3-d2ca-4492-b844-5bb9eec99c5c",
   "metadata": {},
   "source": [
    "### Fermi social learning\n",
    "\n",
    "> A Fermi social learning rule means that individuals make pairwise comparisons between their own strategy and and another strategy in the population that they may choose to copy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cab4078-47e3-4468-af4a-742219f3b2c5",
   "metadata": {},
   "source": [
    "#### Derivation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5245cb-1d83-4bbe-8683-96cf42af71a3",
   "metadata": {},
   "source": [
    "Each period of the evolutionary game involves individuals being randomly selected to play against one another individual.\n",
    "\n",
    "Letting $Z$ denote the size of the population, and $π$ denote the game's payoff matrix, we can compute the fitness of a strategy, $B$ for example, when $k$ individuals are of type $B$ as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "ΠB_k = πBA \\frac{k-1}{Z - 1} + πBB \\frac{Z-k}{Z- 1}\n",
    "\\end{equation}\n",
    "\n",
    "where $πBA$ and $πBB$ are the payoffs for playing $B$ against type $A$ or $B$ respectively.\n",
    "\n",
    "The **Fermi social learning rule** adopts strategy $B$ selected from the population over their current strategy $A$ with probability given by:\n",
    "\n",
    "\\begin{equation}\n",
    "Pr(adopt \\, B | k) = \\frac{1}{(1 + \\exp^{-\\beta (ΠB_k - ΠA_k)})}\n",
    "\\end{equation}\n",
    "\n",
    "where $ΠB_k - ΠA_k$ is the relative fitness of strategy $B$ over $A$ in a population with $k$ individuals of type $B$, the rest of type $A$. Notice how the larger the relative fitness, the closer the denominator, and therefore the probability, is to $1$.\n",
    "\n",
    "Using the Fermi social learning rule above, we can write the probability of increasing the number of type $B$ individuals as\n",
    "\n",
    "\\begin{equation}\n",
    "T^+_B(k) = \\frac{Z-k}{Z} \\frac{k}{Z} Pr(adopt \\, B | k) \n",
    "\\end{equation}\n",
    "Z\n",
    "as an individual of type $A$ needs to randomly be chosen to compare their strategy against someone of type $B$.\n",
    "\n",
    "and the probability of decreasing the number of type $B$ individuals as\n",
    "\n",
    "\\begin{equation}\n",
    "T^-_B(k) = \\frac{k}{Z} \\frac{Z-k}{Z} Pr(adopt \\, A | k) \n",
    "\\end{equation}\n",
    "\n",
    "as an individual of type $B$ needs to randomly be chosen to compare their strategy against someone of type $A$.\n",
    "\n",
    "We will often employ their ratio, which is: \n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{T^-_B(k)}{T^+_B(k)} = \\frac{Pr(adopt \\, A | k) }{Pr(adopt \\, B | k)} = \\frac{1 + \\exp^{-\\beta (ΠB_k - ΠA_k)}}{1 + \\exp^{-\\beta (ΠA_k - ΠB_k)}}\n",
    "\\end{equation}\n",
    "\n",
    "Notice that $\\frac{1 + \\exp^x}{1 + \\exp^{-x}} = \\exp^{x}$\n",
    "\n",
    "So, this ratio simplifies to $\\frac{T^-_B(k)}{T^+_B(k)} =  \\exp^{-\\beta (ΠB_k - ΠA_k)}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86898d7e-42d1-4ef9-af35-0859f8097c22",
   "metadata": {},
   "source": [
    "#### Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bea9cbf-f84a-4131-893c-47099a4487a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "def fermi_learning(fitnessA: nptyping.NDArray,  # fitness of strategy A\n",
    "                   fitnessB: nptyping.NDArray,  # fitness of strategy B\n",
    "                   β: nptyping.NDArray,  # learning rate\n",
    "                   ) -> nptyping.NDArray:\n",
    "    \"\"\"Compute the likelihood that a player with strategy A adopts strategy B using the fermi function.\"\"\"\n",
    "    return (1 + np.exp(-β*(fitnessB - fitnessA)))**(-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb62f2bd-4534-4464-9147-de20bf2dc42b",
   "metadata": {},
   "source": [
    "#### Examples and Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fca8e00-f849-490b-b29d-54119b064a2e",
   "metadata": {},
   "source": [
    "When each strategy has the same fitness, then the likelihood that a player adopts strategy $B$ is 50%, no matter the value of $\\beta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "678244e2-9597-4d85-96ae-a69211d64539",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = fermi_learning(np.array([5]),\n",
    "                   np.array([5]),\n",
    "                   np.array([1]),)\n",
    "nptyping.assert_isinstance(\n",
    "    x, nptyping.NDArray[nptyping.Shape[\"1\"], typing.Any])\n",
    "fastcore.test.test_eq(x, 0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e881f80e-272a-4727-9a46-881e5b51e38f",
   "metadata": {},
   "source": [
    "### Fixation rate\n",
    "\n",
    "> The fixation rate for type B in a population of type A, $\\rho$, is defined as the probability that the appearance of a mutant of type B leads to the entire population adopting type B instead of A, i.e. what is the likelihood that a mutant of type B invades population A."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a01463-b50c-4fd6-aade-8ec965813481",
   "metadata": {},
   "source": [
    "#### Derivation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ffe1bf-842e-4890-b40f-493bd627e9ce",
   "metadata": {},
   "source": [
    "A derivation of the fixation rate defined below can be found in Nowak 2006 (reproduced below).\n",
    "\n",
    "> Consider a one-dimensional stochastic process on a discrete state space, $ i \\in \\{0, 1, \\cdots, N\\}$ that represents the number of individuals in a population of $N$ individuals who are of type $B$, the rest are type $A$.\n",
    ">\n",
    "> In each stochastic event, the number of individuals of type $B$ can at most increase or decrease by 1.\n",
    ">\n",
    "> For a given number of individuals, $i$, let $a_i$, $b_i$, and $1 - a_i - b_i$ represent the chance of an increase, decrease, or no change in $i$.\n",
    "> \n",
    "> This stochastic process follows the transition matrix ,$P$ (*not to be confused with the transition matrices we discuss elsewhere!*)\n",
    ">\n",
    ">\n",
    "> \\begin{equation}\n",
    "P \\, = \\, \\begin{pmatrix}\n",
    "1 & 0 & 0 & \\cdots & 0 & 0 & 0\\\\\n",
    "b_1 & (1 - a_1 - b_1) & a_1 & \\cdots & 0 & 0 & 0\\\\\n",
    "\\vdots & \\vdots & \\vdots & \\ddots & \\vdots & \\vdots & \\vdots\\\\\n",
    "0 & 0 & 0 & \\cdots & b_{n-1} & (1 - a_{n-1} - b_{n-1}) & a_{n-1}\\\\\n",
    "0 & 0 & 0 & \\cdots & 0 & 0 & 1\\\\\n",
    "\\end{pmatrix}\n",
    "\\end{equation}\n",
    ">\n",
    "> Denote by $x_i$ the probability of reaching state $N$ when starting from $i$.\n",
    ">\n",
    "> From transition matrix $P$ above, we can see that $x_i$ must satisfy:\n",
    ">\n",
    "> $x_0 = 0$\n",
    ">\n",
    "> $x_i = b_i x_{i-1} + (1 - a_i - b_i) x_i + a_i x_{i+1}$\n",
    ">\n",
    "> $x_N = 1$\n",
    ">\n",
    "> The fixation rate for a mutant B in a population of type A is clearly $x_1$\n",
    ">\n",
    "> We can solve for $x_i$ by rewriting the above as $b_i x_i - b_i  x_{i-1} = a_i x_{i+1} - a_i x_i$.\n",
    "> \n",
    "> We can denote $y_i = x_i - x_{i-1}$ to simplify the above to $y_{i+1} = \\frac{b_i}{a_i} y_i$\n",
    ">\n",
    "> Notice that $\\sum_{i=1}^N{y_i} = x_N - x_0 = 1$ and that $y_1 = x_1$\n",
    ">\n",
    "> We can use the above to write\n",
    "\\begin{equation}\n",
    "x_1 + {\\sum_{i=2}^N{y_i}} = x_1 (1 + {\\sum_{i=1}^{N-1}{\\prod_{j=1}^{i} \\frac{b_j}{a_j}}}) = 1\n",
    "\\end{equation}\n",
    ">\n",
    "> And so\n",
    "\\begin{equation}\n",
    "x_1 = \\frac{1}{(1 + \\sum_{i=1}^{N-1}{\\prod_{j=1}^{i} \\frac{b_j}{a_j}})}\n",
    "\\end{equation}\n",
    ">\n",
    "> Note that $x_1$ is the fixation rate for a mutant $B$ in a population of type $A$, often denoted as $\\rho$.\n",
    ">\n",
    "> *Also note that $1 - x_{N-1}$ is the fixation rate for a mutant $A$ in a population of type $B$. We could find expressions for all $x_i$ if we note that $x_i = x_1 (1 + \\sum_{j=1}^{i-1}{\\prod_{k=1}^{j} \\frac{b_k}{a_k}})$ (see Nowak 2006 for further details).*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b526b83-8fe7-4a4e-bf12-228f4879dceb",
   "metadata": {},
   "source": [
    "We can use our definitions above to determine when the fixation rate for a mutant $B$ in a population of type $A$ is greater than that for a mutant $A$ in a population of type $B$. \n",
    "\n",
    "This condition requires that $x_1 > 1 - x_{N-1}$, i.e. $\\frac{1}{(1 + \\sum_{i=1}^{N-1}{\\prod_{j=1}^{i} \\frac{b_j}{a_j}})} > \\frac{\\prod_{j=1}^{N-1} \\frac{b_j}{a_j}}{(1 + \\sum_{i=1}^{N-1}{\\prod_{j=1}^{i} \\frac{b_j}{a_j}})}$.\n",
    "\n",
    "Using the fermi social learning rule and the aforementioned simplifications, we can see that this condition holds true whenever $1 > \\exp^{-\\beta \\sum_{j=1}^{N-1}{\\Pi_B(j) - \\Pi_A(j)}}$ which implies $\\sum_{j=1}^{N-1}{\\Pi_B(j)} > \\sum_{j=1}^{N-1}{\\Pi_A(j)}$.\n",
    "\n",
    "Lastly, we can make use of the equation $\\sum_{j=1}^{N-1}{j}=\\frac{(N-1) N}{2}$ to simplify this condition to $\\pi_{BA} + \\pi_{BA} > \\pi_{AA} + \\pi_{AB}$\n",
    "\n",
    "This is exactly the risk dominance condition implied by 2 by 2 payoff matrices. The risk dominance condition has been used in the literature to offer a reason to motivate selecting one monomorphic equilibria over another in such games. In such games there is a precise connection between risk dominance and the monomorphic equilibria selected for by social learning. This connection disappears in games with larger payoff matrices (which is why theorists tends to consider the concept of stochastic stability instead, perhaps using Young's method (Young 2003)).\n",
    "\n",
    "Even in games with more than 2 players (or populations), we can make use of this condition to tell us in which direction the fixation rate is stronger between two strategies. At times, this is enough to gain an intuition for the gradient of selection present in polymorphic states where multiple strategies coexist in one or more populations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd408dd8-b57b-4fce-9100-758299ea3c18",
   "metadata": {},
   "source": [
    "#### Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc4b2af0-7469-4788-bd6b-96d143e27ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "T_type = list[nptyping.NDArray[nptyping.Shape[\"N_models\"], typing.Any]]\n",
    "\n",
    "\n",
    "def fixation_rate(Tplus: T_type,  # A list of NDarrays, one array (of size n_models) for each possible number of mutants in the population; the probability of gaining one mutant\n",
    "                  # A list of NDarrays, one array (of size n_models) for each possible number of mutants in the population; the probability of losing one mutant\n",
    "                  Tneg: T_type,\n",
    "                  ) -> nptyping.NDArray[nptyping.Shape[\"N_models\"], typing.Any]:  # Fixation rates for the given strategy in each model\n",
    "    \"\"\"Calculate the likelihood that a mutant invades the population.\"\"\"\n",
    "    Z = len(Tplus) + 1\n",
    "    ρ = (np.sum([np.prod([Tneg[j-1]/Tplus[j-1]\n",
    "                         for j in range(1, i+1)],\n",
    "                         axis=0,\n",
    "                         keepdims=False)\n",
    "                 for i in range(1, Z)],\n",
    "                axis=0,\n",
    "                keepdims=False)\n",
    "         + 1)**-1\n",
    "    # The fixation rate may be very close to 0. Innacuracies with floats\n",
    "    # may mean that we run into issues later on. We assume the fixation rate\n",
    "    # never drops below 1e-10.\n",
    "    ρ = np.maximum(ρ, 1e-10)\n",
    "    return ρ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4236065c-1875-4503-b790-8b59188e13b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/PaoloBova/gh-pages-example/blob/main/gh_pages_example/methods.py#L45){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### fixation_rate\n",
       "\n",
       ">      fixation_rate (Tplus:list[nptyping.base_meta_classes.NDArray],\n",
       ">                     Tneg:list[nptyping.base_meta_classes.NDArray])\n",
       "\n",
       "Calculate the likelihood that a mutant invades the population.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| Tplus | list | A list of NDarrays, one array (of size n_models) for each possible number of mutants in the population; the probability of gaining one mutant |\n",
       "| Tneg | list | A list of NDarrays, one array (of size n_models) for each possible number of mutants in the population; the probability of losing one mutant |\n",
       "| **Returns** | **NDArray** | **Fixation rates for the given strategy in each model** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/PaoloBova/gh-pages-example/blob/main/gh_pages_example/methods.py#L45){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### fixation_rate\n",
       "\n",
       ">      fixation_rate (Tplus:list[nptyping.base_meta_classes.NDArray],\n",
       ">                     Tneg:list[nptyping.base_meta_classes.NDArray])\n",
       "\n",
       "Calculate the likelihood that a mutant invades the population.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| Tplus | list | A list of NDarrays, one array (of size n_models) for each possible number of mutants in the population; the probability of gaining one mutant |\n",
       "| Tneg | list | A list of NDarrays, one array (of size n_models) for each possible number of mutants in the population; the probability of losing one mutant |\n",
       "| **Returns** | **NDArray** | **Fixation rates for the given strategy in each model** |"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(fixation_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aeab27b-5b89-424e-981d-0a6d1b161e7e",
   "metadata": {},
   "source": [
    "#### Examples and Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005877f9-bb91-4f68-a982-a5d50ca48f71",
   "metadata": {},
   "source": [
    "When the chance of gaining a mutant always equals the chance of losing a mutant, then the fixation rate will be $\\frac{1}{Z}$\n",
    "\n",
    "Note that because we have to sample the population for a mutant and the player of the type being invaded, the chance of gaining or losing a mutant can be no greater than $\\frac{k}{Z} \\frac{Z-k}{Z}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5be4272f-1d85-416b-b424-53d4d3186b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = 2  # With Z=2, we only need to evaluate Tplus and Tneg for when k=1\n",
    "Tplus_example = [np.array([1/8])]\n",
    "Tneg_example = [np.array([1/8])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b0d9199-f2e7-4dfd-927e-f6c21fc83454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# |  hide\n",
    "# validate test inputs\n",
    "assert len(Tplus_example) == len(Tneg_example)\n",
    "for tplus, tneg in zip(Tplus_example, Tneg_example):\n",
    "    assert tplus.shape == tneg.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61f41700-0399-4be0-9992-5a111cc086c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixation_rate_result = fixation_rate(Tplus_example, Tneg_example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b97469d4-36bf-4d67-9e1f-d39651db1b61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | hide\n",
    "nptyping.assert_isinstance(fixation_rate_result,\n",
    "                           nptyping.NDArray[nptyping.Shape[\"1\"], typing.Any])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd36d254-7f82-4f86-bd1f-c5bcd6d679e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fastcore.test.test_eq(fixation_rate_result, np.array([0.5]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9516d8-2e23-4468-8086-54e4dcd59c8a",
   "metadata": {},
   "source": [
    "When the chance of gaining a mutant is half the chance of losing a mutant, then the fixation rate will be\n",
    "\n",
    "\\begin{equation}\n",
    "\\rho = \\frac{1}{(1 + \\sum_{j=1}^{Z-1}{2^j})}\n",
    "\\end{equation}\n",
    "\n",
    "When $Z=2$, we have $\\rho = \\frac{1}{3}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5c929e5-3ab3-48ae-9dba-002c0054f437",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = 2  # With Z=2, we only need to evaluate Tplus and Tneg for when k=1\n",
    "Tplus_example = [np.array([0.1])]\n",
    "Tneg_example = [np.array([0.2])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64ccc5de-08ce-4d23-bcc4-0f19eb93f390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# |  hide\n",
    "# validate test inputs\n",
    "assert len(Tplus_example) == len(Tneg_example)\n",
    "for i, tplus in enumerate(Tplus_example):\n",
    "    assert tplus.shape == Tneg_example[i].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "011ff240-e534-4220-bd37-fb42cb30caa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixation_rate_result = fixation_rate(Tplus_example, Tneg_example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bca864e7-693c-4787-9eb7-c3416c5245fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fastcore.test.test_eq(fixation_rate_result, np.array([1/3]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f2cff06-3c08-458d-a02a-e68a1c518211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | hide\n",
    "nptyping.assert_isinstance(fixation_rate_result,\n",
    "                           nptyping.NDArray[nptyping.Shape[\"1\"], typing.Any])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f635d3-37a5-4969-a784-1875e9486665",
   "metadata": {},
   "source": [
    "We could instead consider an example where we have a mutant Defector (D) who appears in a population of Cooperators (C) playing a standard Prisoner's Dilemma.\n",
    "\n",
    "We will consider an example of such a scenario where chance of gaining/losing a D player be given by $\\frac{1}{1 + e^{\\pm \\beta \\frac{Z+1}{Z-1}}}$.\n",
    "\n",
    "The fixation rate will be given by the following expression:\n",
    "\n",
    "\\begin{equation}\n",
    "\\rho = \\frac{1}{1 + \\sum_{j=1}^{Z-1}{(\\frac{1 + e^{- \\beta \\frac{Z+1}{Z-1}}}{1 + e^{\\beta \\frac{Z+1}{Z-1}}})^j}}\n",
    "\\end{equation}\n",
    "\n",
    "For this example, we will let $\\beta=1$ and $Z=10$, so $\\beta \\frac{Z+1}{Z-1} = \\frac{11}{9}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3006c88-0cde-4e32-934e-59c97c91df6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "β = 1\n",
    "Z = 10\n",
    "ρ_CD = 1 / (1 + sum((1 + np.exp(- β * (Z + 1) / (Z-1)))**j\n",
    "                    / (1 + np.exp(β * (Z + 1) / (Z-1)))**j\n",
    "                    for j in range(1, Z)))\n",
    "Tplus_example = [np.array([1 / (1 + np.exp(- β * (Z + 1) / (Z-1)))])\n",
    "                 for _ in range(Z-1)]\n",
    "Tneg_example = [np.array([1 / (1 + np.exp(β * (Z + 1) / (Z-1)))])\n",
    "                for _ in range(Z-1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0e5b49e-be35-475b-80c1-249b248672dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# |  hide\n",
    "# validate test inputs\n",
    "assert len(Tplus_example) == len(Tneg_example)\n",
    "for i, tplus in enumerate(Tplus_example):\n",
    "    assert tplus.shape == Tneg_example[i].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "023ec211-bf09-48b8-b14a-1f7d9f2a2e10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | hide\n",
    "nptyping.assert_isinstance(fixation_rate(Tplus_example, Tneg_example),\n",
    "                           nptyping.NDArray[nptyping.Shape[\"1\"], typing.Any])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ebfa15aa-41f1-478e-8d5f-edb6f7902064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fastcore.test.is_close(fixation_rate(Tplus_example, Tneg_example), ρ_CD)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763c7ecc-6786-44ea-b479-7f8eeec3cc0d",
   "metadata": {},
   "source": [
    "Finally, it is useful to know how the fixation rate behaves when any elements of Tplus are zero (as the fixation rate divides by those elements). Even though the Fermi learning rule we use theoretically gives a number between 0 and 1 exclusive, in practise the number may underflow to a 0 if low enough. This will cause unexpected behaviour if we allow it in our alogorithm for computing the transition matrix.\n",
    "\n",
    "We can avoid this issue by using a slightly altered method for calculating the fixation rate, taking advantage of our choice to use the `fermi_learning` rule.\n",
    "\n",
    "In the above fixation rate calculations we used the `fermi_learning` function to calculate the probability of a player with strategy $D$ adopting strategy $C$ (and likewise for the probability of a player with $C$ adopting $D$). Their ratio takes the form, $\\frac{1 + e^x}{1 + e^{-x}}$. It is not too hard to verify that $\\frac{1 + e^x}{1 + e^{-x}} = e^x$.\n",
    "\n",
    "Moreover, we can avoid taking the product of the ratios at all, since the product of exponentials (with the same base) is just the exponential of the sum of their exponents.\n",
    "\n",
    "By using the above substitution and algebraic manipulation, we can substantially mitigate the numerical stability issues. For this reason, we will not use `fermi_learning` nor `fixation_rate` in our algorithm at all (although in most cases we would expect these methods to yield the same answers). Instead, we will use `fixation_rate_stable`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3822d05b-aa2c-407a-babb-0fa6dc2b7169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "@multi\n",
    "def fixation_rate_stable(ΠA: list,  # Average payoffs for the strategy A they consider adopting for each number of mutants following A\n",
    "                         ΠB: list,  # Average payoffs for the strategy B that the player currently follows for each number of mutants following A\n",
    "                         β: Array1D,  # learning rate\n",
    "                         method=\"cheap\", # method to dispatch on\n",
    "                         ):\n",
    "       return method\n",
    "\n",
    "@method(fixation_rate_stable)\n",
    "def fixation_rate_stable(ΠA: list,  # Average payoffs for the strategy A they consider adopting for each number of mutants following A\n",
    "                         ΠB: list,  # Average payoffs for the strategy B that the player currently follows for each number of mutants following A\n",
    "                         β: Array1D,  # learning rate\n",
    "                         method=None, # method to dispatch on\n",
    "                         ):\n",
    "    \"\"\"Calculate the likelihood that a mutant B invades population A\n",
    "    using a numerically stable method.\"\"\"\n",
    "    fastcore.test.test_eq(len(ΠA), len(ΠB))\n",
    "    Z = len(ΠA) + 1\n",
    "    ρ = (np.sum([np.exp(np.clip(np.sum([-β*(ΠB[j-1] - ΠA[j-1])\n",
    "                                        for j in range(1, i+1)],\n",
    "                                       axis=0,\n",
    "                                       keepdims=False),\n",
    "                                -500,\n",
    "                                500))  # avoid underflow/overflow warnings\n",
    "                 for i in range(1, Z)],\n",
    "                axis=0,\n",
    "                keepdims=False)\n",
    "         + 1)**-1\n",
    "    # The fixation rate may be very close to 0. Innacuracies with floats\n",
    "    # may mean that we run into issues later on. We assume the fixation rate\n",
    "    # never drops below 1e-10.\n",
    "#     ρ = np.maximum(ρ, 1e-15)\n",
    "    return ρ\n",
    "\n",
    "@method(fixation_rate_stable, \"cheap\")\n",
    "def fixation_rate_stable(ΠA: list,  # Average payoffs for the strategy A they consider adopting for each number of mutants following A\n",
    "                         ΠB: list,  # Average payoffs for the strategy B that the player currently follows for each number of mutants following A\n",
    "                         β: Array1D,  # learning rate\n",
    "                         method=None, # method to dispatch on\n",
    "                         ):\n",
    "    \"\"\"Calculate the likelihood that a mutant B invades population A\n",
    "    using a numerically stable method.\"\"\"\n",
    "    fastcore.test.test_eq(len(ΠA), len(ΠB))\n",
    "    Z = len(ΠA) + 1\n",
    "    # avoid underflow/overflow warnings\n",
    "    ρ = (np.sum(np.exp(np.clip(np.cumsum([-β*(ΠB[j-1] - ΠA[j-1])\n",
    "                                          for j in range(1, Z)],\n",
    "                                         axis=0),\n",
    "                               -500,\n",
    "                               500)),  \n",
    "                axis=0,\n",
    "                keepdims=False)\n",
    "         + 1)**-1\n",
    "    # The fixation rate may be very close to 0. Innacuracies with floats\n",
    "    # may mean that we run into issues later on. We assume the fixation rate\n",
    "    # never drops below 1e-10.\n",
    "#     ρ = np.maximum(ρ, 1e-15)\n",
    "    return ρ\n",
    "\n",
    "@method(fixation_rate_stable, \"cheap2\")\n",
    "def fixation_rate_stable(ΠA: list,  # Average payoffs for the strategy A they consider adopting for each number of mutants following A\n",
    "                         ΠB: list,  # Average payoffs for the strategy B that the player currently follows for each number of mutants following A\n",
    "                         β: Array1D,  # learning rate\n",
    "                         method=None, # method to dispatch on\n",
    "                         ):\n",
    "    \"\"\"Calculate the likelihood that a mutant B invades population A\n",
    "    using a numerically stable method.\"\"\"\n",
    "    fastcore.test.test_eq(len(ΠA), len(ΠB))\n",
    "    Z = len(ΠA) + 1\n",
    "    # avoid underflow/overflow warnings\n",
    "    ρ = (np.sum(2**(np.clip(np.cumsum([-β*(ΠB[j-1] - ΠA[j-1])\n",
    "                                          for j in range(1, Z)],\n",
    "                                         axis=0),\n",
    "                               -500,\n",
    "                               500)),  \n",
    "                axis=0,\n",
    "                keepdims=False)\n",
    "         + 1)**-1\n",
    "    # The fixation rate may be very close to 0. Innacuracies with floats\n",
    "    # may mean that we run into issues later on. We assume the fixation rate\n",
    "    # never drops below 1e-10.\n",
    "#     ρ = np.maximum(ρ, 1e-15)\n",
    "    return ρ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45f22eb-9d81-4cd6-86e1-c86cefbdf7b1",
   "metadata": {},
   "source": [
    "We can see in the examples which follow that both methods usually give the same answers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba97c8c5-cd72-48da-87ed-d17e2c47b950",
   "metadata": {},
   "source": [
    "To match an earlier example where `Tplus` and `Tneg` were both equal to $\\frac{1}{8}$ (as $Z=2$ we only need to consider one value for each when $k=1$), we let $\\beta=1$ and recall that $T^+_B(k) = \\frac{Z-k}{Z} \\frac{k}{Z} Pr(adopt \\, B | k) = \\frac{Z-k}{Z} \\frac{k}{Z} \\frac{1}{1 + \\exp^{-\\beta (ΠB(k) - ΠA(k))}} $\n",
    "\n",
    "We can then say that $ΠA - ΠB = \\log{(\\frac{1}{\\frac{4}{8}} - 1)} = \\log{\\frac{4}{4}} = \\log{4} - \\log{4}$\n",
    "\n",
    "Notice that to achieve netural drift, the payoffs have to be equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "22c6a3ee-2171-4ce2-a9f7-b9ad627f71ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = 2\n",
    "β = 1\n",
    "ΠA = [np.array([np.log(4)])]\n",
    "ΠB = [np.array([np.log(4)])]\n",
    "result = fixation_rate_stable(ΠA, ΠB, β)\n",
    "fastcore.test.test_close(result, 0.5)\n",
    "result = fixation_rate_stable(ΠA, ΠB, β, method=None)\n",
    "fastcore.test.test_close(result, 0.5)\n",
    "result = fixation_rate_stable(ΠA, ΠB, β, method=\"cheap\")\n",
    "fastcore.test.test_close(result, 0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab6a8b1-95c7-48fe-a235-b36a929e1dd1",
   "metadata": {},
   "source": [
    "We can also consider an example from a payoff matrix I've run into in practise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d8ccbfcc-91c7-4849-96ed-d3e3b2c1dc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "payoffs = np.array([[51, 0.6, 51],\n",
    "                    [114.3, 57.75, 39.38],\n",
    "                    [51, 0.99798, 51]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526bcead-17a7-4305-9d09-ec9e8723e672",
   "metadata": {},
   "source": [
    "We are interested in the fixation rate of a mutant B in a population of A\n",
    "\n",
    "Strategy A is the strategy represented by row 3\n",
    "\n",
    "Strategy B is the strategy represented by row 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f14ae521-1122-484a-9b61-8f5405b479a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = 100\n",
    "β = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000f38ed-56ca-4ad5-b1f2-d2e5fe19c5dd",
   "metadata": {},
   "source": [
    "We need only the average payoffs for the stable calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "afd49060-30d6-4b2b-a395-cef069f36a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "ΠA = [k/(Z-1) * payoffs[2, 1] + (Z-k-1)/(Z-1) * payoffs[2, 2]\n",
    "      for k in range(1, Z)]\n",
    "ΠB = [(k-1)/(Z-1) * payoffs[1, 1] + (Z-k)/(Z-1) * payoffs[1, 2]\n",
    "      for k in range(1, Z)]\n",
    "\n",
    "result_stable = fixation_rate_stable(ΠA, ΠB, β)\n",
    "# method=None may not be the default forever\n",
    "result_stable_none = fixation_rate_stable(ΠA, ΠB, β, method=None)\n",
    "result_stable_cheap = fixation_rate_stable(ΠA, ΠB, β, method=\"cheap\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632080d7-60ac-4ca5-976c-e90a7087c5a5",
   "metadata": {},
   "source": [
    "We also need the adoption rates for the unstable calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b007792b-11a9-4ff4-97fc-8f5efaa0823f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tneg = [fermi_learning(ΠB[k-1], ΠA[k-1], β)\n",
    "        for k in range(1, Z)]\n",
    "Tplus = [fermi_learning(ΠA[k-1], ΠB[k-1], β)\n",
    "         for k in range(1, Z)]\n",
    "\n",
    "# Naiive and unstable calculation\n",
    "result_unstable = fixation_rate(Tplus, Tneg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c007dbe6-4a3f-4f39-8ffe-88c4ba52df67",
   "metadata": {},
   "outputs": [],
   "source": [
    "fastcore.test.test_close(result_stable, 0)\n",
    "fastcore.test.test_close(result_stable_none, 0)\n",
    "fastcore.test.test_close(result_stable_cheap, 0)\n",
    "fastcore.test.test_close(result_unstable, 0)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4e080b7d",
   "metadata": {},
   "source": [
    "In terms of efficiency, the `\"cheap\"` method is much faster for\n",
    "computing `fixation_rate_stable`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "680d0d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = 2\n",
    "β = 1\n",
    "ΠA = [np.log(np.array([4 for _ in range(int(1e6))])) for _ in range(100)]\n",
    "ΠB = [np.log(np.array([4 for _ in range(int(1e6))])) for _ in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8525b767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = fixation_rate_stable(ΠA, ΠB, β, method=None)\n",
    "# fastcore.test.test_close(result[0], 1/101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e5e22c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = fixation_rate_stable(ΠA, ΠB, β, method=\"cheap\")\n",
    "# fastcore.test.test_close(result[0], 1/101)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c827802-97f6-4bf4-a626-3e8db969fb97",
   "metadata": {},
   "source": [
    "### Build transition matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd8d5bc-dfd0-4a4b-a750-9ecec7fdd117",
   "metadata": {},
   "source": [
    "Recall that step 1 of finding the solution to the Evolutionary Game dynamics is to build a transition matrix between all monomorphic states. \n",
    "\n",
    "The transition matrix captures the probability that if the population of the Evolutionary Game transitions to another state. We read an entry of the transition matrix as saying the probability of transitioning from the row state to column state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "932859e9-a0bb-48c3-9853-7ff72c997165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class ModelTypeEGT():\n",
    "    \"\"\"This is the schema for an Evolutionary Game Theory model.\n",
    "\n",
    "    Note: This schema is not enforced and is here purely for documentation\n",
    "    purposes.\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 Z: int,  # the size of the population\n",
    "                 strategy_set: list[str],  # the set of strategies in the model\n",
    "                 β: Array1D,  # the learning rate\n",
    "                 payoffs: Array3D,  # the payoffs of the game\n",
    "                 transition_matrix: Array3D = None,  # the model's transition matrix\n",
    "                 ergodic: Array2D = None,  # ergodic distribution of the model's markov chain\n",
    "                 ):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "61aaa4a8-200c-4bbe-b6bb-34ed13151248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/PaoloBova/gh-pages-example/blob/main/gh_pages_example/methods.py#L153){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ModelTypeEGT\n",
       "\n",
       ">      ModelTypeEGT (Z:int, strategy_set:list[str],\n",
       ">                    β:gh_pages_example.types.Array1D,\n",
       ">                    payoffs:gh_pages_example.types.Array3D,\n",
       ">                    transition_matrix:gh_pages_example.types.Array3D=None,\n",
       ">                    ergodic:gh_pages_example.types.Array2D=None)\n",
       "\n",
       "This is the schema for an Evolutionary Game Theory model.\n",
       "\n",
       "Note: This schema is not enforced and is here purely for documentation\n",
       "purposes.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| Z | int |  | the size of the population |\n",
       "| strategy_set | list |  | the set of strategies in the model |\n",
       "| β | Array1D |  | the learning rate |\n",
       "| payoffs | Array3D |  | the payoffs of the game |\n",
       "| transition_matrix | Array3D | None | the model's transition matrix |\n",
       "| ergodic | Array2D | None | ergodic distribution of the model's markov chain |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/PaoloBova/gh-pages-example/blob/main/gh_pages_example/methods.py#L153){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ModelTypeEGT\n",
       "\n",
       ">      ModelTypeEGT (Z:int, strategy_set:list[str],\n",
       ">                    β:gh_pages_example.types.Array1D,\n",
       ">                    payoffs:gh_pages_example.types.Array3D,\n",
       ">                    transition_matrix:gh_pages_example.types.Array3D=None,\n",
       ">                    ergodic:gh_pages_example.types.Array2D=None)\n",
       "\n",
       "This is the schema for an Evolutionary Game Theory model.\n",
       "\n",
       "Note: This schema is not enforced and is here purely for documentation\n",
       "purposes.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| Z | int |  | the size of the population |\n",
       "| strategy_set | list |  | the set of strategies in the model |\n",
       "| β | Array1D |  | the learning rate |\n",
       "| payoffs | Array3D |  | the payoffs of the game |\n",
       "| transition_matrix | Array3D | None | the model's transition matrix |\n",
       "| ergodic | Array2D | None | ergodic distribution of the model's markov chain |"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(ModelTypeEGT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "525269fc-1afe-4e7b-9e72-c7f6f6596cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "# | hide\n",
    "@multi\n",
    "def build_transition_matrix(models: dict  # A dictionary that contains the parameters in `ModelTypeEGT`\n",
    "                            ):\n",
    "    \"\"\"Build a transition matrix between all monomorphic states using the\n",
    "    fermi social learning rule.\"\"\"\n",
    "    return models.get('dispatch-type')\n",
    "\n",
    "\n",
    "@method(build_transition_matrix)\n",
    "def build_transition_matrix(models: dict  # A dictionary that contains the parameters in `ModelTypeEGT`\n",
    "                            ):\n",
    "    \"\"\"Build a transition matrix between all monomorphic states\n",
    "    using the fermi social learning rule for each model.    \n",
    "    \"\"\"\n",
    "\n",
    "    Z, S, β = [models[k] for k in ['Z', 'strategy_set', 'β']]\n",
    "    π = models['payoffs']\n",
    "    n_models = π.shape[0]\n",
    "    M = np.zeros((n_models, len(S), len(S)))\n",
    "    for row_ind, s in enumerate(S):\n",
    "        for col_ind, sₒ in enumerate(S):\n",
    "            if row_ind == col_ind:\n",
    "                M[:, row_ind, row_ind] += 1\n",
    "                # We calibrate these entries later so rows add up to 1\n",
    "                continue\n",
    "            πAA = π[:, row_ind, row_ind]\n",
    "            πAB = π[:, row_ind, col_ind]\n",
    "            πBA = π[:, col_ind, row_ind]\n",
    "            πBB = π[:, col_ind, col_ind]\n",
    "            ΠA = [πAA*(Z-k-1)/(Z-1) + πAB*k/(Z-1)\n",
    "                  for k in range(1, Z)]\n",
    "            ΠB = [πBA*(Z-k)/(Z-1) + πBB*(k-1)/(Z-1)\n",
    "                  for k in range(1, Z)]\n",
    "            # We use a numerically stable method to find the fixation rate, ρ.\n",
    "            # ρ is the probability that mutant B successfully invades A\n",
    "            ρ = fixation_rate_stable(ΠA, ΠB, β)\n",
    "            M[:, row_ind, col_ind] = ρ / max(1, len(S)-1)\n",
    "            M[:, row_ind, row_ind] -= ρ / max(1, len(S)-1)\n",
    "    return {**models, \"transition_matrix\": M}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7e727d1b-c3a9-411c-89b4-e4483a4d32fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "# | hide\n",
    "@method(build_transition_matrix, 'unstable')\n",
    "def build_transition_matrix(models: dict  # A dictionary that contains the parameters in `ModelTypeEGT`\n",
    "                            ):\n",
    "    \"\"\"Build a transition matrix using a numerically unstable method.\"\"\"\n",
    "\n",
    "    Z, S, β = [models[k] for k in ['Z', 'strategy_set', 'β']]\n",
    "    π = models['payoffs']\n",
    "    n_models = π.shape[0]\n",
    "    M = np.zeros((n_models, len(S), len(S)))\n",
    "    for row_ind, s in enumerate(S):\n",
    "        for col_ind, sₒ in enumerate(S):\n",
    "            if row_ind == col_ind:\n",
    "                M[:, row_ind, row_ind] += 1\n",
    "                # We calibrate these entries later so rows add up to 1\n",
    "                continue\n",
    "            πAA = π[:, row_ind, row_ind]\n",
    "            πAB = π[:, row_ind, col_ind]\n",
    "            πBA = π[:, col_ind, row_ind]\n",
    "            πBB = π[:, col_ind, col_ind]\n",
    "            ΠA = [πAA*(Z-k-1)/(Z-1) + πAB*k/(Z-1)\n",
    "                  for k in range(1, Z)]\n",
    "            ΠB = [πBA*(Z-k)/(Z-1) + πBB*(k-1)/(Z-1)\n",
    "                  for k in range(1, Z)]\n",
    "            Tneg = [fermi_learning(ΠB[k-1], ΠA[k-1], β)\n",
    "                    for k in range(1, Z)]\n",
    "            Tplus = [fermi_learning(ΠA[k-1], ΠB[k-1], β)\n",
    "                     for k in range(1, Z)]\n",
    "            ρ = fixation_rate(Tplus, Tneg)\n",
    "            M[:, row_ind, col_ind] = ρ / max(1, len(S)-1)\n",
    "            M[:, row_ind, row_ind] -= ρ / max(1, len(S)-1)\n",
    "    return {**models, \"transition_matrix\": M}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "28cfebf8-5411-4d33-89b6-cf010a272b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/PaoloBova/gh-pages-example/blob/main/gh_pages_example/methods.py#L1612){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### build_transition_matrix\n",
       "\n",
       ">      build_transition_matrix (models:dict)\n",
       "\n",
       "Build a transition matrix between all monomorphic states using the\n",
       "fermi social learning rule.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| models | dict | A dictionary that contains the parameters in `ModelTypeEGT` |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/PaoloBova/gh-pages-example/blob/main/gh_pages_example/methods.py#L1612){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### build_transition_matrix\n",
       "\n",
       ">      build_transition_matrix (models:dict)\n",
       "\n",
       "Build a transition matrix between all monomorphic states using the\n",
       "fermi social learning rule.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| models | dict | A dictionary that contains the parameters in `ModelTypeEGT` |"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(build_transition_matrix.__dispatch_fn__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098a1361-4d6c-4eb5-8c6f-6df0a2ab8938",
   "metadata": {},
   "source": [
    "#### Examples and Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25222a93-d57e-47b9-abb6-d1280b5d99a3",
   "metadata": {},
   "source": [
    "Consider the following two examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b182c962-85a7-4812-aa09-d5a9487909fd",
   "metadata": {},
   "source": [
    "**Example 1**\n",
    "\n",
    "Let all payoffs be equal in the game's payoff matrix. All expected payoffs will be equal too.\n",
    "\n",
    "So, Fermi learning will say that each individual has a 50% chance of adopting the behaviour of the one they observe.\n",
    "\n",
    "We therefore have an equal chance during each epoch of gaining or losing an individual of the given type, in this example we denote the type as $s \\in \\{A, B\\}$, although this probability depends on population size $Z$ and the current number of individuals of that type, $k$, $T^+_s(k) = T^-_s(k) = \\frac{Z-k}{Z} \\frac{k}{Z} \\frac{1}{2}$.\n",
    "\n",
    "Recall that we calculate the fixation rate, $\\rho$ as follows:\n",
    "\\begin{equation}\n",
    "\\rho = \\frac{1}{1 + \\sum_{j=1}^{N-1}{\\prod_{k=1}^{j} \\frac{b_k}{a_k}}}\n",
    "\\end{equation}\n",
    "where $N=Z$, $b_k = T^-_s(k)$ and $a_k = T^+_s(k)$\n",
    "\n",
    "In this example, for each strategy $s$, $T^-_s(k) = T^+_s(k), \\, \\forall k$, so $\\rho = \\frac{1}{Z}$.\n",
    "\n",
    "We only have $2$ strategies, and $Z=10$, so the final transition matrix will look like\n",
    "\n",
    "\\begin{equation}\n",
    "M \\, = \\, \\begin{pmatrix}\n",
    "1 - \\frac{\\rho}{2 - 1} & \\frac{\\rho}{2 - 1} &\\\\\n",
    "\\frac{\\rho}{2 - 1} & 1 - \\frac{\\rho}{2 - 1}\\\\\n",
    "\\end{pmatrix}\n",
    "= \\begin{pmatrix}\n",
    "0.9 & 0.1 &\\\\\n",
    "0.1 & 0.9\\\\\n",
    "\\end{pmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "Note that the above example describes neutral drift, the idea that even if there is no advantage to be gained from any particular strategy, social learning can still result in the spread of that behaviour. Neutral drift also occurs if we set the Fermi learning rate $\\beta = 0$, no matter what payoff matrix describes the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b0b51afb-7c71-4fed-a636-a67705304ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "payoffs = np.array([[[2, 2],\n",
    "                     [2, 2]]\n",
    "                    ])\n",
    "Z = 10\n",
    "β = 1\n",
    "models = {\"payoffs\": payoffs,\n",
    "          \"Z\": Z,\n",
    "          \"β\": β,\n",
    "          \"strategy_set\": [\"A\", \"B\"],\n",
    "          }\n",
    "result = build_transition_matrix(models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "16d41c9a-9ad4-482f-a003-63eb6477a2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fastcore.test.test_close(result['transition_matrix'],\n",
    "                         np.array([[0.9, 0.1],\n",
    "                                   [0.1, 0.9]]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a32d142-e5ae-455d-b782-117edb407a10",
   "metadata": {},
   "source": [
    "**Example 2**\n",
    "\n",
    "Let the payoff matrix be akin to a Prisoner's Dilemma with two strategies, $C$ or $D$ (Cooperate or Defect respectively):\n",
    "\n",
    "\\begin{pmatrix}\n",
    "2 & 0\\\\\n",
    "3 & 1\\\\\n",
    "\\end{pmatrix}\n",
    "\n",
    "Again, for this simple example, the relative average success of strategy $C$ is independent of the number of $C$ players, $k$. This is rarely the case in practise but permits a more legible example.\n",
    "\n",
    "$C$'s relative success over $D$ will be $\\frac{2 (k-1)}{Z-1} - \\frac{3 k + (Z - k - 1)}{Z-1} = - \\frac{Z + 1}{Z-1}$.\n",
    "\n",
    "Fermi learning means the probability of a $D$ player adopting what they see $C$ do is:\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{1}{1 + e^{- \\beta (\\Pi_C(k) - \\Pi_D(k))}} = \\frac{1}{1 + e^{\\beta \\frac{Z + 1}{Z-1}}}\n",
    "\\end{equation}\n",
    "\n",
    "The fixation rate for mutant $C$ in a population of $D$ players, $\\rho_{DC}$, can be computed as\n",
    "\n",
    "\\begin{equation}\n",
    "\\rho_{DC} = \\frac{1}{1 + \\sum_{j=1}^{Z-1}{(\\frac{1 + e^{\\beta \\frac{Z + 1}{Z-1}}}{1 + e^{-\\beta \\frac{Z + 1}{Z-1}}})^j}}\n",
    "\\end{equation}\n",
    "\n",
    "Similarly, the fixation rate for mutant $D$ in a population of $C$ players, $\\rho_{CD}$, can be computed as \n",
    "\n",
    "\\begin{equation}\n",
    "\\rho_{CD} = \\frac{1}{1 + \\sum_{j=1}^{Z-1}{(\\frac{1 + e^{-\\beta \\frac{Z + 1}{Z-1}}}{1 + e^{\\beta \\frac{Z + 1}{Z-1}}})^j}}\n",
    "\\end{equation}\n",
    "\n",
    "For $Z=10$ and $\\beta = 1$, the above yields the following transition matrix,\n",
    "\n",
    "\\begin{equation}\n",
    "M \\, = \\, \\begin{pmatrix}\n",
    "1 - \\frac{\\rho_{CD}}{2 - 1} & \\frac{\\rho_{CD}}{2 - 1} &\\\\\n",
    "\\frac{\\rho_{DC}}{2 - 1} & 1 - \\frac{\\rho_{DC}}{2 - 1}\\\\\n",
    "\\end{pmatrix}\n",
    "\\approx \\begin{pmatrix}\n",
    "0.295 & 0.705 &\\\\\n",
    "0.000 & 1.000\\\\\n",
    "\\end{pmatrix}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06de05f4-e0b9-4cbb-963c-18b83039e7d4",
   "metadata": {},
   "source": [
    "\n",
    "Note how in the above fixation rate calculations how we used the `fermi_learning` function to calculate the probability of a player with strategy $D$ adopting strategy $C$ (and likewise for the probability of a player with $C$ adopting $D$). This function has special properties which aid us in calculating the fixation rate.\n",
    "\n",
    "Notice how the ratio of the two adoption rates takes the form, $\\frac{1 + e^x}{1 + e^{-x}}$. It is not too hard to verify that $\\frac{1 + e^x}{1 + e^{-x}} = e^x$.\n",
    "\n",
    "We utilities this property to considerably improve the numerical stability of our algorithm for building a transition matrix. For this reason, we do not use `fermi_learning` in our algorithm at all.\n",
    "\n",
    "We can similarly note that $\\frac{1}{1 + e^{-x}} = 1 - \\frac{1}{1 + e^{x}}$, i.e. the two adoption rates are complementary probabilities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6e885818-dcfd-4443-9ae3-2c616b8e976e",
   "metadata": {},
   "outputs": [],
   "source": [
    "payoffs = np.array([[[2, 0],\n",
    "                     [3, 1]],\n",
    "                    ])\n",
    "Z = 10\n",
    "β = 1\n",
    "models = {\"payoffs\": payoffs,\n",
    "          \"Z\": Z,\n",
    "          \"β\": β,\n",
    "          \"strategy_set\": [\"C\", \"D\"],\n",
    "          }\n",
    "result = build_transition_matrix(models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f1f9b18d-a668-430f-8fcf-a9702fbfd9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ρ_CD = 1 / (1 + sum((1 + np.exp(- β * (Z + 1) / (Z-1)))**j\n",
    "                    / (1 + np.exp(β * (Z + 1) / (Z-1)))**j\n",
    "                    for j in range(1, Z)))\n",
    "ρ_DC = 1 / (1 + sum((1 + np.exp(β * (Z + 1) / (Z-1)))**j\n",
    "                    / (1 + np.exp(- β * (Z + 1) / (Z-1)))**j\n",
    "                    for j in range(1, Z)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "96de16cf-c528-4dfd-aeb2-e349a3811415",
   "metadata": {},
   "outputs": [],
   "source": [
    "ρ_CD_alt = 1 / (1 + sum(np.exp(- j * β * (Z + 1) / (Z-1))\n",
    "                        for j in range(1, Z)))\n",
    "ρ_DC_alt = 1 / (1 + sum(np.exp(j * β * (Z + 1) / (Z-1))\n",
    "                        for j in range(1, Z)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "41ede78a-9d20-4bfa-92b3-61ae7a4096a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fastcore.test.test_close(ρ_CD, ρ_CD_alt)\n",
    "fastcore.test.test_close(ρ_DC, ρ_DC_alt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "deed5ac3-48a9-47ea-86b8-d3a1135077fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fastcore.test.test_close(result['transition_matrix'],\n",
    "                         np.array([[1 - ρ_CD, ρ_CD],\n",
    "                                   [ρ_DC, 1 - ρ_DC]]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e68e50-329b-4e8d-b3cb-9b81e051384c",
   "metadata": {},
   "source": [
    "#### Example 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c81be48-0a09-488f-94f0-dc60127c454e",
   "metadata": {},
   "source": [
    "Here is an additional example for the 3 by 3 matrix we discussed when testing other functions.\n",
    "\n",
    "This time, we make sure we get the correct probabilities for each transition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1a94eb04-dcff-4d54-a218-d90c5137eaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "payoffs = np.array([[[51, 0.6, 51],\n",
    "                     [114.3, 57.75, 39.38],\n",
    "                     [51, 0.99798, 51]],\n",
    "                    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "eb4dd779-f4db-4347-a0a2-e78a9bd85738",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected = np.array([[[0.495, 0.5, 0.005],\n",
    "                     [0, 1, 0],\n",
    "                     [0.005, 0, 0.995]],\n",
    "                     ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c3abd346-2a8a-4f0d-8136-7a56fa4f4bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = 100\n",
    "β = 1\n",
    "models = {\"payoffs\": payoffs,\n",
    "          \"Z\": Z,\n",
    "          \"β\": β,\n",
    "          \"strategy_set\": [\"AS\", \"AU\", \"PS\"],\n",
    "          }\n",
    "result = build_transition_matrix(models)\n",
    "fastcore.test.test_close(result['transition_matrix'], expected)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf604f74-2729-4ac9-bbfc-f1cf1fa4a9fc",
   "metadata": {},
   "source": [
    "### Find ergodic strategy distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aced671-f623-440b-ab31-c0d200ee0729",
   "metadata": {},
   "source": [
    "Step 2 is to find the ergodic distribution for the Evolutionary Game using the transition matrix we constructed in step 1.\n",
    "\n",
    "Let $M$ denote the transition matrix, and $\\omega_t$ be the column vector describing the proportions with which each strategy is played in the population.\n",
    "\n",
    "We can describe the evolution of this system with $\\omega_{t+1} = M^T \\omega_t$, i.e. the proportion of players that use a given strategy in the next round will be equal to the sum of the proportions of players for each strategy who adopted that strategy in the current round. Equivalently, we can also consider $\\omega_t$ as describing the probabilities that the system at time t is in each of the monomorphic states.\n",
    "\n",
    "As each of the monomporphic states described in the transition matrix is reachable from any other with some probability and since the transition probabilities only depend on the current state, what we have is a markov chain which is irreducible.\n",
    "\n",
    "The ergodicity theorem guarantees that such irreducible and aperiodic markov chains have an ergodic distribution that the system converges to, no matter where it starts. An ergodic distribution (also called a stationary distribution),  $\\omega^*$ satisfies  $\\omega^* = M^T \\omega^*$ [[1]](https://gregorygundersen.com/blog/2019/10/28/ergodic-markov-chains/) [[2]](http://www.stat.columbia.edu/~liam/teaching/neurostat-spr11/papers/mcmc/Ergodicity_Theorem.pdf) [[3]](https://textbooks.math.gatech.edu/ila/1553/stochastic-matrices.html).\n",
    "\n",
    "Our ergodic distribution, $\\omega^*$, is therefore defined as the normalised right-hand eigenvector with eigenvalue 1 of the transposed transition matrix, $M^T$ (or equivalently, if we defined $\\omega$ as a row vector instead, $\\omega^*$ would be the left-hand eigenvector with eigenvalue 1 of transition matrix, $M$; numerical computing packages usually return the right-hand eigenvectors more directly, which is why I used the other formalism).\n",
    "\n",
    "We use standard linear algebra methods from the [numpy](https://numpy.org/) package to find this eigenvector. These numerical methods will usually not return an eigenvector which is normalised to sum to 1, so we must normalise the eigenvector we are given. See their documentation to learn more about these numerical methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f8c98786-9d06-4471-b322-a90e521e6fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def find_ergodic_distribution(models: dict  # A dictionary that contains the parameters in `ModelTypeEGT`\n",
    "                              ):\n",
    "    \"\"\"Find the ergodic distribution of a markov chain with the\n",
    "    given transition matrix.\"\"\"\n",
    "    M = models[\"transition_matrix\"]\n",
    "    # find unit eigenvector of markov chain\n",
    "    Λ, V = np.linalg.eig(M.transpose(0, 2, 1))\n",
    "    V = np.real_if_close(V)\n",
    "    x = np.isclose(Λ, 1)\n",
    "    # if multiple unit eigenvalues then choose the first\n",
    "    y = np.zeros_like(x, dtype=bool)\n",
    "    idx = np.arange(len(x)), x.argmax(axis=1)\n",
    "    y[idx] = x[idx]\n",
    "    ergodic = np.array(V.transpose(0, 2, 1)[y], dtype=float)\n",
    "    # ensure ergodic frequencies are positive and sum to 1\n",
    "    ergodic = np.abs(ergodic) / np.sum(np.abs(ergodic), axis=1)[:, None]\n",
    "    return {**models, 'ergodic': ergodic}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e63ecf01",
   "metadata": {},
   "source": [
    "#### An exploration of EGT Tools Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a4c993f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@multi\n",
    "def calculate_stationary_distribution(transition_matrix: Union[np.ndarray, csr_matrix, csc_matrix],\n",
    "                                      method=None):\n",
    "    \"\"\"A multimethod for calculating the stationary distribution of different\n",
    "    types of matrices.\"\"\"\n",
    "    return method\n",
    "\n",
    "@method(calculate_stationary_distribution)\n",
    "def calculate_stationary_distribution(transition_matrix: Union[np.ndarray, csr_matrix, csc_matrix], # A single 2D transition matrix or a 3D array containing a stack of transition matrices\n",
    "                                      method=None # The method to use to find the statonary distribution, the default approach relies on using `numpy.linalg.eig` which is not recommended for non-hermitian matrices. Use \"shcur\" if matrix is non-hermitian.\n",
    "                                      ) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculates stationary distribution from a transition matrix of Markov chain.\n",
    "\n",
    "    The use of this function is not recommended if the matrix is non-Hermitian. Please use\n",
    "    calculate_stationary_distribution_non_hermitian instead in this case.\n",
    "\n",
    "    The stationary distribution is the normalized eigenvector associated with the eigenvalue 1\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    transition_matrix : Union[numpy.ndarray, scipy.sparse.csr_matrix, scipy.sparse.csc_matrix]\n",
    "        A 2 dimensional transition matrix\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        A 1-dimensional vector containing the stationary distribution\n",
    "\n",
    "    See Also\n",
    "    --------\n",
    "    egttools.utils.calculate_stationary_distribution_non_hermitian\n",
    "\n",
    "    \"\"\"\n",
    "    if (type(transition_matrix) == csr_matrix) or (type(transition_matrix) == csc_matrix):\n",
    "        tmp = transition_matrix.toarray()\n",
    "    else:\n",
    "        tmp = transition_matrix\n",
    "        \n",
    "    if np.ndim(transition_matrix)==2:\n",
    "        tmp = transition_matrix[None, ...]\n",
    "    \n",
    "    # Check if there is any transition with value 1 - this would mean that the game is degenerate\n",
    "    if np.isclose(tmp, 1., atol=1e-11).any():\n",
    "        warn(\n",
    "            \"Some of the entries in the transition matrix are close to 1 (with a tolerance of 1e-11). \"\n",
    "            \"This could result in more than one eigenvalue of magnitute 1 \"\n",
    "            \"(the Markov Chain is degenerate), so please be careful when analysing the results.\", RuntimeWarning)\n",
    "        \n",
    "    # `numpy.linalg.eig` returns the right-handed eigenvectors so we need to tranpose our transition matrices first.\n",
    "    tmp = tmp.transpose(0, 2, 1)\n",
    "\n",
    "    # calculate stationary distributions using eigenvalues and eigenvectors\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(tmp)\n",
    "    \n",
    "    # look for the first element closest to 1 in the list of eigenvalues\n",
    "    index_stationary = (np.arange(len(eigenvalues)),\n",
    "                        np.argmin(np.abs(eigenvalues - 1.0), axis=-1))\n",
    "    mask_stationary = np.zeros_like(eigenvalues, dtype=bool)\n",
    "    mask_stationary[index_stationary] = True\n",
    "    sd = np.abs(eigenvectors.transpose(0, 2, 1)[mask_stationary].real)\n",
    "    return sd / np.sum(sd, axis=-1)[:, None]  # normalize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c6bc1744",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@method(calculate_stationary_distribution, \"schur\")\n",
    "def calculate_stationary_distribution(transition_matrix: Union[np.ndarray, csr_matrix, csc_matrix], # A single 2D transition matrix or a 3D array containing a stack of transition matrices\n",
    "                                      method=None # The method to use to find the statonary distribution, the default approach relies on using `numpy.linalg.eig` which is not recommended for non-hermitian matrices. Use \"shcur\" if matrix is non-hermitian.\n",
    "                                      ) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculates stationary distribution from a transition matrix of Markov chain.\n",
    "\n",
    "    The stationary distribution is the normalized eigenvector associated with the eigenvalue 1\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    transition_matrix : Union[numpy.ndarray, scipy.sparse.csr_matrix, scipy.sparse.csc_matrix]\n",
    "        A 2 dimensional transition matrix\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        A 1-dimensional vector containing the stationary distribution\n",
    "\n",
    "    See Also\n",
    "    --------\n",
    "    egttools.utils.calculate_stationary_distribution_non_hermitian\n",
    "\n",
    "    \"\"\"\n",
    "    if (type(transition_matrix) == csr_matrix) or (type(transition_matrix) == csc_matrix):\n",
    "        tmp = transition_matrix.toarray()\n",
    "    else:\n",
    "        tmp = transition_matrix\n",
    "        \n",
    "    if np.ndim(transition_matrix)==2:\n",
    "        tmp = transition_matrix[None, ...]\n",
    "    \n",
    "    # Check if there is any transition with value 1 - this would mean that the game is degenerate\n",
    "    if np.isclose(tmp, 1., atol=1e-11).any():\n",
    "        warn(\n",
    "            \"Some of the entries in the transition matrix are close to 1 (with a tolerance of 1e-11). \"\n",
    "            \"This could result in more than one eigenvalue of magnitute 1 \"\n",
    "            \"(the Markov Chain is degenerate), so please be careful when analysing the results.\", RuntimeWarning)\n",
    "\n",
    "    # calculate stationary distributions using eigenvalues and eigenvectors\n",
    "    schur_results = [schur(m) for m in tmp]\n",
    "    eigenvectors = np.array([r[1] for r in schur_results]).real\n",
    "    eigenvalues = np.array([eigvals(r[0]) for r in schur_results]).real\n",
    "    # look for the first element closest to 1 in the list of eigenvalues\n",
    "    index_stationary = (np.arange(len(eigenvalues)),\n",
    "                        np.argmin(np.abs(eigenvalues - 1.0), axis=-1))\n",
    "    mask_stationary = np.zeros_like(eigenvalues, dtype=bool)\n",
    "    mask_stationary[index_stationary] = True\n",
    "    sd = np.abs(eigenvectors[mask_stationary].real)\n",
    "    return sd / np.sum(sd, axis=-1)[:, None]  # normalize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "35213f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def gth_solve(A, overwrite=False):\n",
    "    r\"\"\"\n",
    "    This routine computes the stationary distribution of an irreducible\n",
    "    Markov transition matrix (stochastic matrix) or transition rate\n",
    "    matrix (generator matrix) `A`.\n",
    "    More generally, given a Metzler matrix (square matrix whose\n",
    "    off-diagonal entries are all nonnegative) `A`, this routine solves\n",
    "    for a nonzero solution `x` to `x (A - D) = 0`, where `D` is the\n",
    "    diagonal matrix for which the rows of `A - D` sum to zero (i.e.,\n",
    "    :math:`D_{ii} = \\sum_j A_{ij}` for all :math:`i`). One (and only\n",
    "    one, up to normalization) nonzero solution exists corresponding to\n",
    "    each reccurent class of `A`, and in particular, if `A` is\n",
    "    irreducible, there is a unique solution; when there are more than\n",
    "    one solution, the routine returns the solution that contains in its\n",
    "    support the first index `i` such that no path connects `i` to any\n",
    "    index larger than `i`. The solution is normalized so that its 1-norm\n",
    "    equals one. This routine implements the Grassmann-Taksar-Heyman\n",
    "    (GTH) algorithm [1]_, a numerically stable variant of Gaussian\n",
    "    elimination, where only the off-diagonal entries of `A` are used as\n",
    "    the input data. For a nice exposition of the algorithm, see Stewart\n",
    "    [2]_, Chapter 10.\n",
    "    Parameters\n",
    "    ----------\n",
    "    A : array_like(float, ndim=2)\n",
    "        Stochastic matrix or generator matrix. Must be of shape n x n.\n",
    "    Returns\n",
    "    -------\n",
    "    x : numpy.ndarray(float, ndim=1)\n",
    "        Stationary distribution of `A`.\n",
    "    overwrite : bool, optional(default=False)\n",
    "        Whether to overwrite `A`.\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] W. K. Grassmann, M. I. Taksar and D. P. Heyman, \"Regenerative\n",
    "       Analysis and Steady State Distributions for Markov Chains,\"\n",
    "       Operations Research (1985), 1107-1116.\n",
    "    .. [2] W. J. Stewart, Probability, Markov Chains, Queues, and\n",
    "       Simulation, Princeton University Press, 2009.\n",
    "    \"\"\"\n",
    "    A1 = np.array(A, dtype=float, copy=not overwrite, order='C')\n",
    "    # `order='C'` is for use with Numba <= 0.18.2\n",
    "    # See issue github.com/numba/numba/issues/1103\n",
    "\n",
    "    if len(A1.shape) != 2 or A1.shape[0] != A1.shape[1]:\n",
    "        raise ValueError('matrix must be square')\n",
    "\n",
    "    n = A1.shape[0]\n",
    "    x = np.zeros(n)\n",
    "\n",
    "    # === Reduction === #\n",
    "    for k in range(n-1):\n",
    "        scale = np.sum(A1[k, k+1:n])\n",
    "        if scale <= 0:\n",
    "            # There is one (and only one) recurrent class contained in\n",
    "            # {0, ..., k};\n",
    "            # compute the solution associated with that recurrent class.\n",
    "            n = k+1\n",
    "            break\n",
    "        A1[k+1:n, k] /= scale\n",
    "\n",
    "        A1[k+1:n, k+1:n] += np.dot(A1[k+1:n, k:k+1], A1[k:k+1, k+1:n])\n",
    "\n",
    "    # === Backward substitution === #\n",
    "    x[n-1] = 1\n",
    "    for k in range(n-2, -1, -1):\n",
    "        x[k] = np.dot(x[k+1:n], A1[k+1:n, k])\n",
    "\n",
    "    # === Normalization === #\n",
    "    x /= np.sum(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dd586419",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@method(calculate_stationary_distribution, \"quantecon\")\n",
    "def calculate_stationary_distribution(transition_matrix: Union[np.ndarray, csr_matrix, csc_matrix], # A single 2D transition matrix or a 3D array containing a stack of transition matrices\n",
    "                                      method=None # The method to use to find the statonary distribution, the default approach relies on using `numpy.linalg.eig` which is not recommended for non-hermitian matrices. Use \"shcur\" if matrix is non-hermitian.\n",
    "                                      ) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculates stationary distribution from a transition matrix of Markov chain.\n",
    "\n",
    "    The stationary distribution is the normalized eigenvector associated with the eigenvalue 1\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    transition_matrix : Union[numpy.ndarray, scipy.sparse.csr_matrix, scipy.sparse.csc_matrix]\n",
    "        A 2 dimensional transition matrix\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        A 1-dimensional vector containing the stationary distribution\n",
    "\n",
    "    See Also\n",
    "    --------\n",
    "    egttools.utils.calculate_stationary_distribution_non_hermitian\n",
    "\n",
    "    \"\"\"\n",
    "    if (type(transition_matrix) == csr_matrix) or (type(transition_matrix) == csc_matrix):\n",
    "        tmp = transition_matrix.toarray()\n",
    "    else:\n",
    "        tmp = transition_matrix\n",
    "        \n",
    "    if np.ndim(transition_matrix)==2:\n",
    "        tmp = transition_matrix[None, ...]\n",
    "    \n",
    "    # Check if there is any transition with value 1 - this would mean that the game is degenerate\n",
    "    if np.isclose(tmp, 1., atol=1e-11).any():\n",
    "        warn(\n",
    "            \"Some of the entries in the transition matrix are close to 1 (with a tolerance of 1e-11). \"\n",
    "            \"This could result in more than one eigenvalue of magnitute 1 \"\n",
    "            \"(the Markov Chain is degenerate), so please be careful when analysing the results.\", RuntimeWarning)\n",
    "    return np.array([gth_solve(p) for p in tmp])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a216e60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def calculate_sd_helper(models):\n",
    "    P =  models['transition_matrix']\n",
    "    sd = calculate_stationary_distribution(P, method=models.get('sd-method'))\n",
    "    return {**models, \"ergodic\": sd }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eb548f04",
   "metadata": {},
   "source": [
    "#### A brief note on the quantecon method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd6edc3",
   "metadata": {},
   "source": [
    "\n",
    "Quantecon.py have a class MarkovChain which checks for the number of recurrence\n",
    "classes in the matrix before looking for stationary distributions for each one\n",
    "using the GTH algorithm. I noticed that finding the recurrence classes is much more\n",
    "expensive the finding the stationary distributions (at least for smaller matrices).\n",
    "\n",
    "Moreover, the transition matrices that we build for Moran and similar evolutionary\n",
    "processes are technically irreducible by construction (in other words, they only\n",
    "have one recurrence class). I therefore skip the search for recurence classes and\n",
    "simply call the `gth_solve` function (lightly edited from Quantecon.py) to find\n",
    "the stationary distribution.\n",
    "\n",
    "Additional note: there are numerical difficulties to ensuring our transition matrices\n",
    "are actually irreducible. We deal with these when computing the fixation rates in\n",
    "`fixation_rate_stable`. As it is plausible that this method could be used for more general\n",
    "transition matrices (e.g. when computing the payoffs of a stochastic game), we leave in a\n",
    "warning when the matrix is close to being degenerate (i.e. reducible)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0249dbbc-12f1-4cee-8488-c5f755216cf9",
   "metadata": {},
   "source": [
    "#### Examples and Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb2ae7f-f94f-4b54-90eb-ec4af9077aba",
   "metadata": {},
   "source": [
    "Let our transition matrix, $M$ be\n",
    "\n",
    "\\begin{equation}\n",
    "M = \\begin{pmatrix}\n",
    "\\frac{3}{4} & \\frac{1}{4} \\\\\n",
    "\\frac{1}{4} & \\frac{3}{4} \\\\\n",
    "\\end{pmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "Note that $M^T$ is a stochastic matrix because each column of the transposed matrix would sum to $1$ (in general the rows of the transposed matrix are unlikely to sum to 1, but choosing an example like the above makes it easy to compute the eigenvectors).\n",
    "\n",
    "It's not too hard to verify that the characteristic polynomial of $M^T$ can be factored into $(\\lambda - 1)(\\lambda - \\frac{1}{2})$, so we have two eigenvalues, $1$ and $\\frac{1}{2}$.\n",
    "\n",
    "It's not too hard to verify that column vector $[1, 1]$ is the eigenvector of $M^T$ with eigenvalue $1$\n",
    ".\n",
    "\n",
    "Now that we know the weights placed on each strategy, we can compute the strategy distribution by normalising our eigenvector.\n",
    "\n",
    "The ergodic distribution i $\\omega^* = [\\frac{1}{2}, \\frac{1}{2}]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f7ac241d-d8c9-40f6-ad80-0ddb81b00e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.array([[[3/4, 1/4],\n",
    "               [1/4, 3/4]],\n",
    "             [[3/4, 1/4],\n",
    "               [1/4, 3/4]],\n",
    "              ])\n",
    "models = {\"transition_matrix\": M}\n",
    "result = find_ergodic_distribution(models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9bc0de01-3983-48c1-956f-3c686c4d27b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fastcore.test.test_eq(result['ergodic'],\n",
    "                      np.array([[1/2, 1/2]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "73a95e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fastcore.test.test_eq(calculate_stationary_distribution(M[0]),\n",
    "                      np.array([1/2, 1/2]))\n",
    "fastcore.test.test_eq(calculate_stationary_distribution(M),\n",
    "                      np.array([[1/2, 1/2]]))\n",
    "fastcore.test.test_eq(calculate_stationary_distribution(M,\n",
    "                                                        method=\"schur\"),\n",
    "                      np.array([[1/2, 1/2]]))\n",
    "fastcore.test.test_eq(calculate_stationary_distribution(M,\n",
    "                                                        method=\"quantecon\"),\n",
    "                      np.array([[1/2, 1/2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4f3a57ac-f485-46a0-b736-2a08cdf18a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| hide\n",
    "# # Here is some code which illustrates how one could use sympy to find the relevant eigenvectors\n",
    "# # using symbolic methods (but please note that even sympy must resort to numerical methods if\n",
    "# # the matrices are bigger than 5 by 5 in size, due to the fundamental lack of exact solutions to\n",
    "# # polynomial equations with order greater than 5)\n",
    "# import sympy\n",
    "# for m in M:\n",
    "#     # Sympy needs integers or expressions to work\n",
    "#     # Integers is usually safer\n",
    "#     m = np.array(1000 * m, dtype=int)\n",
    "#     M_symbolic = sympy.Matrix(m)\n",
    "#     for result in M_symbolic.eigenvects():\n",
    "#         lamda, multiplicity, evs = result\n",
    "\n",
    "#         # print(\"lambda: \" , lamda,\n",
    "#         #           \"multiplicity: \", multiplicity,\n",
    "#         #           \"eigenvectors: \", evs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94604c8-2f2b-46d5-8234-334635abd500",
   "metadata": {},
   "source": [
    "Here is another quick illustrative example.\n",
    "\n",
    "Let our transition matrix, $M$ be\n",
    "\n",
    "\\begin{equation}\n",
    "M = \\begin{pmatrix}\n",
    "\\frac{3}{4} & \\frac{1}{4} \\\\\n",
    "\\frac{3}{4} & \\frac{1}{4} \\\\\n",
    "\\end{pmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "$M^T$ is a stochastic matrix. It is easy to verify that $[\\frac{3}{4}, \\frac{1}{4}]$ is the normalised eigenvector with eigenvalue 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "37ae7587-ea91-4a61-a316-35563ea0222f",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.array([[[3/4, 1/4],\n",
    "               [3/4, 1/4]],\n",
    "              ])\n",
    "models = {\"transition_matrix\": M}\n",
    "result = find_ergodic_distribution(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d8543490-6385-4b3b-9801-9229a54cb053",
   "metadata": {},
   "outputs": [],
   "source": [
    "fastcore.test.test_eq(result['ergodic'],\n",
    "                      np.array([[3/4, 1/4]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1edf7824",
   "metadata": {},
   "outputs": [],
   "source": [
    "fastcore.test.test_eq(calculate_stationary_distribution(M[0]),\n",
    "                      np.array([3/4, 1/4]))\n",
    "fastcore.test.test_eq(calculate_stationary_distribution(M),\n",
    "                      np.array([[3/4, 1/4]]))\n",
    "fastcore.test.test_eq(calculate_stationary_distribution(M.transpose(0, 2, 1), method=\"schur\"),\n",
    "                      np.array([[3/4, 1/4]]))\n",
    "fastcore.test.test_eq(calculate_stationary_distribution(M, method=\"quantecon\"),\n",
    "                      np.array([[3/4, 1/4]]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cebc30c6",
   "metadata": {},
   "source": [
    "Notice that `find_ergodic_distribution` and the default method of `calculate_stationary_distribution` are equivalent and similar in speed. Unfortunately, they\n",
    "are inappropriate for non-hermitian matrices. The `\"schur\"` method is more appropriate if\n",
    "the matrices are normal, but this code cannot be easily vectorized as the other numpy-based\n",
    "solutions can. For the most accurate results, it makes sense to use the eigen library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "19555283",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.array([[[3/4, 1/4],\n",
    "               [3/4, 1/4]]\n",
    "              for _ in range(10000)\n",
    "              ])\n",
    "models = {\"transition_matrix\": M}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0574c39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = find_ergodic_distribution(models)\n",
    "fastcore.test.test_eq(result['ergodic'],\n",
    "                      np.array([[3/4, 1/4]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ed4c3d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fastcore.test.test_eq(calculate_stationary_distribution(M),\n",
    "                      np.array([[3/4, 1/4]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "53a94fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fastcore.test.test_eq(calculate_stationary_distribution(M.transpose(0, 2, 1),\n",
    "                                                        method=\"schur\"),\n",
    "                      np.array([[3/4, 1/4]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c9829464",
   "metadata": {},
   "outputs": [],
   "source": [
    "fastcore.test.test_eq(np.array([gth_solve(m) for m in M]),\n",
    "                      np.array([[3/4, 1/4]]))\n",
    "fastcore.test.test_eq(calculate_stationary_distribution(M,\n",
    "                                                        method=\"quantecon\"),\n",
    "                      np.array([[3/4, 1/4]]))\n",
    "fastcore.test.test_eq(calculate_sd_helper({**models,\n",
    "                                           \"sd-method\": \"quantecon\"})['ergodic'],\n",
    "                      np.array([[3/4, 1/4]]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7bfd3ac4",
   "metadata": {},
   "source": [
    "On a technical level, we know that the matrix is irreducible since all the\n",
    "transition probabilities should be strictly positive by design. \n",
    "\n",
    "Unfortunately, on a numerical level, these matrices are nearly degenerate. It\n",
    "is unclear how to deal with this best. \n",
    "\n",
    "Options:\n",
    "- bound all transition rates below by 1e-10 or a similar factor.\n",
    "- round all transition rates below 1e-10 to zero and find stationary distribution of all recurrent classes.\n",
    "\n",
    "Whichever option we go with, only the quantecon method is appropriate for finding the\n",
    "stationary distribution(s).\n",
    "\n",
    "I think we should go for the first option as this allows us to exploit that there\n",
    "is only one recurrent class in our transition matrices and therefore only one\n",
    "stationary distribution that is relevant to our results. We can also skip the\n",
    "expensive quantecon routines needed to find the recurrent classes of the matrix that\n",
    "would ultimately be very difficult to speed up.\n",
    "\n",
    "We should of course check whether gth_solve used by quantecon is even affected by the floating point issues and near-degeneracy of the transition matrices that it is given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "27968b3f-8b47-4298-b6e6-1020c894e8ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/PaoloBova/gh-pages-example/blob/main/gh_pages_example/methods.py#L247){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### find_ergodic_distribution\n",
       "\n",
       ">      find_ergodic_distribution (models:dict)\n",
       "\n",
       "Find the ergodic distribution of a markov chain with the\n",
       "given transition matrix.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| models | dict | A dictionary that contains the parameters in `ModelTypeEGT` |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/PaoloBova/gh-pages-example/blob/main/gh_pages_example/methods.py#L247){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### find_ergodic_distribution\n",
       "\n",
       ">      find_ergodic_distribution (models:dict)\n",
       "\n",
       "Find the ergodic distribution of a markov chain with the\n",
       "given transition matrix.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| models | dict | A dictionary that contains the parameters in `ModelTypeEGT` |"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(find_ergodic_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d870ac66-b641-434b-bb9a-27df3577eecf",
   "metadata": {},
   "source": [
    "### Run full markov chain algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cd9f0e-f1e5-459a-b7a9-829c11bfc7e9",
   "metadata": {},
   "source": [
    "Finally, here is a helper function to both build the transition matrix for the model and find its ergodic distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bfe4a9b3-6248-4f70-9694-820307de7b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def markov_chain(models: dict  # A dictionary that contains the parameters in `ModelTypeEGT`\n",
    "                 ):\n",
    "    \"\"\"Find the ergodic distribution of the evolutionary\n",
    "    game given by each model in models.\"\"\"\n",
    "    return thread_macro(models,\n",
    "                        build_transition_matrix,\n",
    "                        find_ergodic_distribution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9a0fb6f2-cb09-4a98-ac1c-f91aa1b292f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/PaoloBova/gh-pages-example/blob/main/gh_pages_example/methods.py#L506){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### markov_chain\n",
       "\n",
       ">      markov_chain (models:dict)\n",
       "\n",
       "Find the ergodic distribution of the evolutionary\n",
       "game given by each model in models.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| models | dict | A dictionary that contains the parameters in `ModelTypeEGT` |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/PaoloBova/gh-pages-example/blob/main/gh_pages_example/methods.py#L506){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### markov_chain\n",
       "\n",
       ">      markov_chain (models:dict)\n",
       "\n",
       "Find the ergodic distribution of the evolutionary\n",
       "game given by each model in models.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| models | dict | A dictionary that contains the parameters in `ModelTypeEGT` |"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(markov_chain)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ab3139-41ee-40d3-9a22-3506072288ae",
   "metadata": {},
   "source": [
    "## Multiple Populations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6771d1a2",
   "metadata": {},
   "source": [
    "### Building blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d50f8cb",
   "metadata": {},
   "source": [
    "I will now describe the building blocks for an algorithm for building the transition matrix for a evolutionary game with multiple populations.\n",
    "\n",
    "When we have multiple populations, it is very easy to have many possible transitions. For this reason, it is important that we have a way to programatically handle them. \n",
    "\n",
    "My algorithm allows one to build these transition matrices using only the following information (in addition to other parameters needed in the single population case):\n",
    "- (i) Payoffs\n",
    "- (ii) Each sector's strategies\n",
    "- (iii) Allowed sectors for each player\n",
    "- (iv) Sampling rule (optional)\n",
    "- (v) profile filters (optional)\n",
    "\n",
    "(iii) in particular allows for a great deal of flexibility in setting up a game. It is possible to capture games where the number of players may vary or where the interaction contains players who may be sampled from one of several poulations. This flexibility will allow us to study a wide range of models from the literature. By default, (iv) and (v) are already quite general, though one can provide their own sampling rules and profile filters should they want even greater flexibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befaa57e",
   "metadata": {},
   "source": [
    "#### Payoffs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93b7304",
   "metadata": {},
   "source": [
    "`payoffs` is a nested dictionary which is 2 levels deep. On the first level, each key is a string of the form \"...n3-n2-n1\". n1 is an integer which encodes the strategy that player 1 uses in the interaction. n2 and n3 are the same. We have as many integers as there are possible players in the interaction. This key therefore captures the strategy profile employed by the players.\n",
    "\n",
    "At the second level, we have keys for each player, \"P1\", \"P2\", \"P3\", ... \n",
    "\n",
    "Each value is a 1D numpy array containing the player's payoffs (relevant to the specified strategy profile) for each model we are solving the game for.\n",
    "\n",
    "There are number of important hints to follow when writing your payoffs for use in my multiple populations algorithm. \n",
    "- Players are allowed to be from any sector. Note that I assume strategies are coded for each sector in order. So, Sector 1's strategies are coded from 1 to num_s1_strategies, Sector 2's are coded from num_s1_strategies + 1 to num_s1_strategies + num_s2 strategies, and so on. In this way the strategy code tells us which sector the strategy is from and which strategy they follow.\n",
    "- I use a 0 to indicate that the player is not involved in the current interaction. Intuitively you may prefer to think of the player as doing nothing and being from Sector 0. This allows us to flexibly allow the possibility of an uncertain number of players in each interaction.\n",
    "- In some games, it is possible that there are a large number of possible strategy profiles (e.g. a game with 3 sectors, 3 strategies, and up to 4 players in each interaction would have 10**4 possible strategy profiles). However, very few of those strategy profiles will be relevant to building the transition matrix, especially if the order of the players does not matter, and if some players must belong to certain sectors. The number of strategy profiles will often be much smaller than the number of parameter combinations (what I refer to as models) we wish to solve for.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca922a84",
   "metadata": {},
   "source": [
    "#### Sector strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fadda0c",
   "metadata": {},
   "source": [
    "A dictionary with keys for each sector and values as lists of integers which encode the sector's strategies. Recall that sector 1's strategies start from 1, sector 2's strategies start from num_s1_strategies + 1 and so on.\n",
    "\n",
    "We will use the sector strategies to generate the set of recurrent states, the states that the system visits in the limit of rare mutations. Such states have every member of a sector (also often reffered to as a population) using the same strategy, i.e. they are monomorphic. These are the states we need to the build the transition matrix for."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b63482e",
   "metadata": {},
   "source": [
    "#### Allowed_sectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c1470f",
   "metadata": {},
   "source": [
    "`allowed_sectors` specifies which sectors each player can be from and therefore specifies all possible interactions in the game.\n",
    "\n",
    "It is a dictionary where the keys are players, e.g. \"P1\" and the values are lists of sectors, e.g. [\"S1\", \"S2\"]. This tells the algorithm which interactions are possible in the game.\n",
    "\n",
    "To specify that the player may not be present in an interaction, you can specify \"S0\" in the list.\n",
    "\n",
    "Note: `sectors` are perhaps more commonly reffered to as `populations` or `subpopulations` in the literature. For the sake of brevity, I use `sectors` instead when naming variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e41cbe",
   "metadata": {},
   "source": [
    "#### Sampling rule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd9b494",
   "metadata": {},
   "source": [
    "A sampling rule tells us the likelihood that a strategy profile will be selected given the current state of the system and the number of mutants (of the specified type). The sampling also needs to know which player represents the agent who is comparing the two strategies under consideration as this player does not need to be sampled. \n",
    "\n",
    "However, if this agent could have been one of several players (they would be playing the same strategy in the strategy profile), then the sampling rule should also multiply the likelihood by the probability that the agent would have been chosen as the current player."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4a084096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "@multi\n",
    "def sample_profile(models):\n",
    "    return models.get('sample_profile_key')\n",
    "\n",
    "\n",
    "@method(sample_profile)\n",
    "def sample_profile(models):\n",
    "    \"\"\"We sample players from their allowed sectors as per the sector weights.\"\"\"\n",
    "    sector_strategies = models['sector_strategies']\n",
    "    allowed_sectors = models['allowed_sectors']\n",
    "    profile = models['profile']\n",
    "    chosen_player = models['chosen_player']\n",
    "    chosen_strategy = int(models['chosen_strategy'])\n",
    "    current_strategy = int(models['current_strategy'])\n",
    "    mutant_strategy = int(models['mutant_strategy'])\n",
    "    affected_sector = models['affected_sector']\n",
    "    n_mutants = models['n_mutants']\n",
    "    Z = models['Z']\n",
    "    sector_weights = models.get('sector_weights', {})\n",
    "    assert n_mutants >= 1\n",
    "    assert n_mutants <= Z[affected_sector] - 1\n",
    "    assert current_strategy != mutant_strategy\n",
    "    assert chosen_strategy in [current_strategy, mutant_strategy]\n",
    "    assert affected_sector in sector_strategies.keys()\n",
    "    assert chosen_player in allowed_sectors.keys()\n",
    "\n",
    "    profile_tuple = list(map(int, profile.split(\"-\")))\n",
    "    assert chosen_strategy in profile_tuple\n",
    "\n",
    "    # TODO: does it make sense for chosen_player_likelihood to take into account\n",
    "    # any possible position our chosen_player could have been in, no matter\n",
    "    # which strategies each player actually plays in the profile?\n",
    "    above = sector_weights.get(chosen_player, {}).get(affected_sector, 1)\n",
    "    below = 0\n",
    "    for player, sectors in allowed_sectors.items():\n",
    "        if affected_sector in sectors:\n",
    "            below += sector_weights.get(player, {}).get(affected_sector, 1)\n",
    "    if below == 0:\n",
    "        raise ValueError(\"\"\"affected_sector is never allowed in the game, \n",
    "                         double check allowed_sectors\"\"\")\n",
    "    # print(\"chosen_player_likelihood: \", above / below)\n",
    "    chosen_player_likelihood = above / below\n",
    "\n",
    "    likelihood = chosen_player_likelihood\n",
    "\n",
    "    n_sampled_from_affected_sector = 1\n",
    "    n_mutants_sampled = 1 if chosen_strategy == mutant_strategy else 0\n",
    "    for i, strategy in enumerate(profile_tuple[::-1]):\n",
    "        valid_strategy = False\n",
    "        for sector in allowed_sectors[f\"P{i+1}\"]:\n",
    "            if strategy in map(int, sector_strategies[sector]):\n",
    "                valid_strategy = True\n",
    "        if not valid_strategy:\n",
    "            raise ValueError(f\"\"\"Profile, {profile}, implies a player plays a\n",
    "                             strategy from a sector they do not belong to.\"\"\")\n",
    "        if f\"P{i+1}\" == chosen_player:\n",
    "            continue\n",
    "        if strategy in map(int, sector_strategies[affected_sector]):\n",
    "            if strategy == current_strategy:\n",
    "                likelihood *= ((Z[affected_sector]\n",
    "                                - (n_sampled_from_affected_sector\n",
    "                                   - n_mutants_sampled)\n",
    "                                - n_mutants)\n",
    "                               / (Z[affected_sector]\n",
    "                                  - n_sampled_from_affected_sector))\n",
    "                # print(\"current-lk: \",\n",
    "                #       (Z[affected_sector]\n",
    "                #        - (n_sampled_from_affected_sector - n_mutants_sampled)\n",
    "                #        - n_mutants),\n",
    "                #       \"/\",\n",
    "                #       (Z[affected_sector] - n_sampled_from_affected_sector))\n",
    "                n_sampled_from_affected_sector += 1\n",
    "            elif strategy == mutant_strategy:\n",
    "                likelihood *= ((n_mutants\n",
    "                                - n_mutants_sampled)\n",
    "                               / (Z[affected_sector]\n",
    "                                  - n_sampled_from_affected_sector))\n",
    "                # print(\"mutant-lk: \",\n",
    "                #       (n_mutants - n_mutants_sampled),\n",
    "                #       \"/\",\n",
    "                #       (Z[affected_sector] - n_sampled_from_affected_sector))\n",
    "                n_mutants_sampled += 1\n",
    "                n_sampled_from_affected_sector += 1\n",
    "            else:\n",
    "                raise ValueError(\"\"\"At least one profile implies the copresence\n",
    "                                 of 3 strategies for one sector. This default\n",
    "                                 profile likelihood method is not meant to be\n",
    "                                 used for such situations. Make sure you use\n",
    "                                 profile filters to prevent passing such\n",
    "                                 strategy profiles to this sampling rule.\"\"\")\n",
    "        relevant_sector = [sector\n",
    "                           for sector in sector_strategies.keys()\n",
    "                           if strategy in map(int, sector_strategies[sector])]\n",
    "        if len(relevant_sector) > 1:\n",
    "            raise ValueError(\"Each sector must have unique strategy codes\")\n",
    "        elif len(relevant_sector) == 0:\n",
    "            raise ValueError(\"Strategy does not belong to any sector\")\n",
    "        else:\n",
    "            relevant_sector = relevant_sector[0]\n",
    "        above = sector_weights.get(\"P{i+1}\", {}).get(relevant_sector, 1)\n",
    "        below = sum(sector_weights.get(\"P{i+1}\", {}).get(sector, 1)\n",
    "                    for sector in allowed_sectors[f\"P{i+1}\"])\n",
    "        likelihood *= above / below\n",
    "        # print(\"relevant_sector_likelihood: \", above / below)\n",
    "    return likelihood\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565d5fab",
   "metadata": {},
   "source": [
    "##### Tests for `sample_profile`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe9eb0c",
   "metadata": {},
   "source": [
    "The `sample_profile` default method is very general. It will calculate the\n",
    "likelihood of the profile by assuming that all allowed sectors for each\n",
    "player are uniformly sampled from (unless sector weights are provided) and\n",
    "consider the likelihood of sampling a mutant from the sector which has a mutant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3adfe38c",
   "metadata": {},
   "source": [
    "##### Test 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9510d3e4",
   "metadata": {},
   "source": [
    "I conduct a number of tests below on a simple game where every player in an interaction is\n",
    "fixed to a particular sector. In such games, the likelihood of each profile being chosen is\n",
    "is always 1, no matter how many mutants there are, as no individual plays against a player\n",
    "from the same sector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ff41adf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "Z = {\"S3\": 10, \"S2\": 10, \"S1\": 10}\n",
    "sector_strategies = {\"S3\": [5, 6],\n",
    "                     \"S2\": [3, 4],\n",
    "                     \"S1\": [1, 2]}\n",
    "allowed_sectors = {\"P3\": [\"S3\"],\n",
    "                   \"P2\": [\"S2\"],\n",
    "                   \"P1\": [\"S1\"]}\n",
    "n_players = len(allowed_sectors.keys())\n",
    "n_strategies = [len(strategies) for strategies in sector_strategies]\n",
    "\n",
    "sector_weights = {}\n",
    "\n",
    "models = {\"Z\": Z,\n",
    "          \"sector_strategies\": sector_strategies,\n",
    "          \"allowed_sectors\": allowed_sectors,\n",
    "          \"profile\": \"5-3-1\",\n",
    "          \"chosen_player\": \"P1\",\n",
    "          \"chosen_strategy\": 1,\n",
    "          \"current_strategy\": 1,\n",
    "          \"mutant_strategy\": 2,\n",
    "          \"affected_sector\": \"S1\",\n",
    "          \"n_mutants\": 2,\n",
    "          #   \"sector_weights\": sector_weights,\n",
    "          }\n",
    "result1 = sample_profile(models)\n",
    "result2 = sample_profile({**models, \"n_mutants\": 8})\n",
    "result3 = sample_profile({**models, \"n_mutants\": 9})\n",
    "result4 = sample_profile({**models,\n",
    "                          \"affected_sector\": \"S2\",\n",
    "                          \"chosen_player\": \"P2\",\n",
    "                          \"current_strategy\": 3,\n",
    "                          \"mutant_strategy\": 4,\n",
    "                          \"chosen_strategy\": 3})\n",
    "result5 = sample_profile({**models,\n",
    "                          \"profile\": \"5-3-2\",\n",
    "                          \"current_strategy\": 1,\n",
    "                          \"mutant_strategy\": 2,\n",
    "                          \"chosen_strategy\": 2})\n",
    "result6 = sample_profile({**models,\n",
    "                          \"profile\": \"6-3-1\",\n",
    "                          \"affected_sector\": \"S3\",\n",
    "                          \"chosen_player\": \"P3\",\n",
    "                          \"current_strategy\": 5,\n",
    "                          \"mutant_strategy\": 6,\n",
    "                          \"chosen_strategy\": 6})\n",
    "expected = (1  # \"P1\" is from \"S1\": it must be our chosen_player with the chosen_strategy\n",
    "            * 1  # \"P2\" can only be from \"S2\", but all players form that sector play 3\n",
    "            * 1  # \"P3\" can only be from \"S3\", but all players form that sector play 5\n",
    "            )\n",
    "fastcore.test.test_eq(result1, expected)\n",
    "fastcore.test.test_eq(result2, expected)\n",
    "fastcore.test.test_eq(result3, expected)\n",
    "fastcore.test.test_eq(result4, expected)\n",
    "fastcore.test.test_eq(result5, expected)\n",
    "fastcore.test.test_eq(result6, expected)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22329f3",
   "metadata": {},
   "source": [
    "##### Test 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75506af4",
   "metadata": {},
   "source": [
    "There are several errors a user may encounter if they give invalid values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1f8f0888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "Z = {\"S3\": 10, \"S2\": 10, \"S1\": 10}\n",
    "sector_strategies = {\"S3\": [5, 6],\n",
    "                     \"S2\": [3, 4],\n",
    "                     \"S1\": [1, 2]}\n",
    "allowed_sectors = {\"P3\": [\"S3\"],\n",
    "                   \"P2\": [\"S2\"],\n",
    "                   \"P1\": [\"S1\"]}\n",
    "n_players = len(allowed_sectors.keys())\n",
    "n_strategies = [len(strategies) for strategies in sector_strategies]\n",
    "\n",
    "sector_weights = {}\n",
    "\n",
    "models = {\"Z\": Z,\n",
    "          \"sector_strategies\": sector_strategies,\n",
    "          \"allowed_sectors\": allowed_sectors,\n",
    "          \"profile\": \"5-3-1\",\n",
    "          \"chosen_player\": \"P1\",\n",
    "          \"chosen_strategy\": 1,\n",
    "          \"current_strategy\": 1,\n",
    "          \"mutant_strategy\": 2,\n",
    "          \"affected_sector\": \"S1\",\n",
    "          \"n_mutants\": 2,\n",
    "          #   \"sector_weights\": sector_weights,\n",
    "          }\n",
    "\n",
    "with fastcore.test.ExceptionExpected(ex=AssertionError):\n",
    "    sample_profile({**models, \"n_mutants\": 1000})\n",
    "with fastcore.test.ExceptionExpected(ex=AssertionError):\n",
    "    sample_profile({**models, \"chosen_strategy\": 2})\n",
    "with fastcore.test.ExceptionExpected(ex=AssertionError):\n",
    "    sample_profile({**models, \"profile\": \"5-3-2\"})\n",
    "with fastcore.test.ExceptionExpected(ex=AssertionError):\n",
    "    sample_profile({**models,\n",
    "                    \"mutant_strategy\": 5,\n",
    "                    \"current_strategy\": 6})\n",
    "with fastcore.test.ExceptionExpected(ex=AssertionError):\n",
    "    sample_profile({**models,\n",
    "                    \"mutant_strategy\": 1,\n",
    "                    \"current_strategy\": 1})\n",
    "with fastcore.test.ExceptionExpected(ex=ValueError):\n",
    "    sample_profile({**models,\n",
    "                    \"sector_strategies\": {**sector_strategies,\n",
    "                                          \"S3\": [3, 4]}})\n",
    "with fastcore.test.ExceptionExpected(ex=ValueError):\n",
    "    sample_profile({**models, \"profile\": \"10-6-1\"})\n",
    "with fastcore.test.ExceptionExpected(ex=AssertionError):\n",
    "    sample_profile({**models,\n",
    "                    \"sector_strategies\": {\"S3\": [5, 6],\n",
    "                                          \"S2\": [3, 4]}})\n",
    "with fastcore.test.ExceptionExpected(ex=ValueError):\n",
    "    sample_profile({**models,\n",
    "                    \"allowed_sectors\": {\"P1\": [\"S2\"],\n",
    "                                        \"P2\": [\"S2\"],\n",
    "                                        \"P3\": [\"S3\"]}})\n",
    "with fastcore.test.ExceptionExpected(ex=ValueError):\n",
    "    sample_profile({**models,\n",
    "                    \"sector_strategies\": {\"S1\": [1, 2, 3]},\n",
    "                    \"allowed_sectors\": {\"P1\": [\"S1\"],\n",
    "                                        \"P2\": [\"S1\"],\n",
    "                                        \"P3\": [\"S1\"]},\n",
    "                    \"profile\": \"3-2-1\"})\n",
    "with fastcore.test.ExceptionExpected(ex=ValueError):\n",
    "    sample_profile({**models,\n",
    "                    \"profile\": \"3-2-1\"})\n",
    "with fastcore.test.ExceptionExpected(ex=KeyError):\n",
    "    sample_profile({**models,\n",
    "                    \"sector_strategies\": {\"S1\": [1, 2, 3]},\n",
    "                    \"profile\": \"3-2-1\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fe5467",
   "metadata": {},
   "source": [
    "##### Test 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538e3498",
   "metadata": {},
   "source": [
    "Now, consider a more complicated example where we have 2 players that belong to the same sector and one player who is fixed to another sector. Now the profile likelihoods depend on\n",
    "the number of mutants.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "055aa5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "Z = {\"S2\": 10, \"S1\": 10}\n",
    "sector_strategies = {\"S2\": [3, 4],\n",
    "                     \"S1\": [1, 2]}\n",
    "allowed_sectors = {\"P3\": [\"S2\"],\n",
    "                   \"P2\": [\"S1\"],\n",
    "                   \"P1\": [\"S1\"]}\n",
    "n_players = len(allowed_sectors.keys())\n",
    "n_strategies = [len(strategies) for strategies in sector_strategies]\n",
    "\n",
    "sector_weights = {}\n",
    "\n",
    "models = {\"Z\": Z,\n",
    "          \"sector_strategies\": sector_strategies,\n",
    "          \"allowed_sectors\": allowed_sectors,\n",
    "          \"profile\": \"3-2-1\",\n",
    "          \"chosen_player\": \"P1\",\n",
    "          \"chosen_strategy\": 1,\n",
    "          \"current_strategy\": 1,\n",
    "          \"mutant_strategy\": 2,\n",
    "          \"affected_sector\": \"S1\",\n",
    "          \"n_mutants\": 2,\n",
    "          #   \"sector_weights\": sector_weights,\n",
    "          }\n",
    "\n",
    "\n",
    "result1 = sample_profile(models)\n",
    "result2 = sample_profile({**models, \"n_mutants\": 8})\n",
    "result3 = sample_profile({**models,\n",
    "                          \"chosen_strategy\": 2,\n",
    "                          \"chosen_player\": \"P2\"})\n",
    "result4 = sample_profile({**models,\n",
    "                          \"current_strategy\": 2,\n",
    "                          \"mutant_strategy\": 1,\n",
    "                          \"chosen_strategy\": 2,\n",
    "                          \"chosen_player\": \"P2\"})\n",
    "result5 = sample_profile({**models,\n",
    "                          \"profile\": \"3-2-2\",\n",
    "                          \"current_strategy\": 1,\n",
    "                          \"mutant_strategy\": 2,\n",
    "                          \"chosen_strategy\": 2})\n",
    "result6 = sample_profile({**models,\n",
    "                          \"profile\": \"3-1-2\",\n",
    "                          \"current_strategy\": 1,\n",
    "                          \"mutant_strategy\": 2,\n",
    "                          \"chosen_strategy\": 2})\n",
    "expected1 = (  # \"P1\" is our chosen_player. The likelihood of choosing our\n",
    "    # chosen player given the affected_sector is just the likelihood of\n",
    "    # choosing that player instead of any other player. chosen_player\n",
    "    # is the first player we sample, and they must be present, so only\n",
    "    # the liklelihood of each player sampling from the affected sector\n",
    "    # matters. In this case, 2 of the players have the same same of\n",
    "    # sampling from \"S1\", and the other has a 0% change. So, the\n",
    "    # likelihood of them being \"P1\" is 50%.\n",
    "    0.5\n",
    "    # \"P2\", like our chosen player, \"P1\" is from \"S1\". We have 2\n",
    "    # mutants in the affected sector, and \"P2\" is using the mutant\n",
    "    # strategy. The probability of this happening is\n",
    "    * 2 / (10 - 1)\n",
    "    * 1  # \"P3\" can only be from \"S3\" and all \"S3\" members play 3\n",
    ")\n",
    "expected2 = (0.5 * 8 / 9 * 1)\n",
    "expected3 = (8 / 9 * 0.5 * 1)\n",
    "expected4 = (2 / 9 * 0.5 * 1)\n",
    "expected5 = (0.5 * 1 / 9 * 1)\n",
    "expected6 = (0.5 * 8 / 9 * 1)\n",
    "fastcore.test.test_eq(result1, expected1)\n",
    "fastcore.test.test_eq(result2, expected2)\n",
    "fastcore.test.test_eq(result3, expected3)\n",
    "fastcore.test.test_eq(result4, expected4)\n",
    "fastcore.test.test_eq(result5, expected5)\n",
    "fastcore.test.test_eq(result6, expected6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5488951a",
   "metadata": {},
   "source": [
    "##### Test 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ccc69f",
   "metadata": {},
   "source": [
    "I also test it for a game where all 3 players can be from the same two sectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2b3b8ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "Z = {\"S2\": 10, \"S1\": 10}\n",
    "sector_strategies = {\"S2\": [3, 4],\n",
    "                     \"S1\": [1, 2]}\n",
    "allowed_sectors = {\"P3\": [\"S1\", \"S2\"],\n",
    "                   \"P2\": [\"S1\", \"S2\"],\n",
    "                   \"P1\": [\"S1\", \"S2\"]}\n",
    "n_players = len(allowed_sectors.keys())\n",
    "n_strategies = [len(strategies) for strategies in sector_strategies]\n",
    "\n",
    "sector_weights = {}\n",
    "\n",
    "models = {\"Z\": Z,\n",
    "          \"sector_strategies\": sector_strategies,\n",
    "          \"allowed_sectors\": allowed_sectors,\n",
    "          \"profile\": \"2-2-1\",\n",
    "          \"chosen_player\": \"P1\",\n",
    "          \"chosen_strategy\": 1,\n",
    "          \"current_strategy\": 1,\n",
    "          \"mutant_strategy\": 2,\n",
    "          \"affected_sector\": \"S1\",\n",
    "          \"n_mutants\": 2,\n",
    "          #   \"sector_weights\": sector_weights,\n",
    "          }\n",
    "\n",
    "\n",
    "result1 = sample_profile(models)\n",
    "result2 = sample_profile({**models, \"n_mutants\": 8})\n",
    "result3 = sample_profile({**models,\n",
    "                          \"chosen_strategy\": 2,\n",
    "                          \"chosen_player\": \"P2\"})\n",
    "result4 = sample_profile({**models,\n",
    "                          \"current_strategy\": 2,\n",
    "                          \"mutant_strategy\": 1,\n",
    "                          \"chosen_strategy\": 2,\n",
    "                          \"chosen_player\": \"P2\"})\n",
    "result5 = sample_profile({**models,\n",
    "                          \"profile\": \"3-2-2\",\n",
    "                          \"current_strategy\": 1,\n",
    "                          \"mutant_strategy\": 2,\n",
    "                          \"chosen_strategy\": 2})\n",
    "result6 = sample_profile({**models,\n",
    "                          \"profile\": \"3-1-2\",\n",
    "                          \"current_strategy\": 1,\n",
    "                          \"mutant_strategy\": 2,\n",
    "                          \"chosen_strategy\": 2})\n",
    "expected1 = (  # \"P1\" is our chosen_player. We could have chosen any player\n",
    "    # since all players can sample from the affected sector. Moreover,\n",
    "    # they all do so with equal likelihood, so the likelihood of\n",
    "    # choosing to follow \"P-1\" is 1/3\n",
    "    1 / 3\n",
    "    # \"P2\", like our chosen player, \"P1\" is from \"S1\". We have 2\n",
    "    # mutants in the affected sector, and \"P2\" is using the mutant\n",
    "    # strategy. We need the likelihood that an \"S1\" member was sampled\n",
    "    # instead of an \"S2\" member as well as the likelihood the \"S1\"\n",
    "    # member was a mutant\n",
    "    * 2 / (10 - 1) * 0.5\n",
    "    # \"P3\" is also from \"S1\" and plays the mutant strategy too.\n",
    "    # We sample without replacement, so the probability is\n",
    "    * 1 / (10 - 2) * 0.5\n",
    ")\n",
    "expected2 = (1 / 3\n",
    "             * 8 / 9 / 2\n",
    "             * 7 / 8 / 2)\n",
    "expected3 = (8 / 9 / 2\n",
    "             * 1 / 3\n",
    "             * 1 / 8 / 2)\n",
    "expected4 = (2 / 9 / 2\n",
    "             * 1 / 3\n",
    "             * 7 / 8 / 2)\n",
    "expected5 = (1 / 3\n",
    "             * 1 / 9 / 2\n",
    "             * 1 / 2)\n",
    "expected6 = (1 / 3\n",
    "             * 8 / 9 / 2\n",
    "             * 1 / 2)\n",
    "fastcore.test.test_eq(result1, expected1)\n",
    "fastcore.test.test_eq(result2, expected2)\n",
    "fastcore.test.test_eq(result3, expected3)\n",
    "fastcore.test.test_eq(result4, expected4)\n",
    "fastcore.test.test_eq(result5, expected5)\n",
    "fastcore.test.test_eq(result6, expected6)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4ea919de",
   "metadata": {},
   "source": [
    "#### Profile filters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2a4203ca",
   "metadata": {},
   "source": [
    "Profile filters work by filtering a list of profiles for only those profiles\n",
    "which meet the required conditions. Se `create_profiles` to read up how we\n",
    "create a list of profiles, and `profile_filter` for different profile filters.\n",
    "\n",
    "We can also use the `apply_profile_filters` function which by default filters\n",
    "our profiles so that we only keep those profiles which are relevant to the\n",
    "transition and are consistent with the given `allowed_sectors`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889d4795",
   "metadata": {},
   "source": [
    "### Create all recurrent states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ec6844bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def create_recurrent_states(models):\n",
    "    \"\"\"Create all recurrent-states for the set of models.\"\"\"\n",
    "    sector_strategies = models['sector_strategies']\n",
    "    n_states = np.prod([len(S) for S in sector_strategies.values()])\n",
    "    sorted_keys = sorted(sector_strategies, reverse=True)\n",
    "    strategy_axes = [sector_strategies[k] for k in sorted_keys]\n",
    "    grid = build_grid_from_axes(strategy_axes)\n",
    "    states = [\"-\".join(map(str, row)) for row in grid]\n",
    "    fastcore.test.test_eq(len(states), n_states)\n",
    "    return states\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b08b445",
   "metadata": {},
   "source": [
    "Here is a quick test for `create_recurrent_states`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9d4d57d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = create_recurrent_states({\"sector_strategies\": {\"S1\": [1, 2],\n",
    "                                                        \"S2\": [3, 4],\n",
    "                                                        \"S3\": [5, 6]}})\n",
    "expected = ['5-3-1',\n",
    "            '5-3-2',\n",
    "            '5-4-1',\n",
    "            '5-4-2',\n",
    "            '6-3-1',\n",
    "            '6-3-2',\n",
    "            '6-4-1',\n",
    "            '6-4-2']\n",
    "fastcore.test.test_eq(result, expected)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8671d169-c677-4a13-a9e9-a67a5b12e325",
   "metadata": {},
   "source": [
    "### Check transition is valid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7796c239-4732-4bb4-be37-88f9ce003879",
   "metadata": {},
   "source": [
    "Here is a method for checking that a given transition is valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4d1aba5b-8631-47ca-9b89-6827685ff5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def valid_transition(ind1: str,  # The index of the current state, expressed in the form \"{strategy_code}-{strategy_code}-{strategy_code}\"\n",
    "                     ind2: str,  # The index of the next state, expressed in the same form as `ind1`\n",
    "                     ) -> bool:  # True if the transition is valid, false otherwise\n",
    "    \"\"\"Check if the transition from ind1->ind2 is valid\n",
    "    i.e. that only one population undergoes a change in strategy.\"\"\"\n",
    "    ind1_tuple = list(map(int, ind1.split(\"-\")))\n",
    "    ind2_tuple = list(map(int, ind2.split(\"-\")))\n",
    "    differ = [i1 != i2 for i1, i2 in zip(ind1_tuple, ind2_tuple)]\n",
    "    valid = sum(differ) == 1\n",
    "    return valid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce2be49-d383-4aa8-82f4-c87268446d0a",
   "metadata": {},
   "source": [
    "**Tests for `valid_transition`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "02347d26-0167-4784-8c93-c64e00d004a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "fastcore.test.test_eq(valid_transition(\"1-1-1\", \"2-1-1\"), True)\n",
    "fastcore.test.test_eq(valid_transition(\"1-1-1\", \"2-1-2\"), False)\n",
    "fastcore.test.test_eq(valid_transition(\"1-1-1\", \"0-0-0\"), False)\n",
    "fastcore.test.test_eq(valid_transition(\"1-1-1\", \"22-1-3\"), False)\n",
    "# Even though possible, self transitions are marked as false since we never compute them directly\n",
    "fastcore.test.test_eq(valid_transition(\"1-1-1\", \"1-1-1\"), False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac27c69",
   "metadata": {},
   "source": [
    "### A multimethod for computing the likelihoods of different strategy profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4a41c2e3-7a3f-45f7-807e-28e53dbc6458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "@multi\n",
    "def compute_profile_dist(models):\n",
    "    \"\"\"Compute the probability distribution of the relevant profiles.\"\"\"\n",
    "    return models.get('profile_dist_rule')\n",
    "\n",
    "\n",
    "@method(compute_profile_dist)\n",
    "def compute_profile_dist(models):\n",
    "    \"\"\"Compute the probability distribution of the relevant profiles - default.\"\"\"\n",
    "    chosen_strategy = models['chosen_strategy']\n",
    "    profiles = models['profiles_filtered']\n",
    "    profile_distribution = {}\n",
    "    for profile in profiles:\n",
    "        profile_tuple = list(map(int, profile.split(\"-\")))\n",
    "        possible_players = [f\"P{i+1}\"\n",
    "                            for i, strategy in enumerate(profile_tuple[::-1])\n",
    "                            if strategy == chosen_strategy]\n",
    "        profile_distribution[profile] = {}\n",
    "        for chosen_player in possible_players:\n",
    "            likelihood = sample_profile({**models,\n",
    "                                         \"profile\": profile,\n",
    "                                         \"chosen_player\": chosen_player})\n",
    "            profile_distribution[profile][chosen_player] = likelihood\n",
    "    return profile_distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9cd7aa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "@method(compute_profile_dist, 'multi-player-symmetric')\n",
    "def compute_profile_dist(models):\n",
    "    \"\"\"Compute the probability distribution of the relevant profiles - we have\n",
    "    one profile per combination of players and only compute the likelihood for\n",
    "    the relevant player type.\"\"\"\n",
    "    chosen_strategy = models['chosen_strategy']\n",
    "    profiles = models['profiles_filtered']\n",
    "    profile_distribution = {}\n",
    "    counter = collections.Counter()\n",
    "    visited = collections.defaultdict()\n",
    "    for profile in profiles:\n",
    "        profile_tuple = list(map(int, profile.split(\"-\")))\n",
    "        unique, counts = np.unique(profile_tuple, return_counts=True)\n",
    "        counter_key = \"-\".join([f\"{u}:{c}\" for u, c in zip(unique, counts)])\n",
    "        counter[counter_key] += 1\n",
    "        visited[counter_key] = False\n",
    "    for profile in profiles:\n",
    "        profile_tuple = list(map(int, profile.split(\"-\")))\n",
    "        unique, counts = np.unique(profile_tuple, return_counts=True)\n",
    "        counter_key = \"-\".join([f\"{u}:{c}\" for u, c in zip(unique, counts)])\n",
    "        if visited[counter_key]:\n",
    "            # If we have seen a profile with the same strategy counts, skip it\n",
    "            continue\n",
    "        else:\n",
    "            visited[counter_key] = True\n",
    "            possible_players = [f\"P{i+1}\"\n",
    "                                for i, strategy in enumerate(profile_tuple[::-1])\n",
    "                                if strategy == chosen_strategy]\n",
    "            profile_distribution[profile] = {}\n",
    "            if len(possible_players) > 0:\n",
    "                # Player order does not matter\n",
    "                chosen_player = possible_players[0]\n",
    "                likelihood = sample_profile({**models,\n",
    "                                             \"profile\": profile,\n",
    "                                             \"chosen_player\": chosen_player})\n",
    "                # We must multiply the above likelihood by the number of ways\n",
    "                # this combination of players can be permuted.\n",
    "                likelihood *= counter[counter_key] * len(possible_players)\n",
    "                profile_distribution[profile][chosen_player] = likelihood\n",
    "    return profile_distribution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb24129d",
   "metadata": {},
   "source": [
    "#### Tests for `compute_profile_dist`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aa32c031",
   "metadata": {},
   "source": [
    "##### Test 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534b5d04",
   "metadata": {},
   "source": [
    "I consider a model with 2 sectors, who each have 2 strategies and 10 members,\n",
    "and play a game with 2 players who can each be from either sector.\n",
    "\n",
    "We therefore specify the sectors sizes, `Z`, the `sector_strategies` and the `allowed_sectors`\n",
    "\n",
    "`profiles_filtered` will be all profiles in such a game relevant to a transition\n",
    "between Sector 1 playing their first strategy and Sector 1 playing their\n",
    "second strategy. The members of Sector 2 play their first strategy.\n",
    "\n",
    "I encode these recurrent states as \"3-1\" and \"3-2\" respectively.\n",
    "\n",
    "I also mark \"S1\" as the `affected_sector`, as well as the `mutant_strategy`\n",
    "and `current_strategy`. \n",
    "\n",
    "`profiles_filtered` then includes: all possible \"x-y\" where x,y in {1,2,3},\n",
    "since there will be no \"S2\" players playing strategy 4.\n",
    "\n",
    "We also have to specify the `chosen_strategy` to indicate whether we are\n",
    "interested in the profile likelihoods from the perspective of a mutant player\n",
    "or a current player.\n",
    "\n",
    "The tests consider different values of `n_mutants`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e6250b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "Z = {\"S2\": 10, \"S1\": 10}\n",
    "sector_strategies = {\"S2\": [3, 4],\n",
    "                     \"S1\": [1, 2]}\n",
    "allowed_sectors = {\"P2\": [\"S1\", \"S2\"],\n",
    "                   \"P1\": [\"S1\", \"S2\"]}\n",
    "n_players = len(allowed_sectors.keys())\n",
    "n_strategies = [len(strategies) for strategies in sector_strategies]\n",
    "\n",
    "sector_weights = {}\n",
    "\n",
    "models = {\"Z\": Z,\n",
    "          \"sector_strategies\": sector_strategies,\n",
    "          \"allowed_sectors\": allowed_sectors,\n",
    "          \"n_players\": n_players,\n",
    "          \"n_strategies\": n_strategies,\n",
    "          \"chosen_strategy\": 1,\n",
    "          \"current_strategy\": 1,\n",
    "          \"mutant_strategy\": 2,\n",
    "          \"affected_sector\": \"S1\",\n",
    "          \"n_mutants\": 2,\n",
    "          #   \"sector_weights\": sector_weights,\n",
    "          }\n",
    "\n",
    "models = thread_macro(models,\n",
    "                      create_profiles,\n",
    "                      (assoc, \"transition_indices\", [\"3-1\", \"3-2\"]),\n",
    "                      apply_profile_filters)\n",
    "profiles_filtered = ['1-1', '1-2', '1-3',\n",
    "                     '2-1', '2-2', '2-3',\n",
    "                     '3-1', '3-2', '3-3']\n",
    "fastcore.test.test_eq(models[\"profiles_filtered\"], profiles_filtered)\n",
    "\n",
    "result1 = compute_profile_dist(models)\n",
    "expected1 = {'1-1': {\"P1\": 7 / 9 / 2 / 2, \"P2\": 7 / 9 / 2 / 2},\n",
    "             '1-2': {\"P2\": 2 / 9 / 2 / 2},\n",
    "             '1-3': {\"P2\": 1 / 2 / 2},\n",
    "             '2-1': {\"P1\": 2 / 9 / 2 / 2},\n",
    "             '2-2': {},\n",
    "             '2-3': {},\n",
    "             '3-1': {\"P1\": 1 / 2 / 2},\n",
    "             '3-2': {},\n",
    "             '3-3': {}}\n",
    "for profile in profiles_filtered:\n",
    "    fastcore.test.test_eq(result1[profile], expected1[profile])\n",
    "\n",
    "\n",
    "result1_sum = 0\n",
    "for likelihoods_by_player in result1.values():\n",
    "    for likelihood in likelihoods_by_player.values():\n",
    "        result1_sum += likelihood\n",
    "fastcore.test.test_eq(result1_sum, 1)\n",
    "\n",
    "\n",
    "result2 = compute_profile_dist({**models, \"chosen_strategy\": 2})\n",
    "expected2 = {'1-1': {},\n",
    "             '1-2': {\"P1\": 8 / 9 / 2 / 2},\n",
    "             '1-3': {},\n",
    "             '2-1': {\"P2\": 8 / 9 / 2 / 2},\n",
    "             '2-2': {\"P1\": 1 / 9 / 2 / 2, \"P2\": 1 / 9 / 2 / 2},\n",
    "             '2-3': {\"P2\": 1 / 2 / 2},\n",
    "             '3-1': {},\n",
    "             '3-2': {\"P1\": 1 / 2 / 2},\n",
    "             '3-3': {}}\n",
    "for profile in profiles_filtered:\n",
    "    fastcore.test.test_eq(result2[profile], expected2[profile])\n",
    "\n",
    "result2_sum = 0\n",
    "for likelihoods_by_player in result1.values():\n",
    "    for likelihood in likelihoods_by_player.values():\n",
    "        result2_sum += likelihood\n",
    "fastcore.test.test_eq(result2_sum, 1)\n",
    "\n",
    "result3 = compute_profile_dist({**models, \"n_mutants\": 5})\n",
    "expected3 = {'1-1': {\"P1\": 4 / 9 / 2 / 2, \"P2\": 4 / 9 / 2 / 2},\n",
    "             '1-2': {\"P2\": 5 / 9 / 2 / 2},\n",
    "             '1-3': {\"P2\": 1 / 2 / 2},\n",
    "             '2-1': {\"P1\": 5 / 9 / 2 / 2},\n",
    "             '2-2': {},\n",
    "             '2-3': {},\n",
    "             '3-1': {\"P1\": 1 / 2 / 2},\n",
    "             '3-2': {},\n",
    "             '3-3': {}}\n",
    "for profile in profiles_filtered:\n",
    "    fastcore.test.test_eq(result3[profile], expected3[profile])\n",
    "\n",
    "result3_sum = 0\n",
    "for likelihoods_by_player in result1.values():\n",
    "    for likelihood in likelihoods_by_player.values():\n",
    "        result3_sum += likelihood\n",
    "fastcore.test.test_eq(result2_sum, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184646b2",
   "metadata": {},
   "source": [
    "##### Test 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "534b5d04",
   "metadata": {},
   "source": [
    "I next consider the same model but this time each interaction has 5 players.\n",
    "\n",
    "In such cases, it is desirable to use the multiplayer-symmetric method for\n",
    "computing the likelihood of the relevant profiles.\n",
    "\n",
    "As before, we specify the sectors sizes, `Z`, the `sector_strategies` and the `allowed_sectors`\n",
    "\n",
    "`profiles_filtered` will be all profiles in such a game relevant to a transition\n",
    "between Sector 1 playing their first strategy and Sector 1 playing their\n",
    "second strategy. The members of Sector 2 play their first strategy.\n",
    "\n",
    "I encode these recurrent states as \"3-1\" and \"3-2\" respectively.\n",
    "\n",
    "I also mark \"S1\" as the `affected_sector`, as well as the `mutant_strategy`\n",
    "and `current_strategy`. \n",
    "\n",
    "`profiles_filtered` then includes: all possible \"x-y\" where x,y in {1,2,3},\n",
    "since there will be no \"S2\" players playing strategy 4.\n",
    "\n",
    "While we need all of these profiles for this new method, the profiles we\n",
    "only compute the likelihoods for a subset. There is only one relevant profile\n",
    "per unique strategy count. The profile chosen is the first such profile when\n",
    "iterating through `profiles_filtered` (care must be taken to ensure that the\n",
    "payoffs are computed in a similar way - we will have a method to ensure this).\n",
    "\n",
    "We also have to specify the `chosen_strategy` to indicate whether we are\n",
    "interested in the profile likelihoods from the perspective of a mutant player\n",
    "or a current player.\n",
    "\n",
    "The tests verifies that the result of this method is the same as if aggregated\n",
    "the likelihoods using the default method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e6250b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "Z = {\"S2\": 10, \"S1\": 10}\n",
    "sector_strategies = {\"S2\": [3, 4],\n",
    "                     \"S1\": [1, 2]}\n",
    "allowed_sectors = {\"P5\": [\"S1\", \"S2\"],\n",
    "                   \"P4\": [\"S1\", \"S2\"],\n",
    "                   \"P3\": [\"S1\", \"S2\"],\n",
    "                   \"P2\": [\"S1\", \"S2\"],\n",
    "                   \"P1\": [\"S1\", \"S2\"]}\n",
    "n_players = len(allowed_sectors.keys())\n",
    "n_strategies = [len(strategies) for strategies in sector_strategies]\n",
    "\n",
    "sector_weights = {}\n",
    "\n",
    "models = {\"Z\": Z,\n",
    "          \"sector_strategies\": sector_strategies,\n",
    "          \"allowed_sectors\": allowed_sectors,\n",
    "          \"n_players\": n_players,\n",
    "          \"n_strategies\": n_strategies,\n",
    "          \"chosen_strategy\": 1,\n",
    "          \"current_strategy\": 1,\n",
    "          \"mutant_strategy\": 2,\n",
    "          \"affected_sector\": \"S1\",\n",
    "          \"n_mutants\": 2,\n",
    "          #   \"sector_weights\": sector_weights,\n",
    "          }\n",
    "\n",
    "models = thread_macro(models,\n",
    "                      create_profiles,\n",
    "                      (assoc, \"transition_indices\", [\"3-1\", \"3-2\"]),\n",
    "                      apply_profile_filters)\n",
    "profiles_filtered = ['1-1-1-1-1',\n",
    "                     '1-1-1-1-2',\n",
    "                     '1-1-1-1-3',\n",
    "                     '1-1-1-2-2',\n",
    "                     '1-1-1-2-3',\n",
    "                     '1-1-1-3-3',\n",
    "                     '1-1-2-2-2',\n",
    "                     '1-1-2-2-3',\n",
    "                     '1-1-2-3-3',\n",
    "                     '1-1-3-3-3',\n",
    "                     '1-2-2-2-2',\n",
    "                     '1-2-2-2-3',\n",
    "                     '1-2-2-3-3',\n",
    "                     '1-2-3-3-3',\n",
    "                     '1-3-3-3-3',\n",
    "                     '2-2-2-2-2',\n",
    "                     '2-2-2-2-3',\n",
    "                     '2-2-2-3-3',\n",
    "                     '2-2-3-3-3',\n",
    "                     '2-3-3-3-3',\n",
    "                     '3-3-3-3-3', ]\n",
    "# fastcore.test.test_eq(models[\"profiles_filtered\"], profiles_filtered)\n",
    "\n",
    "result1 = compute_profile_dist({**models,\n",
    "                                \"profile_dist_rule\": \"multi-player-symmetric\"})\n",
    "result2 = compute_profile_dist(models)\n",
    "\n",
    "# The expected results take the probability of attaining a given profile when\n",
    "# sampling all other players from the availabe sectors and player types (top few\n",
    "# lines), divided by the chance your agent was sampled to be in of the player\n",
    "# positions (in this case this is always 1/5), multiplied by the number of\n",
    "# different positions the player could be in for the given profile, and then\n",
    "# multiplied by the number of permutations of the given (read these numbers\n",
    "# from left to right on the last line).\n",
    "expected1 = {'1-1-1-1-1': {'P1': (math.comb(7, 4) / math.comb(9, 4) / 2**4\n",
    "                                  / 5 * 5 * 1)},\n",
    "             '1-1-1-1-2': {'P2': (math.comb(7, 3) / math.comb(9, 3) / 2**3\n",
    "                                  * math.comb(2, 1) / math.comb(6, 1) / 2\n",
    "                                  / 5 * 4 * 5)},\n",
    "             '1-1-1-1-3': {'P2': (math.comb(7, 3) / math.comb(9, 3) / 2**3\n",
    "                                  * (1 / 2)\n",
    "                                  / 5 * 4 * 5)},\n",
    "             '1-1-1-2-2': {'P3': (math.comb(7, 2) / math.comb(9, 2) / 2**2\n",
    "                                  * math.comb(2, 2) / math.comb(7, 2) / 2**2\n",
    "                                  / 5 * 3 * 10)},\n",
    "             '1-1-1-2-3': {'P3': (math.comb(7, 2) / math.comb(9, 2) / 2**2\n",
    "                                  * math.comb(2, 1) / math.comb(7, 1) / 2\n",
    "                                  * (1 / 2)\n",
    "                                  / 5 * 3 * 20)},\n",
    "             '1-1-1-3-3': {'P3': (math.comb(7, 2) / math.comb(9, 2) / 2**2\n",
    "                                  * (1 / 2)**2\n",
    "                                  / 5 * 3 * 10)},\n",
    "             '1-1-2-2-2': {'P4': 0.0},  # Too many mutants so impossible\n",
    "             '1-1-2-2-3': {'P4': (math.comb(7, 1) / math.comb(9, 1) / 2\n",
    "                                  * math.comb(2, 2) / math.comb(8, 2) / 2**2\n",
    "                                  * (1 / 2)\n",
    "                                  / 5 * 2 * 30)},\n",
    "             '1-1-2-3-3': {'P4': (math.comb(7, 1) / math.comb(9, 1) / 2\n",
    "                                  * math.comb(2, 1) / math.comb(8, 1) / 2\n",
    "                                  * (1 / 2)**2\n",
    "                                  / 5 * 2 * 30)},\n",
    "             '1-1-3-3-3': {'P4': (math.comb(7, 1) / math.comb(9, 1) / 2\n",
    "                                  * (1 / 2)**3\n",
    "                                  / 5 * 2 * 10)},\n",
    "             '1-2-2-2-2': {'P5': 0.0},  # Too many mutants so impossible\n",
    "             '1-2-2-2-3': {'P5': 0.0},  # Too many mutants so impossible\n",
    "             '1-2-2-3-3': {'P5': (math.comb(2, 2) / math.comb(9, 2) / 2**2\n",
    "                                  * (1 / 2)**2\n",
    "                                  / 5 * 1 * 30)},\n",
    "             '1-2-3-3-3': {'P5': (math.comb(2, 1) / math.comb(9, 1) / 2\n",
    "                                  * (1 / 2)**3\n",
    "                                  / 5 * 1 * 20)},\n",
    "             '1-3-3-3-3': {'P5': ((1 / 2)**4\n",
    "                                  / 5 * 1 * 5)},\n",
    "             '2-2-2-2-2': {},  # Chosen strategy not present so impossible\n",
    "             '2-2-2-2-3': {},  # Chosen strategy not present so impossible\n",
    "             '2-2-2-3-3': {},  # Chosen strategy not present so impossible\n",
    "             '2-2-3-3-3': {},  # Chosen strategy not present so impossible\n",
    "             '2-3-3-3-3': {},  # Chosen strategy not present so impossible\n",
    "             '3-3-3-3-3': {}}  # Chosen strategy not present so impossible\n",
    "for profile in profiles_filtered:\n",
    "    for player in expected1[profile].keys():\n",
    "        fastcore.test.test_close(result1[profile][player],\n",
    "                                 expected1[profile][player])\n",
    "\n",
    "\n",
    "result1_sum = 0\n",
    "for likelihoods_by_player in result1.values():\n",
    "    for likelihood in likelihoods_by_player.values():\n",
    "        result1_sum += likelihood\n",
    "fastcore.test.test_close(result1_sum, 1)\n",
    "\n",
    "# The expected results take the probability of attaining a given profile when\n",
    "# sampling all other players from the availabe sectors and player types (top few\n",
    "# lines), divided by the chance your agent was sampled to be in of the player\n",
    "# positions (in this case this is always 1/5).\n",
    "expected2 = {'1-1-1-1-1': {'P1': (math.comb(7, 4) / math.comb(9, 4) / 2**4\n",
    "                                  / 5)},\n",
    "             '1-1-1-1-2': {'P2': (math.comb(7, 3) / math.comb(9, 3) / 2**3\n",
    "                                  * math.comb(2, 1) / math.comb(6, 1) / 2\n",
    "                                  / 5)},\n",
    "             '1-1-1-1-3': {'P2': (math.comb(7, 3) / math.comb(9, 3) / 2**3\n",
    "                                  * (1 / 2)\n",
    "                                  / 5)},\n",
    "             '1-1-1-2-2': {'P3': (math.comb(7, 2) / math.comb(9, 2) / 2**2\n",
    "                                  * math.comb(2, 2) / math.comb(7, 2) / 2**2\n",
    "                                  / 5)},\n",
    "             '1-1-1-2-3': {'P3': (math.comb(7, 2) / math.comb(9, 2) / 2**2\n",
    "                                  * math.comb(2, 1) / math.comb(7, 1) / 2\n",
    "                                  * (1 / 2)\n",
    "                                  / 5)},\n",
    "             '1-1-1-3-3': {'P3': (math.comb(7, 2) / math.comb(9, 2) / 2**2\n",
    "                                  * (1 / 2)**2\n",
    "                                  / 5)},\n",
    "             '1-1-2-2-2': {'P4': 0.0},  # Too many mutants so impossible\n",
    "             '1-1-2-2-3': {'P4': (math.comb(7, 1) / math.comb(9, 1) / 2\n",
    "                                  * math.comb(2, 2) / math.comb(8, 2) / 2**2\n",
    "                                  * (1 / 2)\n",
    "                                  / 5)},\n",
    "             '1-1-2-3-3': {'P4': (math.comb(7, 1) / math.comb(9, 1) / 2\n",
    "                                  * math.comb(2, 1) / math.comb(8, 1) / 2\n",
    "                                  * (1 / 2)**2\n",
    "                                  / 5)},\n",
    "             '1-1-3-3-3': {'P4': (math.comb(7, 1) / math.comb(9, 1) / 2\n",
    "                                  * (1 / 2)**3\n",
    "                                  / 5)},\n",
    "             '1-2-2-2-2': {'P5': 0.0},  # Too many mutants so impossible\n",
    "             '1-2-2-2-3': {'P5': 0.0},  # Too many mutants so impossible\n",
    "             '1-2-2-3-3': {'P5': (math.comb(2, 2) / math.comb(9, 2) / 2**2\n",
    "                                  * (1 / 2)**2\n",
    "                                  / 5)},\n",
    "             '1-2-3-3-3': {'P5': (math.comb(2, 1) / math.comb(9, 1) / 2\n",
    "                                  * (1 / 2)**3\n",
    "                                  / 5)},\n",
    "             '1-3-3-3-3': {'P5': ((1 / 2)**4\n",
    "                                  / 5)},\n",
    "             '2-2-2-2-2': {},  # Chosen strategy not present so impossible\n",
    "             '2-2-2-2-3': {},  # Chosen strategy not present so impossible\n",
    "             '2-2-2-3-3': {},  # Chosen strategy not present so impossible\n",
    "             '2-2-3-3-3': {},  # Chosen strategy not present so impossible\n",
    "             '2-3-3-3-3': {},  # Chosen strategy not present so impossible\n",
    "             '3-3-3-3-3': {}}  # Chosen strategy not present so impossible\n",
    "for profile in profiles_filtered:\n",
    "    for player in expected1[profile].keys():\n",
    "        fastcore.test.test_close(result2[profile][player],\n",
    "                                 expected2[profile][player])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697bea53",
   "metadata": {},
   "source": [
    "### A multimethod for computing each strategy's success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b64d97ad-183c-4564-9773-d40cc50bcef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "@multi\n",
    "def compute_success(models):\n",
    "    \"\"\"Compute the success of the two strategies under consideration.\"\"\"\n",
    "    return models.get('compute_success_rule', \"cheap\")\n",
    "\n",
    "\n",
    "@method(compute_success)\n",
    "def compute_success(models):\n",
    "    \"\"\"Compute the success of the two strategies under consideration for each\n",
    "    number of k mutants implied by the transition.\"\"\"\n",
    "    models = apply_profile_filters(models)\n",
    "    ind1, ind2 = models['transition_indices']\n",
    "    sector_strategies = models['sector_strategies']\n",
    "    Z = models['Z']\n",
    "    payoffs = models['payoffs']\n",
    "\n",
    "    ind1_tuple = list(map(int, ind1.split(\"-\")))\n",
    "    ind2_tuple = list(map(int, ind2.split(\"-\")))\n",
    "    differ = [i1 != i2 for i1, i2 in zip(ind1_tuple, ind2_tuple)]\n",
    "    affected_sector = f\"S{np.argmax(differ[::-1]) + 1}\"\n",
    "    current_strategy = ind1_tuple[np.argmax(differ)]\n",
    "    mutant_strategy = ind2_tuple[np.argmax(differ)]\n",
    "\n",
    "    ΠA = []\n",
    "    ΠB = []\n",
    "    for n_mutants in range(1, Z[affected_sector]):\n",
    "        dist1 = compute_profile_dist({**models,\n",
    "                                      'chosen_strategy': current_strategy,\n",
    "                                      'current_strategy': current_strategy,\n",
    "                                      'mutant_strategy': mutant_strategy,\n",
    "                                      'affected_sector': affected_sector,\n",
    "                                      'n_mutants': n_mutants})\n",
    "        dist2 = compute_profile_dist({**models,\n",
    "                                      'chosen_strategy': mutant_strategy,\n",
    "                                      'current_strategy': current_strategy,\n",
    "                                      'mutant_strategy': mutant_strategy,\n",
    "                                      'affected_sector': affected_sector,\n",
    "                                      'n_mutants': n_mutants})\n",
    "        success_A = 0\n",
    "        for profile, player_map in dist1.items():\n",
    "            for player, likelihood in player_map.items():\n",
    "                success_A += payoffs[profile][player] * likelihood\n",
    "        ΠA.append(success_A)\n",
    "        success_B = 0\n",
    "        for profile, player_map in dist2.items():\n",
    "            for player, likelihood in player_map.items():\n",
    "                success_B += payoffs[profile][player] * likelihood\n",
    "        ΠB.append(success_B)\n",
    "    return ΠA, ΠB\n",
    "\n",
    "@method(compute_success, \"cheap\")\n",
    "def compute_success(models):\n",
    "    \"\"\"Compute the success of the two strategies under consideration for each\n",
    "    number of k mutants implied by the transition.\"\"\"\n",
    "    models = apply_profile_filters(models)\n",
    "    ind1, ind2 = models['transition_indices']\n",
    "    sector_strategies = models['sector_strategies']\n",
    "    Z = models['Z']\n",
    "    payoffs = models['payoffs']\n",
    "\n",
    "    ind1_tuple = list(map(int, ind1.split(\"-\")))\n",
    "    ind2_tuple = list(map(int, ind2.split(\"-\")))\n",
    "    differ = [i1 != i2 for i1, i2 in zip(ind1_tuple, ind2_tuple)]\n",
    "    affected_sector = f\"S{np.argmax(differ[::-1]) + 1}\"\n",
    "    current_strategy = ind1_tuple[np.argmax(differ)]\n",
    "    mutant_strategy = ind2_tuple[np.argmax(differ)]\n",
    "\n",
    "    ΠA = []\n",
    "    ΠB = []\n",
    "    for n_mutants in range(1, Z[affected_sector]):\n",
    "        dist1 = compute_profile_dist({**models,\n",
    "                                      'chosen_strategy': current_strategy,\n",
    "                                      'current_strategy': current_strategy,\n",
    "                                      'mutant_strategy': mutant_strategy,\n",
    "                                      'affected_sector': affected_sector,\n",
    "                                      'n_mutants': n_mutants})\n",
    "        dist2 = compute_profile_dist({**models,\n",
    "                                      'chosen_strategy': mutant_strategy,\n",
    "                                      'current_strategy': current_strategy,\n",
    "                                      'mutant_strategy': mutant_strategy,\n",
    "                                      'affected_sector': affected_sector,\n",
    "                                      'n_mutants': n_mutants})\n",
    "        payoffsA = []\n",
    "        likelihoodsA = []\n",
    "        for profile, player_map in dist1.items():\n",
    "            for player, likelihood in player_map.items():\n",
    "                payoffsA.append(payoffs[profile][player])\n",
    "                likelihoodsA.append(likelihood)\n",
    "        ΠA.append(np.dot(np.array(payoffsA).T, likelihoodsA))\n",
    "        payoffsB = []\n",
    "        likelihoodsB = []\n",
    "        for profile, player_map in dist2.items():\n",
    "            for player, likelihood in player_map.items():\n",
    "                payoffsB.append(payoffs[profile][player]) \n",
    "                likelihoodsB.append(likelihood)\n",
    "        ΠB.append(np.dot(np.array(payoffsB).T, likelihoodsB))\n",
    "    return ΠA, ΠB\n",
    "\n",
    "\n",
    "@method(compute_success, \"functional\")\n",
    "def compute_success(models):\n",
    "    \"\"\"Compute the success of the two strategies under consideration for each\n",
    "    number of k mutants implied by the transition.\"\"\"\n",
    "    models = apply_profile_filters(models)\n",
    "    ind1, ind2 = models['transition_indices']\n",
    "    sector_strategies = models['sector_strategies']\n",
    "    Z = models['Z']\n",
    "    payoffs_function = models['payoffs_function']\n",
    "\n",
    "    ind1_tuple = list(map(int, ind1.split(\"-\")))\n",
    "    ind2_tuple = list(map(int, ind2.split(\"-\")))\n",
    "    differ = [i1 != i2 for i1, i2 in zip(ind1_tuple, ind2_tuple)]\n",
    "    affected_sector = f\"S{np.argmax(differ[::-1]) + 1}\"\n",
    "    current_strategy = ind1_tuple[np.argmax(differ)]\n",
    "    mutant_strategy = ind2_tuple[np.argmax(differ)]\n",
    "\n",
    "    ΠA = []\n",
    "    ΠB = []\n",
    "    for n_mutants in range(1, Z[affected_sector]):\n",
    "        dist1 = compute_profile_dist({**models,\n",
    "                                      'chosen_strategy': current_strategy,\n",
    "                                      'current_strategy': current_strategy,\n",
    "                                      'mutant_strategy': mutant_strategy,\n",
    "                                      'affected_sector': affected_sector,\n",
    "                                      'n_mutants': n_mutants})\n",
    "        dist2 = compute_profile_dist({**models,\n",
    "                                      'chosen_strategy': mutant_strategy,\n",
    "                                      'current_strategy': current_strategy,\n",
    "                                      'mutant_strategy': mutant_strategy,\n",
    "                                      'affected_sector': affected_sector,\n",
    "                                      'n_mutants': n_mutants})\n",
    "        # Record the strategy counts in the population implied by the number of\n",
    "        # mutants so that our payoff function can make use of this information\n",
    "        strategy_counts = {str(strategy): Z[sector]\n",
    "                           for strategy in ind1_tuple\n",
    "                           for sector in sector_strategies.keys()\n",
    "                           if strategy in sector_strategies[sector]}\n",
    "        strategy_counts = {**strategy_counts,\n",
    "                           str(current_strategy): Z[affected_sector] - n_mutants,\n",
    "                           str(mutant_strategy): n_mutants}\n",
    "        population_state = models.get(\"population_state\", {})\n",
    "        population_state = {**population_state,\n",
    "                            \"strategy_counts\": strategy_counts}\n",
    "        # Compute the payoffs for each strategy in each possible profile\n",
    "        # and the likelihood of that profile occuring.\n",
    "        payoffsA = []\n",
    "        likelihoodsA = []\n",
    "        for profile, player_map in dist1.items():\n",
    "            for player, likelihood in player_map.items():\n",
    "                payoffsA.append(payoffs_function({**models,\n",
    "                                                  \"population_state\": population_state,\n",
    "                                                  \"profile\": profile,\n",
    "                                                  \"player\": player}))\n",
    "                likelihoodsA.append(likelihood)\n",
    "        ΠA.append(np.dot(np.array(payoffsA).T, likelihoodsA))\n",
    "        payoffsB = []\n",
    "        likelihoodsB = []\n",
    "        for profile, player_map in dist2.items():\n",
    "            for player, likelihood in player_map.items():\n",
    "                payoffsB.append(payoffs_function({**models,\n",
    "                                                  \"population_state\": population_state,\n",
    "                                                  \"profile\": profile,\n",
    "                                                  \"player\": player}))\n",
    "                likelihoodsB.append(likelihood)\n",
    "        ΠB.append(np.dot(np.array(payoffsB).T, likelihoodsB))\n",
    "    return ΠA, ΠB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7ec612",
   "metadata": {},
   "source": [
    "#### Tests for `compute_success`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2335a4e4",
   "metadata": {},
   "source": [
    "##### Test 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5661dd48",
   "metadata": {},
   "source": [
    "For simplicity, I assume payoffs are always 1. Naturally, the success of\n",
    "each strategy will also be 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de21f4d",
   "metadata": {},
   "source": [
    "I consider a model with 2 sectors, who each have 2 strategies and 10 members,\n",
    "and play a game with 2 players who can each be from either sector.\n",
    "\n",
    "We therefore specify the sectors sizes, `Z`, the `sector_strategies` and the `allowed_sectors`\n",
    "\n",
    "`profiles_filtered` will be all profiles in such a game relevant to a transition\n",
    "between Sector 1 playing their first strategy and Sector 1 playing their\n",
    "second strategy. The members of Sector 2 play their first strategy.\n",
    "\n",
    "I encode these recurrent states as \"3-1\" and \"3-2\" respectively.\n",
    "\n",
    "I also mark \"S1\" as the `affected_sector`, as well as the `mutant_strategy`\n",
    "and `current_strategy`. \n",
    "\n",
    "`profiles_filtered` then includes: all possible \"x-y\" where x,y in {1,2,3},\n",
    "since there will be no \"S2\" players playing strategy 4.\n",
    "\n",
    "We also have to specify the `chosen_strategy` to indicate whether we are\n",
    "interested in the profile likelihoods from the perspective of a mutant player\n",
    "or a current player.\n",
    "\n",
    "The tests consider different values of `n_mutants`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d137e000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "Z = {\"S2\": 10, \"S1\": 10}\n",
    "sector_strategies = {\"S2\": [3, 4],\n",
    "                     \"S1\": [1, 2]}\n",
    "allowed_sectors = {\"P2\": [\"S1\", \"S2\"],\n",
    "                   \"P1\": [\"S1\", \"S2\"]}\n",
    "n_players = len(allowed_sectors.keys())\n",
    "n_strategies = [len(strategies) for strategies in sector_strategies]\n",
    "\n",
    "sector_weights = {}\n",
    "\n",
    "models = {\"Z\": Z,\n",
    "          \"sector_strategies\": sector_strategies,\n",
    "          \"allowed_sectors\": allowed_sectors,\n",
    "          \"n_players\": n_players,\n",
    "          \"n_strategies\": n_strategies,\n",
    "          #   \"sector_weights\": sector_weights,\n",
    "          }\n",
    "\n",
    "models = thread_macro(models,\n",
    "                      create_profiles,\n",
    "                      (assoc, \"transition_indices\", [\"3-1\", \"3-2\"]),\n",
    "                      apply_profile_filters)\n",
    "profiles_filtered = ['1-1', '1-2', '1-3',\n",
    "                     '2-1', '2-2', '2-3',\n",
    "                     '3-1', '3-2', '3-3']\n",
    "fastcore.test.test_eq(models[\"profiles_filtered\"], profiles_filtered)\n",
    "\n",
    "payoffs = {}\n",
    "for profile in profiles_filtered:\n",
    "    payoffs[profile] = {}\n",
    "    for player in allowed_sectors.keys():\n",
    "        payoffs[profile][player] = 1\n",
    "models = {**models, \"payoffs\": payoffs}\n",
    "\n",
    "result1 = compute_success(models)\n",
    "expected1 = [[1 for _ in range(9)],\n",
    "             [1 for _ in range(9)], ]\n",
    "for result, expected in zip(result1[0], expected1[0]):\n",
    "    fastcore.test.test_close(result, expected)\n",
    "for result, expected in zip(result1[1], expected1[1]):\n",
    "    fastcore.test.test_close(result, expected)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab13b4a3",
   "metadata": {},
   "source": [
    "##### Test 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035e82db",
   "metadata": {},
   "source": [
    "I also consider more general payoffs where many entries are unique. However,\n",
    "the order of strategies does not matter. \n",
    "\n",
    "When the order does not matter, it is very easy to calulate\n",
    "an expression for what the success of each strategy should be for the 2 player\n",
    "interactions considered in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "74439a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "Z = {\"S2\": 10, \"S1\": 10}\n",
    "sector_strategies = {\"S2\": [3, 4],\n",
    "                     \"S1\": [1, 2]}\n",
    "allowed_sectors = {\"P2\": [\"S1\", \"S2\"],\n",
    "                   \"P1\": [\"S1\", \"S2\"]}\n",
    "n_players = len(allowed_sectors.keys())\n",
    "n_strategies = [len(strategies) for strategies in sector_strategies]\n",
    "\n",
    "sector_weights = {}\n",
    "\n",
    "models = {\"Z\": Z,\n",
    "          \"sector_strategies\": sector_strategies,\n",
    "          \"allowed_sectors\": allowed_sectors,\n",
    "          \"n_players\": n_players,\n",
    "          \"n_strategies\": n_strategies,\n",
    "          #   \"sector_weights\": sector_weights,\n",
    "          }\n",
    "\n",
    "models = thread_macro(models,\n",
    "                      create_profiles,\n",
    "                      (assoc, \"transition_indices\", [\"3-1\", \"3-2\"]),\n",
    "                      apply_profile_filters)\n",
    "profiles_filtered = ['1-1', '1-2', '1-3',\n",
    "                     '2-1', '2-2', '2-3',\n",
    "                     '3-1', '3-2', '3-3']\n",
    "fastcore.test.test_eq(models[\"profiles_filtered\"], profiles_filtered)\n",
    "\n",
    "payoffs = {\n",
    "    '1-1': {'P1': 2, 'P2': 2},\n",
    "    '1-2': {'P1': 4, 'P2': 0},\n",
    "    '1-3': {'P1': 3, 'P2': 3},\n",
    "    '1-4': {'P1': 6, 'P2': 0},\n",
    "    '2-1': {'P1': 0, 'P2': 4},\n",
    "    '2-2': {'P1': 1, 'P2': 1},\n",
    "    '2-3': {'P1': 0, 'P2': 6},\n",
    "    '2-4': {'P1': 2, 'P2': 1},\n",
    "    '3-1': {'P1': 3, 'P2': 3},\n",
    "    '3-2': {'P1': 6, 'P2': 0},\n",
    "    '3-3': {'P1': 4, 'P2': 4},\n",
    "    '3-4': {'P1': 8, 'P2': 0},\n",
    "    '4-1': {'P1': 0, 'P2': 6},\n",
    "    '4-2': {'P1': 1, 'P2': 2},\n",
    "    '4-3': {'P1': 0, 'P2': 8},\n",
    "    '4-4': {'P1': 2, 'P2': 2},\n",
    "}\n",
    "\n",
    "result2 = compute_success({**models, \"payoffs\": payoffs})\n",
    "# 50% chance of facing strategy 3 no matter if we look at player 1 or 2.\n",
    "# Otherwise, we have a 0.5 * (n_mutants / z_s1) chance of facing strategy 2\n",
    "# and a 0.5 * ((z_s1 - n_mutants) / z_s1) chance of facing strategy 1.\n",
    "expected2 = [[((0.5\n",
    "                * k / (Z[\"S1\"] - 1)\n",
    "                * payoffs['2-1']['P1'])\n",
    "               + (0.5\n",
    "                  * (Z[\"S1\"] - 1 - k) / (Z[\"S1\"] - 1)\n",
    "                  * payoffs['1-1']['P1'])\n",
    "               + 0.5 * payoffs['3-1']['P1'])\n",
    "              for k in range(1, 10)],\n",
    "             [((0.5\n",
    "                * (k - 1) / (Z[\"S1\"] - 1)\n",
    "                * payoffs['2-2']['P1'])\n",
    "               + (0.5\n",
    "                  * (Z[\"S1\"] - k) / (Z[\"S1\"] - 1)\n",
    "                  * payoffs['1-2']['P1'])\n",
    "               + 0.5 * payoffs['3-2']['P1'])\n",
    "              for k in range(1, 10)], ]\n",
    "for result, expected in zip(result2[0], expected2[0]):\n",
    "    fastcore.test.test_close(result, expected)\n",
    "for result, expected in zip(result2[1], expected2[1]):\n",
    "    fastcore.test.test_close(result, expected)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b5441b",
   "metadata": {},
   "source": [
    "##### Test 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fff1e7",
   "metadata": {},
   "source": [
    "We can find a similar expression for when the order does matter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8eb0e5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "Z = {\"S2\": 10, \"S1\": 10}\n",
    "sector_strategies = {\"S2\": [3, 4],\n",
    "                     \"S1\": [1, 2]}\n",
    "allowed_sectors = {\"P2\": [\"S1\", \"S2\"],\n",
    "                   \"P1\": [\"S1\", \"S2\"]}\n",
    "n_players = len(allowed_sectors.keys())\n",
    "n_strategies = [len(strategies) for strategies in sector_strategies]\n",
    "\n",
    "sector_weights = {}\n",
    "\n",
    "models = {\"Z\": Z,\n",
    "          \"sector_strategies\": sector_strategies,\n",
    "          \"allowed_sectors\": allowed_sectors,\n",
    "          \"n_players\": n_players,\n",
    "          \"n_strategies\": n_strategies,\n",
    "          #   \"sector_weights\": sector_weights,\n",
    "          }\n",
    "\n",
    "models = thread_macro(models,\n",
    "                      create_profiles,\n",
    "                      (assoc, \"transition_indices\", [\"3-1\", \"3-2\"]),\n",
    "                      apply_profile_filters)\n",
    "profiles_filtered = ['1-1', '1-2', '1-3',\n",
    "                     '2-1', '2-2', '2-3',\n",
    "                     '3-1', '3-2', '3-3']\n",
    "fastcore.test.test_eq(models[\"profiles_filtered\"], profiles_filtered)\n",
    "\n",
    "payoffs = {}\n",
    "for profile in profiles_filtered:\n",
    "    payoffs[profile] = {}\n",
    "    for player in allowed_sectors.keys():\n",
    "        payoffs[profile][player] = np.random.beta(1, 1)\n",
    "models = {**models, \"payoffs\": payoffs}\n",
    "\n",
    "result2 = compute_success({**models, \"payoffs\": payoffs})\n",
    "# 50% chance of facing strategy 3 no matter if we look at player 1 or 2.\n",
    "# Otherwise, we have a 0.5 * (n_mutants / z_s1) chance of facing strategy 2\n",
    "# and a 0.5 * ((z_s1 - n_mutants) / z_s1) chance of facing strategy 1.\n",
    "# For each of these there is a 50% of being player 1 or player 2.\n",
    "expected2 = [[((0.5\n",
    "                * k / (Z[\"S1\"] - 1)\n",
    "                * (payoffs['2-1']['P1']\n",
    "                   + payoffs['1-2']['P2']) / 2\n",
    "                )\n",
    "               + (0.5\n",
    "                  * (Z[\"S1\"] - 1 - k) / (Z[\"S1\"] - 1)\n",
    "                  * (payoffs['1-1']['P1']\n",
    "                     + payoffs['1-1']['P2']) / 2\n",
    "                  )\n",
    "               + (0.5\n",
    "                  * (payoffs['3-1']['P1']\n",
    "                     + payoffs['1-3']['P2']) / 2\n",
    "                  )\n",
    "               )\n",
    "              for k in range(1, 10)],\n",
    "             [((0.5\n",
    "                * (k - 1) / (Z[\"S1\"] - 1)\n",
    "                * (payoffs['2-2']['P1']\n",
    "                   + payoffs['2-2']['P2']) / 2\n",
    "                )\n",
    "               + (0.5\n",
    "                  * (Z[\"S1\"] - k) / (Z[\"S1\"] - 1)\n",
    "                  * (payoffs['1-2']['P1']\n",
    "                     + payoffs['2-1']['P2']) / 2\n",
    "                  )\n",
    "               + (0.5\n",
    "                  * (payoffs['3-2']['P1']\n",
    "                     + payoffs['2-3']['P2']) / 2\n",
    "                  )\n",
    "               )\n",
    "              for k in range(1, 10)], ]\n",
    "for result, expected in zip(result2[0], expected2[0]):\n",
    "    fastcore.test.test_close(result, expected)\n",
    "for result, expected in zip(result2[1], expected2[1]):\n",
    "    fastcore.test.test_close(result, expected)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533205c0",
   "metadata": {},
   "source": [
    "### Infer number of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "687281ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def vals(d: dict):\n",
    "    \"Return the values of a dictionary.\"\n",
    "    return d.values()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "edaf4cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def infer_n_models(models):\n",
    "    \"Infer the number of models from the model payoffs.\"\n",
    "    try:\n",
    "        payoffs = models.get('payoffs')\n",
    "        payoff_vector = thread_macro(payoffs,\n",
    "                                     vals,\n",
    "                                     iter,\n",
    "                                     next,\n",
    "                                     vals,\n",
    "                                     iter,\n",
    "                                     next)\n",
    "        n_models = (1\n",
    "                    if isinstance(payoff_vector, (float, int))\n",
    "                    else len(payoff_vector))\n",
    "    except:\n",
    "        raise ValueError(\"\"\"Unable to infer `n_models`.\n",
    "                         `payoffs` is structured incorrectly\"\"\")\n",
    "    return n_models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8ebaa9",
   "metadata": {},
   "source": [
    "#### Tests for `infer_n_models`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e036a463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profiles_filtered = ['1-1', '1-2', '1-3',\n",
    "                     '2-1', '2-2', '2-3',\n",
    "                     '3-1', '3-2', '3-3']\n",
    "payoffs = {}\n",
    "for profile in profiles_filtered:\n",
    "    payoffs[profile] = {}\n",
    "    for player in allowed_sectors.keys():\n",
    "        payoffs[profile][player] = np.repeat(np.random.beta(1, 1), 5)\n",
    "infer_n_models({'payoffs': payoffs})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf62fe5",
   "metadata": {},
   "source": [
    "### An algorithm for building the transition matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c79050-23b5-4662-b0d5-2b099d1d0e04",
   "metadata": {},
   "source": [
    "We now have the methods we need for building the transition matrix for a game with an arbitrary number of sectors and various interactions between those sectors.\n",
    "\n",
    "The algorithm goes as follows:\n",
    "\n",
    "For each possible transition\n",
    "  - Check if the transition is valid\n",
    "    - If self-transition, assign the value 1\n",
    "    - If not, skip\n",
    "  - Filter profiles down to only those which are relevant\n",
    "  - Compute average payoffs using the payoffs and those profiles\n",
    "  - Compute the fixation rate\n",
    "  - Compute transition probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "037ec39a-c883-40d6-8efe-033d26623ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "# | hide\n",
    "@method(build_transition_matrix, 'multiple-populations')\n",
    "def build_transition_matrix(models: dict  # A dictionary that contains the parameters in `ModelTypeEGTMultiple`\n",
    "                            ):\n",
    "    \"\"\"Build a transition matrix between all monomorphic states\n",
    "    when there are multiple populations.    \n",
    "    \"\"\"\n",
    "    β = models['β']\n",
    "    n_models = models.get('n_models',\n",
    "                          infer_n_models(models))\n",
    "    S = models.get('recurrent_states',\n",
    "                   create_recurrent_states(models))\n",
    "    M = np.zeros((n_models, len(S), len(S)))\n",
    "    for row_ind in range(M.shape[-1]):\n",
    "        M[:, row_ind, row_ind] += 1\n",
    "    transition_inds = [(i, j)\n",
    "                       for i in range(len(S))\n",
    "                       for j in range(len(S))]\n",
    "    for row_ind, col_ind in transition_inds:\n",
    "        current_state, new_state = S[row_ind], S[col_ind]\n",
    "        if current_state == new_state:\n",
    "            continue\n",
    "        if not valid_transition(current_state, new_state):\n",
    "            continue\n",
    "        ΠA, ΠB = compute_success(assoc(models,\n",
    "                                       \"transition_indices\",\n",
    "                                       [current_state, new_state]))\n",
    "        # TODO: Clean up assymetric beta code below\n",
    "        ind1_tuple = list(map(int, current_state.split(\"-\")))\n",
    "        ind2_tuple = list(map(int, new_state.split(\"-\")))\n",
    "        differ = [i1 != i2 for i1, i2 in zip(ind1_tuple, ind2_tuple)]\n",
    "        affected_sector = f\"S{np.argmax(differ[::-1]) + 1}\"\n",
    "        if isinstance(β, dict):\n",
    "            ρ = fixation_rate_stable(ΠA, ΠB, β[affected_sector])\n",
    "        else:\n",
    "            ρ = fixation_rate_stable(ΠA, ΠB, β)\n",
    "        n_mutations = sum(valid_transition(current_state, s_alt)\n",
    "                          for s_alt in S)\n",
    "        M[:, row_ind, col_ind] = ρ / n_mutations\n",
    "        M[:, row_ind, row_ind] -= ρ / n_mutations\n",
    "    return {**models, 'transition_matrix': M,\n",
    "            'recurrent_states': S,\n",
    "            'n_models': n_models}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "88ce2b5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/PaoloBova/gh-pages-example/blob/main/gh_pages_example/methods.py#L1612){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### build_transition_matrix\n",
       "\n",
       ">      build_transition_matrix (models:dict)\n",
       "\n",
       "Build a transition matrix between all monomorphic states\n",
       "when there are multiple populations.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| models | dict | A dictionary that contains the parameters in `ModelTypeEGTMultiple` |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/PaoloBova/gh-pages-example/blob/main/gh_pages_example/methods.py#L1612){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### build_transition_matrix\n",
       "\n",
       ">      build_transition_matrix (models:dict)\n",
       "\n",
       "Build a transition matrix between all monomorphic states\n",
       "when there are multiple populations.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| models | dict | A dictionary that contains the parameters in `ModelTypeEGTMultiple` |"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | echo:false\n",
    "# Note: I can't directly call show doc on the expression `build_transition_matrix.__multi__['multiple-populations']`\n",
    "# as it throws an error when I generate documentation using nbdev_preview.\n",
    "# I can fix it with:\n",
    "# x = build_transition_matrix.__multi__['multiple-populations']\n",
    "# show_doc(x)\n",
    "# or using my Clojure-style threading macro:\n",
    "thread_macro(build_transition_matrix.__multi__['multiple-populations'],\n",
    "             show_doc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42ccd41",
   "metadata": {},
   "source": [
    "#### Tests and examples for `build_transition_matrix` for multiple populations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7375e14",
   "metadata": {},
   "source": [
    "##### Test 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c404759",
   "metadata": {},
   "source": [
    "I first consider a random payoff matrix and check that the\n",
    "resulting transition matrices have rows which sum to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d2c4dc",
   "metadata": {},
   "source": [
    "As we are working with multiple populations, our `models` variable needs to declare this with the `dispatch-type` key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1bd255fe-94e4-4a15-b2a3-cae2f1fefd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "β = 1\n",
    "Z = {\"S1\": 50, \"S2\": 50, \"S3\": 50}\n",
    "allowed_sectors = {\"P3\": [\"S3\"],\n",
    "                   \"P2\": [\"S2\"],\n",
    "                   \"P1\": [\"S1\"]}\n",
    "sector_strategies = {\"S3\": [4, 5],\n",
    "                     \"S2\": [2, 3],\n",
    "                     \"S1\": [0, 1]}\n",
    "\n",
    "models = {\"dispatch-type\": \"multiple-populations\",\n",
    "          \"β\": β,\n",
    "          \"Z\": Z,\n",
    "          \"allowed_sectors\": allowed_sectors,\n",
    "          \"sector_strategies\": sector_strategies,\n",
    "          }\n",
    "\n",
    "models = thread_macro(models,\n",
    "                      create_profiles,\n",
    "                      apply_profile_filters)\n",
    "\n",
    "payoffs = {}\n",
    "for profile in models['profiles_filtered']:\n",
    "    payoffs[profile] = {}\n",
    "    for player in models['allowed_sectors'].keys():\n",
    "        payoffs[profile][player] = np.array([np.random.beta(1, 1)\n",
    "                                             for _ in range(2)])\n",
    "models = {**models, \"payoffs\": payoffs}\n",
    "\n",
    "result = build_transition_matrix(models)['transition_matrix']\n",
    "result_sums = np.sum(result, axis=-1)\n",
    "fastcore.test.test_close(result_sums, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16cc40c",
   "metadata": {},
   "source": [
    "##### Test 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a231e8ed",
   "metadata": {},
   "source": [
    "Here is an example of how to build a transition matrix when we have 2 sectors, playing 2 strategies each, and\n",
    "engage in 2 player interactions with players being from either sector.\n",
    "\n",
    "In the limit of small mutation rates, the system spends almost all its time in states where each population plays one strategy. Moreover, only a mutant for one population has the opportunity to fixate in that population. This means we only need to consider transitions where the strategy played by one population has changed. Transitions where both populations would have to change strategy occur with probability 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75487688",
   "metadata": {},
   "source": [
    "In an earlier test, we showed that one could compute the success of each\n",
    "strategy in a pairwise contest analytically, even in the presence of other\n",
    "sectors with fixed populations. \n",
    "\n",
    "Once we have the successes for each `n_mutant` value, we can rely on our\n",
    "well-tested `fixation_rate` function to help compute our expected transition\n",
    "probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0c63124f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "# | hide\n",
    "@multi\n",
    "def compute_success_analytical(models):\n",
    "    return models.get('success_analytical_derivation')\n",
    "\n",
    "\n",
    "@method(compute_success_analytical, '2sector2strategy2player')\n",
    "def compute_success_analytical(models):\n",
    "    \"\"\"Compute the success of each strategy involved in a transition for\n",
    "    a game with two players who can each be from one of two sectors. Each\n",
    "    sector uses two strategies.\"\"\"\n",
    "\n",
    "    # 50% chance of facing fixed strategy no matter if we look at mutant or\n",
    "    # current strategy\n",
    "    # Otherwise, we have a 0.5 * (n_mutants / z_s1) chance of facing strategy 2\n",
    "    # and a 0.5 * ((z_s1 - n_mutants) / z_s1) chance of facing strategy 1.\n",
    "    # For each of theses there is a 50% of being player 1 or player 2.\n",
    "    transition_indices = models['transition_indices']\n",
    "    Z = models['Z']\n",
    "    payoffs = models['payoffs']\n",
    "    ind1, ind2 = transition_indices\n",
    "    ind1_tuple = list(map(int, ind1.split(\"-\")))\n",
    "    ind2_tuple = list(map(int, ind2.split(\"-\")))\n",
    "    differ = [i1 != i2 for i1, i2 in zip(ind1_tuple, ind2_tuple)]\n",
    "    affected_sector = f\"S{np.argmax(differ[::-1]) + 1}\"\n",
    "    current_strategy = ind1_tuple[np.argmax(differ)]\n",
    "    mutant_strategy = ind2_tuple[np.argmax(differ)]\n",
    "    # We only support two sectors here, so we know the other value must be the\n",
    "    # fixed sector.\n",
    "    fs = ind1_tuple[np.argmin(differ)]\n",
    "    cs = current_strategy\n",
    "    ms = mutant_strategy\n",
    "    SA, SB = [], []\n",
    "    z = Z[affected_sector]\n",
    "    for k in range(1, z):\n",
    "        successA = ((0.5\n",
    "                    * k / (z - 1)\n",
    "                    * (payoffs[f\"{ms}-{cs}\"]['P1']\n",
    "                        + payoffs[f\"{cs}-{ms}\"]['P2']) / 2\n",
    "                     )\n",
    "                    + (0.5\n",
    "                        * (z - 1 - k) / (z - 1)\n",
    "                        * (payoffs[f\"{cs}-{cs}\"]['P1']\n",
    "                           + payoffs[f\"{cs}-{cs}\"]['P2']) / 2\n",
    "                       )\n",
    "                    + (0.5\n",
    "                        * (payoffs[f\"{fs}-{cs}\"]['P1']\n",
    "                           + payoffs[f\"{cs}-{fs}\"]['P2']) / 2\n",
    "                       )\n",
    "                    )\n",
    "        SA.append(successA)\n",
    "        successB = ((0.5\n",
    "                     * (k - 1) / (z - 1)\n",
    "                     * (payoffs[f\"{ms}-{ms}\"]['P1']\n",
    "                         + payoffs[f\"{ms}-{ms}\"]['P2']) / 2\n",
    "                     )\n",
    "                    + (0.5\n",
    "                       * (z - k) / (z - 1)\n",
    "                       * (payoffs[f\"{cs}-{ms}\"]['P1']\n",
    "                           + payoffs[f\"{ms}-{cs}\"]['P2']) / 2\n",
    "                       )\n",
    "                    + (0.5\n",
    "                       * (payoffs[f\"{fs}-{ms}\"]['P1']\n",
    "                          + payoffs[f\"{ms}-{fs}\"]['P2']) / 2\n",
    "                       )\n",
    "                    )\n",
    "        SB.append(successB)\n",
    "    return SA, SB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "deaa8df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "Z = {\"S2\": 10, \"S1\": 10}\n",
    "β = 1\n",
    "sector_strategies = {\"S2\": [3, 4],\n",
    "                     \"S1\": [1, 2]}\n",
    "allowed_sectors = {\"P2\": [\"S1\", \"S2\"],\n",
    "                   \"P1\": [\"S1\", \"S2\"]}\n",
    "sector_weights = {}\n",
    "\n",
    "models = {\"dispatch-type\": \"multiple-populations\",\n",
    "          \"β\": β,\n",
    "          \"Z\": Z,\n",
    "          \"allowed_sectors\": allowed_sectors,\n",
    "          \"sector_strategies\": sector_strategies,\n",
    "          #   \"sector_weights\": sector_weights,\n",
    "          }\n",
    "\n",
    "models = thread_macro(models,\n",
    "                      create_profiles,\n",
    "                      apply_profile_filters)\n",
    "\n",
    "payoffs = {}\n",
    "for profile in models['profiles_filtered']:\n",
    "    payoffs[profile] = {}\n",
    "    for player in allowed_sectors.keys():\n",
    "        payoffs[profile][player] = np.array([np.random.beta(1, 1)\n",
    "                                             for _ in range(2)])\n",
    "models = {**models, \"payoffs\": payoffs}\n",
    "\n",
    "result = thread_macro({**models, \"payoffs\": payoffs},\n",
    "                      build_transition_matrix,\n",
    "                      (get, \"transition_matrix\"))\n",
    "\n",
    "# Generate expected results\n",
    "S = ['3-1', '3-2', '4-1', '4-2']\n",
    "matrix_inds = [(i, j)\n",
    "               for i in range(len(S))\n",
    "               for j in range(len(S))]\n",
    "n_models = infer_n_models(models)\n",
    "M = np.zeros((n_models, len(S), len(S)))\n",
    "for i in range(M.shape[-1]):\n",
    "    M[:, i, i] += 1\n",
    "for i, j in matrix_inds:\n",
    "    transition_indices = [S[i], S[j]]\n",
    "    current_state, new_state = transition_indices\n",
    "    if current_state == new_state:\n",
    "        continue\n",
    "    if not valid_transition(current_state, new_state):\n",
    "        continue\n",
    "    transition_indices = [current_state, new_state]\n",
    "    expected_model = {\"transition_indices\": transition_indices,\n",
    "                      \"Z\": Z,\n",
    "                      \"payoffs\": payoffs,\n",
    "                      \"success_analytical_derivation\": \"2sector2strategy2player\"}\n",
    "    PA, PB = compute_success_analytical(expected_model)\n",
    "    rho = fixation_rate_stable(PA, PB, β)\n",
    "    M[:, i, j] += rho / 2\n",
    "    M[:, i, i] -= rho / 2\n",
    "\n",
    "# Test that expected and actual results are close\n",
    "for row_ind in range(M.shape[2]):\n",
    "    for col_ind in range(M.shape[1]):\n",
    "        for model_ind in range(M.shape[0]):\n",
    "            if not fastcore.test.is_close(M[model_ind, col_ind, row_ind],\n",
    "                                          result[model_ind, col_ind, row_ind]):\n",
    "                print(\"indices: \", model_ind, col_ind, row_ind)\n",
    "            fastcore.test.test_close(M[model_ind, col_ind, row_ind],\n",
    "                                     result[model_ind, col_ind, row_ind])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3134e412",
   "metadata": {},
   "source": [
    "##### Test 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "81dc7afc",
   "metadata": {},
   "source": [
    "I also test that we can match closely the transition matrix values for a\n",
    "game with 2 sectors, 2 strategies, and 3 players, where the first 2\n",
    "players are from one sector and the third player is always from the remaining\n",
    "sector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6e64d670",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@method(compute_success_analytical, '2sector2strategy3player')\n",
    "def compute_success_analytical(models):\n",
    "    \"\"\"Compute the success of each strategy involved in a transition for\n",
    "    a game with three players where two players are from one sector and the\n",
    "    third is from another. Each sector uses two strategies.\"\"\"\n",
    "\n",
    "    # 100% chance of third player playing either their chosen strategy if they\n",
    "    # are the chosen agent, or otherwise 100% chance of third player playing\n",
    "    # their current strategy.\n",
    "    # If chosen agent in first sector, we have a (n_mutants / z_s1) chance of\n",
    "    # facing strategy 2 and a ((z_s1 - n_mutants) / z_s1) chance of facing\n",
    "    # strategy 1.\n",
    "    # For each of these, there is a 50% chance of being player 1 or player 2.\n",
    "    # If chosen player is the third player, then they have a 100% of facing\n",
    "    # against the fixed strategy played by the other two players.\n",
    "    transition_indices = models['transition_indices']\n",
    "    Z = models['Z']\n",
    "    payoffs = models['payoffs']\n",
    "    allowed_sectors = models['allowed_sectors']\n",
    "    ind1, ind2 = transition_indices\n",
    "    ind1_tuple = list(map(int, ind1.split(\"-\")))\n",
    "    ind2_tuple = list(map(int, ind2.split(\"-\")))\n",
    "    differ = [i1 != i2 for i1, i2 in zip(ind1_tuple, ind2_tuple)]\n",
    "    affected_sector = f\"S{np.argmax(differ[::-1]) + 1}\"\n",
    "    current_strategy = ind1_tuple[np.argmax(differ)]\n",
    "    mutant_strategy = ind2_tuple[np.argmax(differ)]\n",
    "    # We only support two sectors here, so we know the other value must be the\n",
    "    # fixed sector.\n",
    "    fs = ind1_tuple[np.argmin(differ)]\n",
    "    cs = current_strategy\n",
    "    ms = mutant_strategy\n",
    "    SA, SB = [], []\n",
    "    z = Z[affected_sector]\n",
    "    relevant_players = [p\n",
    "                        for p in allowed_sectors.keys()\n",
    "                        if affected_sector in allowed_sectors[p]]\n",
    "    if len(relevant_players) == 1:\n",
    "        for k in range(1, z):\n",
    "            SA.append(payoffs[f\"{cs}-{fs}-{fs}\"]['P3'])\n",
    "            SB.append(payoffs[f\"{ms}-{fs}-{fs}\"]['P3'])\n",
    "    elif len(relevant_players) == 2:\n",
    "        for k in range(1, z):\n",
    "            successA = ((k / (z - 1)\n",
    "                        * (payoffs[f\"{fs}-{ms}-{cs}\"]['P1']\n",
    "                            + payoffs[f\"{fs}-{cs}-{ms}\"]['P2']) / 2\n",
    "                         )\n",
    "                        + ((z - 1 - k) / (z - 1)\n",
    "                            * (payoffs[f\"{fs}-{cs}-{cs}\"]['P1']\n",
    "                               + payoffs[f\"{fs}-{cs}-{cs}\"]['P2']) / 2\n",
    "                           )\n",
    "                        )\n",
    "            SA.append(successA)\n",
    "            successB = (((k - 1) / (z - 1)\n",
    "                        * (payoffs[f\"{fs}-{ms}-{ms}\"]['P1']\n",
    "                            + payoffs[f\"{fs}-{ms}-{ms}\"]['P2']) / 2\n",
    "                         )\n",
    "                        + ((z - k) / (z - 1)\n",
    "                        * (payoffs[f\"{fs}-{cs}-{ms}\"]['P1']\n",
    "                            + payoffs[f\"{fs}-{ms}-{cs}\"]['P2']) / 2\n",
    "                           )\n",
    "                        )\n",
    "            SB.append(successB)\n",
    "    return SA, SB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "93561006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "Z = {\"S2\": 10, \"S1\": 10}\n",
    "β = 1\n",
    "sector_strategies = {\"S2\": [3, 4],\n",
    "                     \"S1\": [1, 2]}\n",
    "allowed_sectors = {\"P3\": [\"S2\"],\n",
    "                   \"P2\": [\"S1\"],\n",
    "                   \"P1\": [\"S1\"]}\n",
    "sector_weights = {}\n",
    "\n",
    "models = {\"dispatch-type\": \"multiple-populations\",\n",
    "          \"β\": β,\n",
    "          \"Z\": Z,\n",
    "          \"allowed_sectors\": allowed_sectors,\n",
    "          \"sector_strategies\": sector_strategies,\n",
    "          }\n",
    "\n",
    "models = thread_macro(models,\n",
    "                      create_profiles,\n",
    "                      apply_profile_filters)\n",
    "\n",
    "payoffs = {}\n",
    "for profile in models['profiles_filtered']:\n",
    "    payoffs[profile] = {}\n",
    "    for player in allowed_sectors.keys():\n",
    "        payoffs[profile][player] = np.array([np.random.beta(1, 1)\n",
    "                                             for _ in range(2)])\n",
    "models = {**models, \"payoffs\": payoffs}\n",
    "\n",
    "result = thread_macro({**models, \"payoffs\": payoffs},\n",
    "                      build_transition_matrix,\n",
    "                      (get, \"transition_matrix\"))\n",
    "\n",
    "# Generate expected results\n",
    "S = ['3-1', '3-2', '4-1', '4-2']\n",
    "matrix_inds = [(i, j)\n",
    "               for i in range(len(S))\n",
    "               for j in range(len(S))]\n",
    "n_models = infer_n_models(models)\n",
    "M = np.zeros((n_models, len(S), len(S)))\n",
    "for i in range(M.shape[-1]):\n",
    "    M[:, i, i] += 1\n",
    "for i, j in matrix_inds:\n",
    "    transition_indices = [S[i], S[j]]\n",
    "    current_state, new_state = transition_indices\n",
    "    if current_state == new_state:\n",
    "        continue\n",
    "    if not valid_transition(current_state, new_state):\n",
    "        continue\n",
    "    transition_indices = [current_state, new_state]\n",
    "    expected_model = {\"transition_indices\": transition_indices,\n",
    "                      \"Z\": Z,\n",
    "                      \"payoffs\": payoffs,\n",
    "                      \"allowed_sectors\": allowed_sectors,\n",
    "                      \"success_analytical_derivation\": \"2sector2strategy3player\"}\n",
    "    PA, PB = compute_success_analytical(expected_model)\n",
    "    rho = fixation_rate_stable(PA, PB, β)\n",
    "    M[:, i, j] += rho / 2\n",
    "    M[:, i, i] -= rho / 2\n",
    "\n",
    "# Test that expected and actual results are close\n",
    "for row_ind in range(M.shape[2]):\n",
    "    for col_ind in range(M.shape[1]):\n",
    "        for model_ind in range(M.shape[0]):\n",
    "            if not fastcore.test.is_close(M[model_ind, col_ind, row_ind],\n",
    "                                          result[model_ind, col_ind, row_ind]):\n",
    "                print(\"indices: \", model_ind, col_ind, row_ind)\n",
    "            fastcore.test.test_close(M[model_ind, col_ind, row_ind],\n",
    "                                     result[model_ind, col_ind, row_ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e895481f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "Z = {\"S2\": 10, \"S1\": 10}\n",
    "β = 1\n",
    "sector_strategies = {\"S2\": [4, 5],\n",
    "                     \"S1\": [1, 2]}\n",
    "allowed_sectors = {\"P3\": [\"S2\"],\n",
    "                   \"P2\": [\"S1\"],\n",
    "                   \"P1\": [\"S1\"]}\n",
    "sector_weights = {}\n",
    "\n",
    "models = {\"dispatch-type\": \"multiple-populations\",\n",
    "          \"β\": β,\n",
    "          \"Z\": Z,\n",
    "          \"allowed_sectors\": allowed_sectors,\n",
    "          \"sector_strategies\": sector_strategies,\n",
    "          }\n",
    "\n",
    "models = thread_macro(models,\n",
    "                      create_profiles,\n",
    "                      apply_profile_filters)\n",
    "\n",
    "payoffs = {}\n",
    "for profile in models['profiles_filtered']:\n",
    "    payoffs[profile] = {}\n",
    "    for player in allowed_sectors.keys():\n",
    "        payoffs[profile][player] = np.array([np.random.beta(1, 1)\n",
    "                                             for _ in range(2)])\n",
    "models = {**models, \"payoffs\": payoffs}\n",
    "\n",
    "result = thread_macro({**models, \"payoffs\": payoffs},\n",
    "                      build_transition_matrix,\n",
    "                      (get, \"transition_matrix\"))\n",
    "\n",
    "# Generate expected results\n",
    "S = ['4-1', '4-2', '5-1', '5-2']\n",
    "matrix_inds = [(i, j)\n",
    "               for i in range(len(S))\n",
    "               for j in range(len(S))]\n",
    "n_models = infer_n_models(models)\n",
    "M = np.zeros((n_models, len(S), len(S)))\n",
    "for i in range(M.shape[-1]):\n",
    "    M[:, i, i] += 1\n",
    "for i, j in matrix_inds:\n",
    "    transition_indices = [S[i], S[j]]\n",
    "    current_state, new_state = transition_indices\n",
    "    if current_state == new_state:\n",
    "        continue\n",
    "    if not valid_transition(current_state, new_state):\n",
    "        continue\n",
    "    transition_indices = [current_state, new_state]\n",
    "    expected_model = {\"transition_indices\": transition_indices,\n",
    "                      \"Z\": Z,\n",
    "                      \"payoffs\": payoffs,\n",
    "                      \"allowed_sectors\": allowed_sectors,\n",
    "                      \"success_analytical_derivation\": \"2sector2strategy3player\"}\n",
    "    PA, PB = compute_success_analytical(expected_model)\n",
    "    rho = fixation_rate_stable(PA, PB, β)\n",
    "    M[:, i, j] += rho / 2\n",
    "    M[:, i, i] -= rho / 2\n",
    "\n",
    "# Test that expected and actual results are close\n",
    "for row_ind in range(M.shape[2]):\n",
    "    for col_ind in range(M.shape[1]):\n",
    "        for model_ind in range(M.shape[0]):\n",
    "            if not fastcore.test.is_close(M[model_ind, col_ind, row_ind],\n",
    "                                          result[model_ind, col_ind, row_ind]):\n",
    "                print(\"indices: \", model_ind, col_ind, row_ind)\n",
    "            fastcore.test.test_close(M[model_ind, col_ind, row_ind],\n",
    "                                     result[model_ind, col_ind, row_ind])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a63ad354",
   "metadata": {},
   "source": [
    "#### Test 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6535bc-97f4-4a91-8aad-73d64059b5f8",
   "metadata": {},
   "source": [
    "This example comes from a paper by Encarnacao et al. 2016.\n",
    "\n",
    "They have a 3 sector model and report fixation probabilities for a particular scenario. Can we replicate it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b252c632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def payoffs_encanacao_2016(models):\n",
    "    names = ['b_r', 'b_s', 'c_s', 'c_t', 'σ']\n",
    "    b_r, b_s, c_s, c_t, σ = [models[k] for k in names]\n",
    "    payoffs = {}\n",
    "    n_players = 3\n",
    "    n_sectors = 3\n",
    "    n_strategies_per_sector = [2, 2, 2]\n",
    "    n_strategies_total = 6\n",
    "    # All players are from the first sector, playing that sector's first strategy\n",
    "    index_min = \"0-0-0\"\n",
    "    # All players are from the third sector, playing that sector's second strategy\n",
    "    index_max = \"5-5-5\"\n",
    "    # Note: The seperator makes it easy to represent games where n_strategies_total >= 10.\n",
    "\n",
    "    # It is also trivial to define a vector which maps these indexes to strategy profiles\n",
    "    # As sector order is fixed we could neglect to mention suscripts for each sector\n",
    "    strategy_names = [\"D\", \"C\", \"D\", \"C\", \"D\", \"C\"]\n",
    "\n",
    "    zero = np.zeros(b_r.shape[0])\n",
    "    # As in the main text\n",
    "    payoffs[\"C-C-C\"] = {\"P3\": b_r-2*c_s,\n",
    "                        \"P2\": σ+b_s-c_t,\n",
    "                        \"P1\": σ+b_s}\n",
    "    payoffs[\"C-C-D\"] = {\"P3\": -c_s,\n",
    "                        \"P2\": b_s-c_t,\n",
    "                        \"P1\": zero}\n",
    "    payoffs[\"C-D-C\"] = {\"P3\": b_r-c_s,\n",
    "                        \"P2\": zero,\n",
    "                        \"P1\": b_s}\n",
    "    payoffs[\"C-D-D\"] = {\"P3\": zero,\n",
    "                        \"P2\": σ,\n",
    "                        \"P1\": σ}\n",
    "    payoffs[\"D-C-C\"] = {\"P3\": zero,\n",
    "                        \"P2\": σ-c_t,\n",
    "                        \"P1\": σ}\n",
    "    payoffs[\"D-C-D\"] = {\"P3\": zero,\n",
    "                        \"P2\": -c_t,\n",
    "                        \"P1\": zero}\n",
    "    payoffs[\"D-D-C\"] = {\"P3\": zero,\n",
    "                        \"P2\": zero,\n",
    "                        \"P1\": zero}\n",
    "    payoffs[\"D-D-D\"] = {\"P3\": zero,\n",
    "                        \"P2\": σ,\n",
    "                        \"P1\": σ}\n",
    "\n",
    "    # The following indexes capture all strategy profiles where each player is fixed to a unique sector\n",
    "    # (and player order does not matter, so we need only consider one ordering of sectors).\n",
    "    payoffs[\"4-2-0\"] = payoffs[\"D-D-D\"]\n",
    "    payoffs[\"4-2-1\"] = payoffs[\"D-D-C\"]\n",
    "    payoffs[\"4-3-0\"] = payoffs[\"D-C-D\"]\n",
    "    payoffs[\"4-3-1\"] = payoffs[\"D-C-C\"]\n",
    "    payoffs[\"5-2-0\"] = payoffs[\"C-D-D\"]\n",
    "    payoffs[\"5-2-1\"] = payoffs[\"C-D-C\"]\n",
    "    payoffs[\"5-3-0\"] = payoffs[\"C-C-D\"]\n",
    "    payoffs[\"5-3-1\"] = payoffs[\"C-C-C\"]\n",
    "    return {**models, \"payoffs\": payoffs}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "63278aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2071/2810353546.py:15: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  ergodic = np.array(V.transpose(0, 2, 1)[y], dtype=float)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0.07429517, 0.02588305, 0.03549838, 0.06857849, 0.05535651,\n",
       "         0.11993023, 0.04737337, 0.57308479]]),\n",
       " 0.7957449065894959)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | export\n",
    "Z = {\"S3\": 50, \"S2\": 50, \"S1\": 50}\n",
    "β = 0.08\n",
    "sector_strategies = {\"S3\": [4, 5],\n",
    "                     \"S2\": [2, 3],\n",
    "                     \"S1\": [0, 1], }\n",
    "allowed_sectors = {\"P3\": [\"S3\"],\n",
    "                   \"P2\": [\"S2\"],\n",
    "                   \"P1\": [\"S1\"], }\n",
    "sector_weights = {}\n",
    "\n",
    "models = {\"dispatch-type\": \"multiple-populations\",\n",
    "          \"β\": β,\n",
    "          \"Z\": Z,\n",
    "          \"allowed_sectors\": allowed_sectors,\n",
    "          \"sector_strategies\": sector_strategies,\n",
    "          #   \"sector_weights\": sector_weights,\n",
    "          'b_r': np.array([0.8]),\n",
    "          'b_s': np.array([0.4]),\n",
    "          'c_s': np.array([0.15]),\n",
    "          'c_t': np.array([0.15]),\n",
    "          'σ': np.array([0.2]),\n",
    "          }\n",
    "\n",
    "models = thread_macro(models,\n",
    "                      create_profiles,\n",
    "                      apply_profile_filters,\n",
    "                      payoffs_encanacao_2016,\n",
    "                      build_transition_matrix,\n",
    "                      find_ergodic_distribution,\n",
    "                      )\n",
    "models['transition_matrix']\n",
    "models['ergodic'], np.sum(models['ergodic'][0, 4:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3615b0c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[98.58484409,  0.43868208,  0.30980716,  0.        ,\n",
       "          0.66666667,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.96080835, 96.4805528 ,  0.        ,  0.73408493,\n",
       "          0.        ,  1.82455392,  0.        ,  0.        ],\n",
       "        [ 1.22164065,  0.        , 97.32807231,  0.96080835,\n",
       "          0.        ,  0.        ,  0.48947868,  0.        ],\n",
       "        [ 0.        ,  0.60342679,  0.43868208, 97.44630095,\n",
       "          0.        ,  0.        ,  0.        ,  1.51159018],\n",
       "        [ 0.66666667,  0.        ,  0.        ,  0.        ,\n",
       "         97.63844005,  0.96080835,  0.73408493,  0.        ],\n",
       "        [ 0.        ,  0.14274942,  0.        ,  0.        ,\n",
       "          0.43868208, 98.00649791,  0.        ,  1.41207058],\n",
       "        [ 0.        ,  0.        ,  0.88124961,  0.        ,\n",
       "          0.60342679,  0.        , 96.79725701,  1.71806658],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.21292021,\n",
       "          0.        ,  0.24196967,  0.1635232 , 99.38158692]]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models['transition_matrix'] * 50 * 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1cf739",
   "metadata": {},
   "source": [
    "The ergodic distribution of states looks remarkably similar to the results reported in the paper.\n",
    "\n",
    "Unfortunately, there are no exact results available to compare against. However, the direction of\n",
    "change and relative sizes of the bars in the bar chat are very similar. The sum of the last 4 very\n",
    "closely matches the bar for total public cooperators which sits level to 0.8 on the chart."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b7387c-e3a6-4aff-bfc4-6ce526a77853",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c9bfc7-1a73-46e5-a23f-0a4cfe3802b4",
   "metadata": {},
   "source": [
    "https://datagy.io/python-defaultdict/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b2068db8-0c99-4932-bdf8-cfe23f6b0594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import nbdev\n",
    "nbdev.nbdev_export()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "5844494aa8caf4c1a0a05d85746d5381f91a25fadc32ae63a73a248c881db361"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
